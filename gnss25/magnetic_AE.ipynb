{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, losses\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "#File = 1\n",
    "#prFileName = 'dataRssi_at_%d.txt'%File\n",
    "#dirName = '/home/lyt/gnss_wifi/gnss/20201022/indoor/wifi/'\n",
    "#outputname = 'outplot/1out_in'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datas = glob.glob('20201203/wifi/dataRssi_at_*.txt')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "datas[0].split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "load_data = np.loadtxt(datas[0])\n",
    "m = load_data[:,-15:-12][0]/100\n",
    "o = load_data[:,-12:-9][0]/100\n",
    "a = load_data[:,-9:-6][0]/100\n",
    "g = load_data[:,-6:-3][0]/100\n",
    "gra = load_data[:,-3:][0]/100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getRotationMatrix(gra,m):\n",
    "    Ax = gra[0]\n",
    "    Ay = gra[1]\n",
    "    Az = gra[2]\n",
    "    Ex = m[0]\n",
    "    Ey = m[1]\n",
    "    Ez = m[2]\n",
    "    Hx = Ey*Az - Ez*Ay\n",
    "    Hy = Ez*Ax - Ex*Az\n",
    "    Hz = Ex*Ay - Ey*Ax\n",
    "    normH = np.sqrt(Hx*Hx + Hy*Hy + Hz*Hz)\n",
    "    if normH < 0.1:\n",
    "        return False\n",
    "    invH = 1.0 / normH\n",
    "    Hx *= invH\n",
    "    Hy *= invH\n",
    "    Hz *= invH\n",
    "    invA = 1.0 / np.sqrt(Ax*Ax + Ay*Ay + Az*Az)\n",
    "    Ax *= invA\n",
    "    Ay *= invA\n",
    "    Az *= invA\n",
    "    Mx = Ay*Hz - Az*Hy\n",
    "    My = Az*Hx - Ax*Hz\n",
    "    Mz = Ax*Hy - Ay*Hx\n",
    "    R = np.array([Hx,Hy,Hz,Mx,My,Mz,Ax,Ay,Az])\n",
    "    return R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "train_label = []\n",
    "for data in datas:\n",
    "    load_data = np.loadtxt(data)#f.read()\n",
    "    gras = load_data[:,-3:]/100\n",
    "    ms = load_data[:,-15:-12]/100\n",
    "    for gra,m in zip(gras,ms):\n",
    "        R = getRotationMatrix(gra,m)\n",
    "        gm = np.dot(R.reshape(3,3),m.reshape(3,1))\n",
    "        train_data.append(gm)\n",
    "        train_label.append(data.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0])\n",
    "\n",
    "\n",
    "train_data = np.array(train_data).astype('float32')\n",
    "train_data = train_data.reshape(-1,3)\n",
    "train_data = (train_data - train_data.mean(axis=0)) / train_data.std(axis = 0)\n",
    "train_label = np.array(pd.get_dummies(train_label)).astype('float32')\n",
    "#train_label = train_label.reshape(len(train_label),1)\n",
    "train_val_split = np.random.rand(len(train_data)) < 0.70\n",
    "train_x = train_data[train_val_split]\n",
    "train_y = train_label[train_val_split]\n",
    "val_x = train_data[~train_val_split]\n",
    "val_y = train_label[~train_val_split]\n",
    "BUFFER_SIZE = train_x.shape[0]\n",
    "BATCH_SIZE = train_x.shape[0]\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x,train_y))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_x,val_x)).batch(len(val_x))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DenseTranspose(tf.keras.layers.Layer):\n",
    "    def __init__(self, dense, activation=None, **kwargs):\n",
    "        self.dense = dense\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        super().__init__(**kwargs)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.biases = self.add_weight(name='bias',shape=[self.dense.input_shape[-1]],initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "    def call(self, inputs):\n",
    "        z = tf.matmul(inputs, self.dense.weights[0], transpose_b = True)\n",
    "        return self.activation(z + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mirrored_strategy = tf.distribute.MirroredStrategy(devices=[\"/gpu:0\",\"/gpu:1\"])\n",
    "#with mirrored_strategy.scope():\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(3), name='input_layer1')\n",
    "#flatten = tf.keras.layers.Flatten()(input)\n",
    "dense1 = tf.keras.layers.Dense(8, activation='relu')\n",
    "dense2 = tf.keras.layers.Dense(12, activation='relu')\n",
    "dense3 = tf.keras.layers.Dense(16, activation='relu')\n",
    "model_encoder = dense1(input)\n",
    "model_encoder = dense2(model_encoder)\n",
    "model_encoder = dense3(model_encoder)\n",
    "model_down = tf.keras.Model(inputs=[input], outputs=model_encoder,name = \"encoder\")#input1, input2,input3,input4,input5,input6,input7,input8,input9,input10\n",
    "#model_down.summary()\n",
    "#input_encoder = tf.keras.layers.Input(shape=(15), name='input_layer2')\n",
    "input2 = tf.keras.layers.Input(shape=(16), name='input_layer2')\n",
    "model_decoder = DenseTranspose(dense3, activation = 'relu')(input2)\n",
    "model_decoder = DenseTranspose(dense2, activation = 'relu')(model_decoder)\n",
    "model_decoder = DenseTranspose(dense1, activation = 'relu')(model_decoder)\n",
    "model_up = tf.keras.Model(inputs=[input2], outputs=model_decoder,name = \"decoder\")\n",
    "\n",
    "#model_encoder_decoder.summary()\n",
    "input3 = tf.keras.layers.Input(shape=(16), name='input_layer3')\n",
    "model_ann = tf.keras.layers.Dense(16, activation='relu')(input3)\n",
    "model_ann = tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None)(model_ann)\n",
    "model_ann = tf.keras.layers.Dense(16, activation='relu')(model_ann)\n",
    "model_ann = tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None)(model_ann)\n",
    "model_ann = tf.keras.layers.Dense(16, activation='relu')(model_ann)\n",
    "#model_ann = tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None)(model_ann)\n",
    "#model_ann = tf.keras.layers.Dense(16, activation='relu')(model_ann)\n",
    "#model_ann = tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None)(model_ann)\n",
    "#model_ann = tf.keras.layers.Dense(16, activation='relu')(model_ann)\n",
    "#model_ann = tf.keras.layers.Dropout(0.5, noise_shape=None, seed=None)(model_ann)\n",
    "model_ann = tf.keras.layers.Dense(50, activation='softmax')(model_ann)\n",
    "model_ANN = tf.keras.Model(inputs=[input3], outputs=model_ann,name = \"ann\")\n",
    "\n",
    "input_full = tf.keras.layers.Input(shape=(3), name='input_layer4')\n",
    "encoder_out = model_down(input_full)\n",
    "decoder_out = model_up(encoder_out)\n",
    "ann_out = model_ANN(encoder_out)\n",
    "#model_encoder_decoder_ann = tf.keras.Model(inputs=[input_full],outputs=[decoder_out],name = 'encoder_decoder_ann')\n",
    "model_encoder_decoder_ann = tf.keras.Model(inputs=[input_full],outputs=[decoder_out,ann_out],name = 'encoder_decoder_ann')\n",
    "#optimizer = tf.keras.optimizers.SGD(learning_rate=1e-2, momentum=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"encoder_decoder_ann\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_layer4 (InputLayer)       [(None, 3)]          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder (Model)                 (None, 16)           348         input_layer4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "decoder (Model)                 (None, 3)            371         encoder[1][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "ann (Model)                     (None, 50)           1666        encoder[1][0]                    \n",
      "==================================================================================================\n",
      "Total params: 2,037\n",
      "Trainable params: 2,037\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_encoder_decoder_ann.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model_encoder_decoder_ann.trainable_variables)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 8)\n",
      "(8,)\n",
      "(8, 12)\n",
      "(12,)\n",
      "(12, 16)\n",
      "(16,)\n",
      "(12,)\n",
      "(8,)\n",
      "(3,)\n",
      "(16, 16)\n",
      "(16,)\n",
      "(16, 16)\n",
      "(16,)\n",
      "(16, 16)\n",
      "(16,)\n",
      "(16, 50)\n",
      "(50,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(17):\n",
    "    print(model_encoder_decoder_ann.trainable_variables[i].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "shared_vars = model_encoder_decoder_ann.trainable_variables[:6]\n",
    "decode_vars = model_encoder_decoder_ann.trainable_variables[6:9]\n",
    "ann_vars = model_encoder_decoder_ann.trainable_variables[9:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(output,t_x,t_y):\n",
    "    #print(\"in loss\")\n",
    "    output_AE , output_label = output\n",
    "    #output_AE = output\n",
    "    mse = losses.MeanSquaredError()\n",
    "    AE_loss = mse(t_x,output_AE)\n",
    "    ann_loss =losses.categorical_crossentropy(t_y,output_label)\n",
    "    total_loss = AE_loss*100 + ann_loss\n",
    "    \n",
    "    return AE_loss,ann_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate_A = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "initial_learning_rate=1e-4, decay_steps=5000, decay_rate=0.9)\n",
    "optimizer_A = tf.optimizers.SGD(learning_rate=learning_rate_A , momentum=1e-5)\n",
    "learning_rate_B = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "initial_learning_rate=1e-3, decay_steps=10000, decay_rate=0.8)\n",
    "optimizer_B = tf.optimizers.Adam(learning_rate=1e-3)#learning_rate_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@tf.function\n",
    "\n",
    "def train_step(t_x,t_y):\n",
    "  \n",
    "    with tf.GradientTape() as AE_tape,tf.GradientTape() as ANN_tape:\n",
    "        output = model_encoder_decoder_ann(t_x, training=True)\n",
    "        #AE_loss = model_loss(output,t_o,t_y)\n",
    "        AE_loss,ANN_loss = model_loss(output,t_x,t_y)\n",
    "        #gradients = tape.gradient(total_loss, shared_vars+decode_vars)\n",
    "        #optimizer_A.apply_gradients(zip(gradients, shared_vars+decode_vars))\n",
    "\n",
    "    if np.random.rand() < 0.5:\n",
    "        #print(\"AE\")\n",
    "        gradients_AE = AE_tape.gradient(AE_loss, shared_vars+decode_vars)\n",
    "        #gradients_AE = [tf.clip_by_value(g, -1,1) for g in gradients_AE]\n",
    "\n",
    "        #print(\"AE gradient : \",gradients_AE)\n",
    "        optimizer_A.apply_gradients(zip(gradients_AE, shared_vars+decode_vars))\n",
    "    \n",
    "    else:\n",
    "        #print(\"ANN\")\n",
    "        gradients_ANN = ANN_tape.gradient(ANN_loss, shared_vars+ann_vars)\n",
    "        #print(\"ANN gradient : \",gradients_ANN)\n",
    "        #gradients_ANN = [tf.clip_by_value(g, -1,1) for g in gradients_ANN] \n",
    "        optimizer_B.apply_gradients(zip(gradients_ANN, shared_vars+ann_vars))\n",
    "    \n",
    "    return np.array(AE_loss).mean(),np.array(ANN_loss).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_dir = './magnetic_checkpoints/checkpoints_1222'\n",
    "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_dropout_model_{epoch}\")\n",
    "checkpoint = tf.train.Checkpoint(optimizerA=optimizer_A,\n",
    "                                 optimizerB=optimizer_B,\n",
    "                                 model_encoder_decoder_ann=model_encoder_decoder_ann,\n",
    "                                 model_down=model_down)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrintLR(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs=None):\n",
    "    print('\\nLearning rate for epoch {} is {}'.format(epoch + 1,\n",
    "                                                      model_encoder_decoder.optimizer.lr.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validation(v_x,v_y):\n",
    "    output = model_encoder_decoder_ann(v_x)\n",
    "    #output_AE = output\n",
    "    output_AE , output_label = output\n",
    "    mse = losses.MeanSquaredError()\n",
    "    AE_loss = mse(v_x,output_AE)\n",
    "    ann_loss = losses.categorical_crossentropy(v_y,output_label)\n",
    "    total_loss = AE_loss*100 + ann_loss\n",
    "    #print(output_label[200])\n",
    "    #print(v_y[200])\n",
    "    #print(ann_loss)\n",
    "    #print(\"AE loss : {},\".format(np.array(AE_loss).mean()))\n",
    "    print(\"AE loss : {}, ANN loss : {}, Total loss : {}\".format(np.array(AE_loss).mean(),np.array(ann_loss).mean(),np.array(total_loss).mean()))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "validation(val_x,val_o,val_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4235, 3)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epochs):\n",
    "  for epoch in range(epochs):\n",
    "    start = time.time()\n",
    "    all_AE = []\n",
    "    all_ANN =[]\n",
    "    for x,y in train_dataset:\n",
    "        #AE_loss = train_step(x,y)\n",
    "        AE_loss,ANN_loss = train_step(x,y)\n",
    "        all_AE.append(AE_loss)\n",
    "        all_ANN.append(ANN_loss)\n",
    "    #print(\"train AE loss : {}\".format(np.array(all_AE).mean()))\n",
    "    print(\"train AE loss : {}, train ANN loss : {}\".format(np.array(all_AE).mean(),np.array(all_ANN).mean()))\n",
    "    validation(val_x,val_y)\n",
    "    checkpoint.save(file_prefix=checkpoint_prefix)\n",
    "    print(\"learning rate A : \",optimizer_A._decayed_lr(tf.float32))\n",
    "    print(\"learning rate B : \",optimizer_B._decayed_lr(tf.float32))\n",
    "    print(f'Time for epoch {epoch + 1} is {time.time() - start:.4f} sec')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train AE loss : 0.9160338044166565, train ANN loss : 3.9122133255004883\n",
      "AE loss : 0.9196826815605164, ANN loss : 3.9094488620758057, Total loss : 95.87772369384766\n",
      "learning rate A :  tf.Tensor(1e-04, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1 is 0.5819 sec\n",
      "train AE loss : 0.9168521165847778, train ANN loss : 3.911435127258301\n",
      "AE loss : 0.9196534156799316, ANN loss : 3.9094483852386475, Total loss : 95.87479400634766\n",
      "learning rate A :  tf.Tensor(9.999789e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 2 is 0.0975 sec\n",
      "train AE loss : 0.9168226718902588, train ANN loss : 3.911229133605957\n",
      "AE loss : 0.9204185605049133, ANN loss : 3.9082894325256348, Total loss : 95.95014953613281\n",
      "learning rate A :  tf.Tensor(9.999789e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 3 is 0.0823 sec\n",
      "train AE loss : 0.9175580143928528, train ANN loss : 3.909764528274536\n",
      "AE loss : 0.9203894734382629, ANN loss : 3.9082884788513184, Total loss : 95.9472427368164\n",
      "learning rate A :  tf.Tensor(9.999578e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 4 is 0.0781 sec\n",
      "train AE loss : 0.9175288677215576, train ANN loss : 3.908203125\n",
      "AE loss : 0.9203603863716125, ANN loss : 3.9082884788513184, Total loss : 95.9443359375\n",
      "learning rate A :  tf.Tensor(9.9993675e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 5 is 0.0789 sec\n",
      "train AE loss : 0.9174997806549072, train ANN loss : 3.909332752227783\n",
      "AE loss : 0.9209750294685364, ANN loss : 3.907166004180908, Total loss : 96.0046615600586\n",
      "learning rate A :  tf.Tensor(9.9993675e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 6 is 0.0820 sec\n",
      "train AE loss : 0.9181037545204163, train ANN loss : 3.9073150157928467\n",
      "AE loss : 0.9209461212158203, ANN loss : 3.907166004180908, Total loss : 96.00178527832031\n",
      "learning rate A :  tf.Tensor(9.9991565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 7 is 0.0781 sec\n",
      "train AE loss : 0.9180746674537659, train ANN loss : 3.90739369392395\n",
      "AE loss : 0.9209170937538147, ANN loss : 3.907166004180908, Total loss : 95.9988784790039\n",
      "learning rate A :  tf.Tensor(9.998946e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 8 is 0.0781 sec\n",
      "train AE loss : 0.9180455803871155, train ANN loss : 3.907881736755371\n",
      "AE loss : 0.9214565753936768, ANN loss : 3.905996799468994, Total loss : 96.05165100097656\n",
      "learning rate A :  tf.Tensor(9.998946e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 9 is 0.0805 sec\n",
      "train AE loss : 0.9185905456542969, train ANN loss : 3.906724214553833\n",
      "AE loss : 0.9214279651641846, ANN loss : 3.905996799468994, Total loss : 96.04878997802734\n",
      "learning rate A :  tf.Tensor(9.998735e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 10 is 0.0781 sec\n",
      "train AE loss : 0.9185617566108704, train ANN loss : 3.906782388687134\n",
      "AE loss : 0.9219245314598083, ANN loss : 3.9048635959625244, Total loss : 96.0973129272461\n",
      "learning rate A :  tf.Tensor(9.998735e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 11 is 0.0801 sec\n",
      "train AE loss : 0.919070839881897, train ANN loss : 3.9059290885925293\n",
      "AE loss : 0.9218960404396057, ANN loss : 3.9048635959625244, Total loss : 96.09446716308594\n",
      "learning rate A :  tf.Tensor(9.998524e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 12 is 0.0784 sec\n",
      "train AE loss : 0.9190421104431152, train ANN loss : 3.905747413635254\n",
      "AE loss : 0.9218674302101135, ANN loss : 3.904863119125366, Total loss : 96.09161376953125\n",
      "learning rate A :  tf.Tensor(9.998313e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 13 is 0.0781 sec\n",
      "train AE loss : 0.9190134406089783, train ANN loss : 3.905186653137207\n",
      "AE loss : 0.9223962426185608, ANN loss : 3.9037914276123047, Total loss : 96.1434097290039\n",
      "learning rate A :  tf.Tensor(9.998313e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 14 is 0.0798 sec\n",
      "train AE loss : 0.9195567965507507, train ANN loss : 3.904850721359253\n",
      "AE loss : 0.9223679900169373, ANN loss : 3.9037909507751465, Total loss : 96.1406021118164\n",
      "learning rate A :  tf.Tensor(9.998103e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 15 is 0.0790 sec\n",
      "train AE loss : 0.9195283055305481, train ANN loss : 3.903294324874878\n",
      "AE loss : 0.9228323698043823, ANN loss : 3.902782917022705, Total loss : 96.18601989746094\n",
      "learning rate A :  tf.Tensor(9.998103e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 16 is 0.0808 sec\n",
      "train AE loss : 0.9200080037117004, train ANN loss : 3.9037301540374756\n",
      "AE loss : 0.9233130812644958, ANN loss : 3.9017903804779053, Total loss : 96.23310089111328\n",
      "learning rate A :  tf.Tensor(9.998103e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 17 is 0.0788 sec\n",
      "train AE loss : 0.920504629611969, train ANN loss : 3.8990466594696045\n",
      "AE loss : 0.9237650036811829, ANN loss : 3.9007503986358643, Total loss : 96.27725982666016\n",
      "learning rate A :  tf.Tensor(9.998103e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 18 is 0.0819 sec\n",
      "train AE loss : 0.9209830164909363, train ANN loss : 3.8993899822235107\n",
      "AE loss : 0.9241982102394104, ANN loss : 3.8996565341949463, Total loss : 96.3194808959961\n",
      "learning rate A :  tf.Tensor(9.998103e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 19 is 0.0796 sec\n",
      "train AE loss : 0.9214462637901306, train ANN loss : 3.8989298343658447\n",
      "AE loss : 0.924170970916748, ANN loss : 3.899656057357788, Total loss : 96.3167495727539\n",
      "learning rate A :  tf.Tensor(9.9978926e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 20 is 0.0785 sec\n",
      "train AE loss : 0.9214189648628235, train ANN loss : 3.898230791091919\n",
      "AE loss : 0.9241437315940857, ANN loss : 3.8996565341949463, Total loss : 96.31403350830078\n",
      "learning rate A :  tf.Tensor(9.9976816e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 21 is 0.0785 sec\n",
      "train AE loss : 0.921391487121582, train ANN loss : 3.898573398590088\n",
      "AE loss : 0.9245569109916687, ANN loss : 3.8985214233398438, Total loss : 96.35420989990234\n",
      "learning rate A :  tf.Tensor(9.9976816e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 22 is 0.0793 sec\n",
      "train AE loss : 0.9218244552612305, train ANN loss : 3.897123098373413\n",
      "AE loss : 0.9245299100875854, ANN loss : 3.8985214233398438, Total loss : 96.35150909423828\n",
      "learning rate A :  tf.Tensor(9.997471e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 23 is 0.0778 sec\n",
      "train AE loss : 0.9217970967292786, train ANN loss : 3.896641731262207\n",
      "AE loss : 0.9245027899742126, ANN loss : 3.8985214233398438, Total loss : 96.34880065917969\n",
      "learning rate A :  tf.Tensor(9.99726e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 24 is 0.0799 sec\n",
      "train AE loss : 0.9217696785926819, train ANN loss : 3.8979249000549316\n",
      "AE loss : 0.9249312281608582, ANN loss : 3.8973731994628906, Total loss : 96.39049530029297\n",
      "learning rate A :  tf.Tensor(9.99726e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 25 is 0.0795 sec\n",
      "train AE loss : 0.9222156405448914, train ANN loss : 3.8968584537506104\n",
      "AE loss : 0.9249041676521301, ANN loss : 3.8973727226257324, Total loss : 96.38778686523438\n",
      "learning rate A :  tf.Tensor(9.99705e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 26 is 0.0780 sec\n",
      "train AE loss : 0.9221883416175842, train ANN loss : 3.8957173824310303\n",
      "AE loss : 0.9248773455619812, ANN loss : 3.8973727226257324, Total loss : 96.3851089477539\n",
      "learning rate A :  tf.Tensor(9.996839e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 27 is 0.0788 sec\n",
      "train AE loss : 0.9221611618995667, train ANN loss : 3.897437572479248\n",
      "AE loss : 0.9252870678901672, ANN loss : 3.8962228298187256, Total loss : 96.42493438720703\n",
      "learning rate A :  tf.Tensor(9.996839e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 28 is 0.0796 sec\n",
      "train AE loss : 0.9225883483886719, train ANN loss : 3.893442153930664\n",
      "AE loss : 0.9252602458000183, ANN loss : 3.8962223529815674, Total loss : 96.4222412109375\n",
      "learning rate A :  tf.Tensor(9.996629e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 29 is 0.0776 sec\n",
      "train AE loss : 0.9225611686706543, train ANN loss : 3.895329713821411\n",
      "AE loss : 0.9252334833145142, ANN loss : 3.8962223529815674, Total loss : 96.41957092285156\n",
      "learning rate A :  tf.Tensor(9.996418e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 30 is 0.0787 sec\n",
      "train AE loss : 0.9225339889526367, train ANN loss : 3.894517421722412\n",
      "AE loss : 0.9252067804336548, ANN loss : 3.8962223529815674, Total loss : 96.41690063476562\n",
      "learning rate A :  tf.Tensor(9.996207e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 31 is 0.0784 sec\n",
      "train AE loss : 0.9225069284439087, train ANN loss : 3.8933842182159424\n",
      "AE loss : 0.9251798391342163, ANN loss : 3.896221876144409, Total loss : 96.41419982910156\n",
      "learning rate A :  tf.Tensor(9.9959965e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 32 is 0.0783 sec\n",
      "train AE loss : 0.9224798083305359, train ANN loss : 3.895803451538086\n",
      "AE loss : 0.9256314039230347, ANN loss : 3.895042657852173, Total loss : 96.45817565917969\n",
      "learning rate A :  tf.Tensor(9.9959965e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 33 is 0.0817 sec\n",
      "train AE loss : 0.922954261302948, train ANN loss : 3.8934335708618164\n",
      "AE loss : 0.9256047606468201, ANN loss : 3.8950421810150146, Total loss : 96.45552062988281\n",
      "learning rate A :  tf.Tensor(9.995786e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 34 is 0.0778 sec\n",
      "train AE loss : 0.9229272603988647, train ANN loss : 3.894383668899536\n",
      "AE loss : 0.9260644316673279, ANN loss : 3.893810987472534, Total loss : 96.50025939941406\n",
      "learning rate A :  tf.Tensor(9.995786e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 35 is 0.0803 sec\n",
      "train AE loss : 0.9234153628349304, train ANN loss : 3.893012046813965\n",
      "AE loss : 0.9260377287864685, ANN loss : 3.893810987472534, Total loss : 96.4975814819336\n",
      "learning rate A :  tf.Tensor(9.995575e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 36 is 0.0788 sec\n",
      "train AE loss : 0.9233883619308472, train ANN loss : 3.891530990600586\n",
      "AE loss : 0.9260110259056091, ANN loss : 3.893810987472534, Total loss : 96.49491882324219\n",
      "learning rate A :  tf.Tensor(9.995365e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 37 is 0.0786 sec\n",
      "train AE loss : 0.9233613610267639, train ANN loss : 3.8935654163360596\n",
      "AE loss : 0.9259843230247498, ANN loss : 3.893810510635376, Total loss : 96.49224853515625\n",
      "learning rate A :  tf.Tensor(9.995155e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 38 is 0.0778 sec\n",
      "train AE loss : 0.9233343601226807, train ANN loss : 3.8918871879577637\n",
      "AE loss : 0.9264315962791443, ANN loss : 3.892516851425171, Total loss : 96.5356674194336\n",
      "learning rate A :  tf.Tensor(9.995155e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 39 is 0.0821 sec\n",
      "train AE loss : 0.9238185286521912, train ANN loss : 3.8924951553344727\n",
      "AE loss : 0.9268672466278076, ANN loss : 3.8911590576171875, Total loss : 96.577880859375\n",
      "learning rate A :  tf.Tensor(9.995155e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 40 is 0.0798 sec\n",
      "train AE loss : 0.9242943525314331, train ANN loss : 3.8899266719818115\n",
      "AE loss : 0.9268405437469482, ANN loss : 3.8911590576171875, Total loss : 96.57520294189453\n",
      "learning rate A :  tf.Tensor(9.994944e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 41 is 0.0784 sec\n",
      "train AE loss : 0.9242674112319946, train ANN loss : 3.8894424438476562\n",
      "AE loss : 0.9272575378417969, ANN loss : 3.8897366523742676, Total loss : 96.61549377441406\n",
      "learning rate A :  tf.Tensor(9.994944e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 42 is 0.0812 sec\n",
      "train AE loss : 0.9247240424156189, train ANN loss : 3.887507915496826\n",
      "AE loss : 0.9276837110519409, ANN loss : 3.8882453441619873, Total loss : 96.65660858154297\n",
      "learning rate A :  tf.Tensor(9.994944e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 43 is 0.0801 sec\n",
      "train AE loss : 0.9251877665519714, train ANN loss : 3.887022018432617\n",
      "AE loss : 0.9276567697525024, ANN loss : 3.8882453441619873, Total loss : 96.65392303466797\n",
      "learning rate A :  tf.Tensor(9.9947334e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 44 is 0.0783 sec\n",
      "train AE loss : 0.9251605868339539, train ANN loss : 3.886502742767334\n",
      "AE loss : 0.9280757904052734, ANN loss : 3.886691093444824, Total loss : 96.69427490234375\n",
      "learning rate A :  tf.Tensor(9.9947334e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 45 is 0.0810 sec\n",
      "train AE loss : 0.9256088137626648, train ANN loss : 3.8851804733276367\n",
      "AE loss : 0.9280487895011902, ANN loss : 3.886691093444824, Total loss : 96.69157409667969\n",
      "learning rate A :  tf.Tensor(9.9945224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 46 is 0.0787 sec\n",
      "train AE loss : 0.9255817532539368, train ANN loss : 3.884666681289673\n",
      "AE loss : 0.9284644722938538, ANN loss : 3.8850765228271484, Total loss : 96.73152160644531\n",
      "learning rate A :  tf.Tensor(9.9945224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 47 is 0.0807 sec\n",
      "train AE loss : 0.9260240197181702, train ANN loss : 3.8843512535095215\n",
      "AE loss : 0.9284374117851257, ANN loss : 3.8850765228271484, Total loss : 96.72881317138672\n",
      "learning rate A :  tf.Tensor(9.9943114e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 48 is 0.0785 sec\n",
      "train AE loss : 0.925996720790863, train ANN loss : 3.884026288986206\n",
      "AE loss : 0.9284104108810425, ANN loss : 3.8850765228271484, Total loss : 96.72611999511719\n",
      "learning rate A :  tf.Tensor(9.994101e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 49 is 0.0794 sec\n",
      "train AE loss : 0.9259694218635559, train ANN loss : 3.884342670440674\n",
      "AE loss : 0.9288150072097778, ANN loss : 3.883396863937378, Total loss : 96.764892578125\n",
      "learning rate A :  tf.Tensor(9.994101e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 50 is 0.0801 sec\n",
      "train AE loss : 0.9263980984687805, train ANN loss : 3.8808512687683105\n",
      "AE loss : 0.9287880063056946, ANN loss : 3.883396863937378, Total loss : 96.76219940185547\n",
      "learning rate A :  tf.Tensor(9.993891e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 51 is 0.0796 sec\n",
      "train AE loss : 0.9263709187507629, train ANN loss : 3.8799784183502197\n",
      "AE loss : 0.9291790127754211, ANN loss : 3.8816282749176025, Total loss : 96.79953002929688\n",
      "learning rate A :  tf.Tensor(9.993891e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 52 is 0.0799 sec\n",
      "train AE loss : 0.926791250705719, train ANN loss : 3.879976511001587\n",
      "AE loss : 0.929152250289917, ANN loss : 3.8816277980804443, Total loss : 96.7968521118164\n",
      "learning rate A :  tf.Tensor(9.99368e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 53 is 0.0786 sec\n",
      "train AE loss : 0.926764190196991, train ANN loss : 3.879884719848633\n",
      "AE loss : 0.9295371770858765, ANN loss : 3.879763126373291, Total loss : 96.83348846435547\n",
      "learning rate A :  tf.Tensor(9.99368e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 54 is 0.0810 sec\n",
      "train AE loss : 0.9271795153617859, train ANN loss : 3.878230333328247\n",
      "AE loss : 0.9299121499061584, ANN loss : 3.877798080444336, Total loss : 96.8690185546875\n",
      "learning rate A :  tf.Tensor(9.99368e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 55 is 0.0805 sec\n",
      "train AE loss : 0.9275780916213989, train ANN loss : 3.87585186958313\n",
      "AE loss : 0.9298855662345886, ANN loss : 3.8777976036071777, Total loss : 96.86634826660156\n",
      "learning rate A :  tf.Tensor(9.9934696e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 56 is 0.0784 sec\n",
      "train AE loss : 0.9275512099266052, train ANN loss : 3.875621795654297\n",
      "AE loss : 0.9298590421676636, ANN loss : 3.8777976036071777, Total loss : 96.86369323730469\n",
      "learning rate A :  tf.Tensor(9.993259e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 57 is 0.0882 sec\n",
      "train AE loss : 0.9275243282318115, train ANN loss : 3.8758199214935303\n",
      "AE loss : 0.9302360415458679, ANN loss : 3.87571120262146, Total loss : 96.89932250976562\n",
      "learning rate A :  tf.Tensor(9.993259e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 58 is 0.0794 sec\n",
      "train AE loss : 0.9279274344444275, train ANN loss : 3.8732869625091553\n",
      "AE loss : 0.9306196570396423, ANN loss : 3.873488187789917, Total loss : 96.93545532226562\n",
      "learning rate A :  tf.Tensor(9.993259e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 59 is 0.0795 sec\n",
      "train AE loss : 0.9283387064933777, train ANN loss : 3.8699791431427\n",
      "AE loss : 0.9305931925773621, ANN loss : 3.873488187789917, Total loss : 96.93280792236328\n",
      "learning rate A :  tf.Tensor(9.993048e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 60 is 0.0784 sec\n",
      "train AE loss : 0.9283120036125183, train ANN loss : 3.8704795837402344\n",
      "AE loss : 0.930566668510437, ANN loss : 3.873488187789917, Total loss : 96.9301528930664\n",
      "learning rate A :  tf.Tensor(9.992837e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 61 is 0.0784 sec\n",
      "train AE loss : 0.9282852411270142, train ANN loss : 3.871047258377075\n",
      "AE loss : 0.9305402636528015, ANN loss : 3.873488664627075, Total loss : 96.92750549316406\n",
      "learning rate A :  tf.Tensor(9.992627e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 62 is 0.0787 sec\n",
      "train AE loss : 0.9282585382461548, train ANN loss : 3.871548891067505\n",
      "AE loss : 0.9309258460998535, ANN loss : 3.8711259365081787, Total loss : 96.96370697021484\n",
      "learning rate A :  tf.Tensor(9.992627e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 63 is 0.0792 sec\n",
      "train AE loss : 0.9286653399467468, train ANN loss : 3.8695759773254395\n",
      "AE loss : 0.9313555955886841, ANN loss : 3.8686094284057617, Total loss : 97.00416564941406\n",
      "learning rate A :  tf.Tensor(9.992627e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 64 is 0.0815 sec\n",
      "train AE loss : 0.9291117787361145, train ANN loss : 3.8669307231903076\n",
      "AE loss : 0.9313292503356934, ANN loss : 3.868609666824341, Total loss : 97.00153350830078\n",
      "learning rate A :  tf.Tensor(9.992417e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 65 is 0.0803 sec\n",
      "train AE loss : 0.9290851950645447, train ANN loss : 3.867025852203369\n",
      "AE loss : 0.9313029050827026, ANN loss : 3.8686094284057617, Total loss : 96.9989013671875\n",
      "learning rate A :  tf.Tensor(9.9922065e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 66 is 0.0780 sec\n",
      "train AE loss : 0.9290586113929749, train ANN loss : 3.8657546043395996\n",
      "AE loss : 0.9317571520805359, ANN loss : 3.8659777641296387, Total loss : 97.04169464111328\n",
      "learning rate A :  tf.Tensor(9.9922065e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 67 is 0.0815 sec\n",
      "train AE loss : 0.929531455039978, train ANN loss : 3.8642094135284424\n",
      "AE loss : 0.9322173595428467, ANN loss : 3.8632259368896484, Total loss : 97.08495330810547\n",
      "learning rate A :  tf.Tensor(9.9922065e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 68 is 0.0808 sec\n",
      "train AE loss : 0.9300194382667542, train ANN loss : 3.859039545059204\n",
      "AE loss : 0.9326615929603577, ANN loss : 3.8602871894836426, Total loss : 97.12644958496094\n",
      "learning rate A :  tf.Tensor(9.9922065e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 69 is 0.0798 sec\n",
      "train AE loss : 0.9304891228675842, train ANN loss : 3.857182025909424\n",
      "AE loss : 0.9326353669166565, ANN loss : 3.860287666320801, Total loss : 97.12381744384766\n",
      "learning rate A :  tf.Tensor(9.9919955e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 70 is 0.0774 sec\n",
      "train AE loss : 0.9304623007774353, train ANN loss : 3.860255479812622\n",
      "AE loss : 0.932608962059021, ANN loss : 3.860287666320801, Total loss : 97.12118530273438\n",
      "learning rate A :  tf.Tensor(9.991785e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 71 is 0.0778 sec\n",
      "train AE loss : 0.9304353594779968, train ANN loss : 3.8594870567321777\n",
      "AE loss : 0.9330824017524719, ANN loss : 3.8572041988372803, Total loss : 97.16544342041016\n",
      "learning rate A :  tf.Tensor(9.991785e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 72 is 0.0800 sec\n",
      "train AE loss : 0.9309254288673401, train ANN loss : 3.8533599376678467\n",
      "AE loss : 0.9330560564994812, ANN loss : 3.8572046756744385, Total loss : 97.16281127929688\n",
      "learning rate A :  tf.Tensor(9.991575e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 73 is 0.0774 sec\n",
      "train AE loss : 0.9308985471725464, train ANN loss : 3.8549249172210693\n",
      "AE loss : 0.9330297708511353, ANN loss : 3.8572046756744385, Total loss : 97.16018676757812\n",
      "learning rate A :  tf.Tensor(9.991364e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 74 is 0.0787 sec\n",
      "train AE loss : 0.930871844291687, train ANN loss : 3.8566181659698486\n",
      "AE loss : 0.9330033659934998, ANN loss : 3.8572049140930176, Total loss : 97.15754699707031\n",
      "learning rate A :  tf.Tensor(9.991154e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 75 is 0.0775 sec\n",
      "train AE loss : 0.9308449625968933, train ANN loss : 3.8589000701904297\n",
      "AE loss : 0.9329771995544434, ANN loss : 3.8572051525115967, Total loss : 97.1549301147461\n",
      "learning rate A :  tf.Tensor(9.9909426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 76 is 0.0779 sec\n",
      "train AE loss : 0.9308182001113892, train ANN loss : 3.8564908504486084\n",
      "AE loss : 0.9334787726402283, ANN loss : 3.8539865016937256, Total loss : 97.20186614990234\n",
      "learning rate A :  tf.Tensor(9.9909426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 77 is 0.0805 sec\n",
      "train AE loss : 0.9313282370567322, train ANN loss : 3.853529691696167\n",
      "AE loss : 0.9339873194694519, ANN loss : 3.8506157398223877, Total loss : 97.24935150146484\n",
      "learning rate A :  tf.Tensor(9.9909426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 78 is 0.0894 sec\n",
      "train AE loss : 0.9318422675132751, train ANN loss : 3.8487539291381836\n",
      "AE loss : 0.9344984889030457, ANN loss : 3.8470866680145264, Total loss : 97.29694366455078\n",
      "learning rate A :  tf.Tensor(9.9909426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 79 is 0.0795 sec\n",
      "train AE loss : 0.9323598742485046, train ANN loss : 3.8466544151306152\n",
      "AE loss : 0.9349789023399353, ANN loss : 3.8433778285980225, Total loss : 97.34126281738281\n",
      "learning rate A :  tf.Tensor(9.9909426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 80 is 0.0794 sec\n",
      "train AE loss : 0.9328491687774658, train ANN loss : 3.842392683029175\n",
      "AE loss : 0.9354782104492188, ANN loss : 3.8395016193389893, Total loss : 97.38732147216797\n",
      "learning rate A :  tf.Tensor(9.9909426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 81 is 0.0796 sec\n",
      "train AE loss : 0.9333513975143433, train ANN loss : 3.8397955894470215\n",
      "AE loss : 0.9359154105186462, ANN loss : 3.835442304611206, Total loss : 97.4269790649414\n",
      "learning rate A :  tf.Tensor(9.9909426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 82 is 0.0808 sec\n",
      "train AE loss : 0.9337967038154602, train ANN loss : 3.8355555534362793\n",
      "AE loss : 0.9363772869110107, ANN loss : 3.8311591148376465, Total loss : 97.46887969970703\n",
      "learning rate A :  tf.Tensor(9.9909426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 83 is 0.0796 sec\n",
      "train AE loss : 0.9342649579048157, train ANN loss : 3.8343796730041504\n",
      "AE loss : 0.9368019700050354, ANN loss : 3.826663017272949, Total loss : 97.5068588256836\n",
      "learning rate A :  tf.Tensor(9.9909426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 84 is 0.0800 sec\n",
      "train AE loss : 0.9346974492073059, train ANN loss : 3.829129219055176\n",
      "AE loss : 0.936775267124176, ANN loss : 3.8266637325286865, Total loss : 97.50418853759766\n",
      "learning rate A :  tf.Tensor(9.990732e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 85 is 0.0787 sec\n",
      "train AE loss : 0.9346701502799988, train ANN loss : 3.826714038848877\n",
      "AE loss : 0.9371987581253052, ANN loss : 3.8219544887542725, Total loss : 97.54183197021484\n",
      "learning rate A :  tf.Tensor(9.990732e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 86 is 0.0804 sec\n",
      "train AE loss : 0.9351038932800293, train ANN loss : 3.8227787017822266\n",
      "AE loss : 0.93759685754776, ANN loss : 3.817056894302368, Total loss : 97.57674407958984\n",
      "learning rate A :  tf.Tensor(9.990732e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 87 is 0.0805 sec\n",
      "train AE loss : 0.9354987740516663, train ANN loss : 3.823140859603882\n",
      "AE loss : 0.9380089044570923, ANN loss : 3.811990737915039, Total loss : 97.61287689208984\n",
      "learning rate A :  tf.Tensor(9.990732e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 88 is 0.0892 sec\n",
      "train AE loss : 0.9359232783317566, train ANN loss : 3.813591241836548\n",
      "AE loss : 0.9384213089942932, ANN loss : 3.8067421913146973, Total loss : 97.64888000488281\n",
      "learning rate A :  tf.Tensor(9.990732e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 89 is 0.0802 sec\n",
      "train AE loss : 0.9363471865653992, train ANN loss : 3.8117856979370117\n",
      "AE loss : 0.9388248324394226, ANN loss : 3.8013341426849365, Total loss : 97.68382263183594\n",
      "learning rate A :  tf.Tensor(9.990732e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 90 is 0.0914 sec\n",
      "train AE loss : 0.9367778301239014, train ANN loss : 3.808793067932129\n",
      "AE loss : 0.9387975931167603, ANN loss : 3.801335334777832, Total loss : 97.68109130859375\n",
      "learning rate A :  tf.Tensor(9.990522e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 91 is 0.0774 sec\n",
      "train AE loss : 0.9367498159408569, train ANN loss : 3.808317184448242\n",
      "AE loss : 0.9392022490501404, ANN loss : 3.7957868576049805, Total loss : 97.71601104736328\n",
      "learning rate A :  tf.Tensor(9.990522e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 92 is 0.0792 sec\n",
      "train AE loss : 0.9371939301490784, train ANN loss : 3.8011281490325928\n",
      "AE loss : 0.9395939707756042, ANN loss : 3.7900848388671875, Total loss : 97.74948120117188\n",
      "learning rate A :  tf.Tensor(9.990522e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 93 is 0.0816 sec\n",
      "train AE loss : 0.9376249313354492, train ANN loss : 3.796536922454834\n",
      "AE loss : 0.9395661354064941, ANN loss : 3.790086269378662, Total loss : 97.74669647216797\n",
      "learning rate A :  tf.Tensor(9.990312e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 94 is 0.0777 sec\n",
      "train AE loss : 0.937596321105957, train ANN loss : 3.7987241744995117\n",
      "AE loss : 0.9395381808280945, ANN loss : 3.790087938308716, Total loss : 97.74390411376953\n",
      "learning rate A :  tf.Tensor(9.9901015e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 95 is 0.0777 sec\n",
      "train AE loss : 0.9375677108764648, train ANN loss : 3.799070358276367\n",
      "AE loss : 0.9399505257606506, ANN loss : 3.784266233444214, Total loss : 97.77932739257812\n",
      "learning rate A :  tf.Tensor(9.9901015e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 96 is 0.0808 sec\n",
      "train AE loss : 0.9380196928977966, train ANN loss : 3.793757438659668\n",
      "AE loss : 0.9403983354568481, ANN loss : 3.778369903564453, Total loss : 97.81820678710938\n",
      "learning rate A :  tf.Tensor(9.9901015e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 97 is 0.0797 sec\n",
      "train AE loss : 0.9385107159614563, train ANN loss : 3.7895569801330566\n",
      "AE loss : 0.9403693675994873, ANN loss : 3.778371810913086, Total loss : 97.8153076171875\n",
      "learning rate A :  tf.Tensor(9.9898905e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 98 is 0.0784 sec\n",
      "train AE loss : 0.938481330871582, train ANN loss : 3.7897708415985107\n",
      "AE loss : 0.9403405785560608, ANN loss : 3.7783730030059814, Total loss : 97.81242370605469\n",
      "learning rate A :  tf.Tensor(9.9896795e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 99 is 0.0784 sec\n",
      "train AE loss : 0.9384518265724182, train ANN loss : 3.788881778717041\n",
      "AE loss : 0.9403115510940552, ANN loss : 3.7783749103546143, Total loss : 97.80953216552734\n",
      "learning rate A :  tf.Tensor(9.989469e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 100 is 0.0782 sec\n",
      "train AE loss : 0.9384223818778992, train ANN loss : 3.7914481163024902\n",
      "AE loss : 0.9408137202262878, ANN loss : 3.772376298904419, Total loss : 97.85375213623047\n",
      "learning rate A :  tf.Tensor(9.989469e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 101 is 0.0795 sec\n",
      "train AE loss : 0.938950777053833, train ANN loss : 3.7827770709991455\n",
      "AE loss : 0.940784215927124, ANN loss : 3.7723782062530518, Total loss : 97.85079956054688\n",
      "learning rate A :  tf.Tensor(9.989259e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 102 is 0.0791 sec\n",
      "train AE loss : 0.9389206767082214, train ANN loss : 3.7882094383239746\n",
      "AE loss : 0.9412990212440491, ANN loss : 3.76631760597229, Total loss : 97.89622497558594\n",
      "learning rate A :  tf.Tensor(9.989259e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 103 is 0.0791 sec\n",
      "train AE loss : 0.9394609928131104, train ANN loss : 3.780256986618042\n",
      "AE loss : 0.9412689208984375, ANN loss : 3.766319990158081, Total loss : 97.8932113647461\n",
      "learning rate A :  tf.Tensor(9.989049e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 104 is 0.0772 sec\n",
      "train AE loss : 0.9394303560256958, train ANN loss : 3.780313730239868\n",
      "AE loss : 0.941814661026001, ANN loss : 3.7602102756500244, Total loss : 97.9416732788086\n",
      "learning rate A :  tf.Tensor(9.989049e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 105 is 0.0802 sec\n",
      "train AE loss : 0.9399919509887695, train ANN loss : 3.77447247505188\n",
      "AE loss : 0.9423877000808716, ANN loss : 3.7540524005889893, Total loss : 97.99282836914062\n",
      "learning rate A :  tf.Tensor(9.989049e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 106 is 0.0886 sec\n",
      "train AE loss : 0.9405837059020996, train ANN loss : 3.7771246433258057\n",
      "AE loss : 0.9423564672470093, ANN loss : 3.7540547847747803, Total loss : 97.98970794677734\n",
      "learning rate A :  tf.Tensor(9.988838e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 107 is 0.0789 sec\n",
      "train AE loss : 0.9405518770217896, train ANN loss : 3.770009994506836\n",
      "AE loss : 0.9429113268852234, ANN loss : 3.747861385345459, Total loss : 98.03899383544922\n",
      "learning rate A :  tf.Tensor(9.988838e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 108 is 0.0789 sec\n",
      "train AE loss : 0.9411287307739258, train ANN loss : 3.7672040462493896\n",
      "AE loss : 0.9428794980049133, ANN loss : 3.74786376953125, Total loss : 98.03581237792969\n",
      "learning rate A :  tf.Tensor(9.988627e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 109 is 0.0777 sec\n",
      "train AE loss : 0.9410961866378784, train ANN loss : 3.7695255279541016\n",
      "AE loss : 0.9434381127357483, ANN loss : 3.7415435314178467, Total loss : 98.08535766601562\n",
      "learning rate A :  tf.Tensor(9.988627e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 110 is 0.0890 sec\n",
      "train AE loss : 0.94168621301651, train ANN loss : 3.7592971324920654\n",
      "AE loss : 0.9434056282043457, ANN loss : 3.7415459156036377, Total loss : 98.08210754394531\n",
      "learning rate A :  tf.Tensor(9.9884164e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 111 is 0.0797 sec\n",
      "train AE loss : 0.9416529536247253, train ANN loss : 3.756838083267212\n",
      "AE loss : 0.9433731436729431, ANN loss : 3.7415482997894287, Total loss : 98.078857421875\n",
      "learning rate A :  tf.Tensor(9.9882054e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 112 is 0.0791 sec\n",
      "train AE loss : 0.9416198134422302, train ANN loss : 3.763284206390381\n",
      "AE loss : 0.9438409805297852, ANN loss : 3.7353551387786865, Total loss : 98.11945343017578\n",
      "learning rate A :  tf.Tensor(9.9882054e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 113 is 0.0804 sec\n",
      "train AE loss : 0.9421388506889343, train ANN loss : 3.7589027881622314\n",
      "AE loss : 0.94424968957901, ANN loss : 3.729198694229126, Total loss : 98.1541748046875\n",
      "learning rate A :  tf.Tensor(9.9882054e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 114 is 0.0790 sec\n",
      "train AE loss : 0.942607581615448, train ANN loss : 3.75105881690979\n",
      "AE loss : 0.9442158341407776, ANN loss : 3.729201316833496, Total loss : 98.1507797241211\n",
      "learning rate A :  tf.Tensor(9.987995e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 115 is 0.0773 sec\n",
      "train AE loss : 0.9425732493400574, train ANN loss : 3.759453535079956\n",
      "AE loss : 0.9441820383071899, ANN loss : 3.729203701019287, Total loss : 98.14740753173828\n",
      "learning rate A :  tf.Tensor(9.987785e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 116 is 0.0782 sec\n",
      "train AE loss : 0.9425389766693115, train ANN loss : 3.7537341117858887\n",
      "AE loss : 0.9446389079093933, ANN loss : 3.72314715385437, Total loss : 98.18704223632812\n",
      "learning rate A :  tf.Tensor(9.987785e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 117 is 0.0797 sec\n",
      "train AE loss : 0.943056583404541, train ANN loss : 3.7513587474823\n",
      "AE loss : 0.9446035027503967, ANN loss : 3.7231497764587402, Total loss : 98.18350219726562\n",
      "learning rate A :  tf.Tensor(9.9875746e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 118 is 0.0781 sec\n",
      "train AE loss : 0.943020761013031, train ANN loss : 3.754412889480591\n",
      "AE loss : 0.9450470209121704, ANN loss : 3.717254400253296, Total loss : 98.22195434570312\n",
      "learning rate A :  tf.Tensor(9.9875746e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 119 is 0.0806 sec\n",
      "train AE loss : 0.9435272812843323, train ANN loss : 3.745924711227417\n",
      "AE loss : 0.9454275369644165, ANN loss : 3.7115001678466797, Total loss : 98.2542495727539\n",
      "learning rate A :  tf.Tensor(9.9875746e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 120 is 0.0809 sec\n",
      "train AE loss : 0.9439701437950134, train ANN loss : 3.7410240173339844\n",
      "AE loss : 0.9457470178604126, ANN loss : 3.7058420181274414, Total loss : 98.28053283691406\n",
      "learning rate A :  tf.Tensor(9.9875746e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 121 is 0.0795 sec\n",
      "train AE loss : 0.9443644285202026, train ANN loss : 3.7386438846588135\n",
      "AE loss : 0.9457098245620728, ANN loss : 3.7058448791503906, Total loss : 98.2768325805664\n",
      "learning rate A :  tf.Tensor(9.987364e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 122 is 0.0786 sec\n",
      "train AE loss : 0.9443269371986389, train ANN loss : 3.740537166595459\n",
      "AE loss : 0.9459773302078247, ANN loss : 3.700289726257324, Total loss : 98.29801940917969\n",
      "learning rate A :  tf.Tensor(9.987364e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 123 is 0.0791 sec\n",
      "train AE loss : 0.9446746110916138, train ANN loss : 3.7302117347717285\n",
      "AE loss : 0.9459393620491028, ANN loss : 3.7002923488616943, Total loss : 98.29421997070312\n",
      "learning rate A :  tf.Tensor(9.987154e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 124 is 0.0781 sec\n",
      "train AE loss : 0.944636344909668, train ANN loss : 3.7338364124298096\n",
      "AE loss : 0.9459014534950256, ANN loss : 3.7002956867218018, Total loss : 98.29045104980469\n",
      "learning rate A :  tf.Tensor(9.986943e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 125 is 0.0775 sec\n",
      "train AE loss : 0.9445978999137878, train ANN loss : 3.732093095779419\n",
      "AE loss : 0.946132481098175, ANN loss : 3.694859504699707, Total loss : 98.30810546875\n",
      "learning rate A :  tf.Tensor(9.986943e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 126 is 0.0798 sec\n",
      "train AE loss : 0.9449207186698914, train ANN loss : 3.7327497005462646\n",
      "AE loss : 0.9462653398513794, ANN loss : 3.6895947456359863, Total loss : 98.31613159179688\n",
      "learning rate A :  tf.Tensor(9.986943e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 127 is 0.0792 sec\n",
      "train AE loss : 0.9451502561569214, train ANN loss : 3.728935718536377\n",
      "AE loss : 0.9462267160415649, ANN loss : 3.6895976066589355, Total loss : 98.31227111816406\n",
      "learning rate A :  tf.Tensor(9.986733e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 128 is 0.0785 sec\n",
      "train AE loss : 0.9451112747192383, train ANN loss : 3.72853946685791\n",
      "AE loss : 0.9461880922317505, ANN loss : 3.689600944519043, Total loss : 98.30841064453125\n",
      "learning rate A :  tf.Tensor(9.9865225e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 129 is 0.0771 sec\n",
      "train AE loss : 0.9450723528862, train ANN loss : 3.728020429611206\n",
      "AE loss : 0.946149468421936, ANN loss : 3.6896040439605713, Total loss : 98.3045425415039\n",
      "learning rate A :  tf.Tensor(9.986312e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 130 is 0.0775 sec\n",
      "train AE loss : 0.9450335502624512, train ANN loss : 3.7258856296539307\n",
      "AE loss : 0.9461109042167664, ANN loss : 3.6896069049835205, Total loss : 98.30069732666016\n",
      "learning rate A :  tf.Tensor(9.986102e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 131 is 0.0788 sec\n",
      "train AE loss : 0.9449946284294128, train ANN loss : 3.719998836517334\n",
      "AE loss : 0.9460723400115967, ANN loss : 3.689610004425049, Total loss : 98.29684448242188\n",
      "learning rate A :  tf.Tensor(9.985892e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 132 is 0.0786 sec\n",
      "train AE loss : 0.9449557065963745, train ANN loss : 3.723536729812622\n",
      "AE loss : 0.946178138256073, ANN loss : 3.6844441890716553, Total loss : 98.30226135253906\n",
      "learning rate A :  tf.Tensor(9.985892e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 133 is 0.0789 sec\n",
      "train AE loss : 0.9451649188995361, train ANN loss : 3.7183170318603516\n",
      "AE loss : 0.946139395236969, ANN loss : 3.6844475269317627, Total loss : 98.29837799072266\n",
      "learning rate A :  tf.Tensor(9.985681e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 134 is 0.0786 sec\n",
      "train AE loss : 0.9451256990432739, train ANN loss : 3.7244489192962646\n",
      "AE loss : 0.9462686777114868, ANN loss : 3.6793549060821533, Total loss : 98.30622100830078\n",
      "learning rate A :  tf.Tensor(9.985681e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 135 is 0.0794 sec\n",
      "train AE loss : 0.9453501105308533, train ANN loss : 3.715669631958008\n",
      "AE loss : 0.9463520050048828, ANN loss : 3.67431640625, Total loss : 98.30951690673828\n",
      "learning rate A :  tf.Tensor(9.985681e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 136 is 0.0799 sec\n",
      "train AE loss : 0.9455238580703735, train ANN loss : 3.7097864151000977\n",
      "AE loss : 0.9463127851486206, ANN loss : 3.6743195056915283, Total loss : 98.30560302734375\n",
      "learning rate A :  tf.Tensor(9.9854704e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 137 is 0.0787 sec\n",
      "train AE loss : 0.9454842209815979, train ANN loss : 3.710423231124878\n",
      "AE loss : 0.9462733864784241, ANN loss : 3.6743226051330566, Total loss : 98.3016586303711\n",
      "learning rate A :  tf.Tensor(9.98526e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 138 is 0.0781 sec\n",
      "train AE loss : 0.9454447031021118, train ANN loss : 3.709906578063965\n",
      "AE loss : 0.9462340474128723, ANN loss : 3.674325704574585, Total loss : 98.2977294921875\n",
      "learning rate A :  tf.Tensor(9.98505e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 139 is 0.0784 sec\n",
      "train AE loss : 0.9454050660133362, train ANN loss : 3.7168521881103516\n",
      "AE loss : 0.9462681412696838, ANN loss : 3.669480800628662, Total loss : 98.29629516601562\n",
      "learning rate A :  tf.Tensor(9.98505e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 140 is 0.0819 sec\n",
      "train AE loss : 0.9455234408378601, train ANN loss : 3.7071166038513184\n",
      "AE loss : 0.9462285041809082, ANN loss : 3.6694836616516113, Total loss : 98.2923355102539\n",
      "learning rate A :  tf.Tensor(9.9848396e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 141 is 0.0787 sec\n",
      "train AE loss : 0.9454835057258606, train ANN loss : 3.712096929550171\n",
      "AE loss : 0.9461614489555359, ANN loss : 3.6647233963012695, Total loss : 98.28086853027344\n",
      "learning rate A :  tf.Tensor(9.9848396e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 142 is 0.0793 sec\n",
      "train AE loss : 0.945500910282135, train ANN loss : 3.708324670791626\n",
      "AE loss : 0.946121335029602, ANN loss : 3.664726495742798, Total loss : 98.27686309814453\n",
      "learning rate A :  tf.Tensor(9.9846286e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 143 is 0.0796 sec\n",
      "train AE loss : 0.9454606771469116, train ANN loss : 3.704552173614502\n",
      "AE loss : 0.9460813403129578, ANN loss : 3.664729356765747, Total loss : 98.27285766601562\n",
      "learning rate A :  tf.Tensor(9.984418e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 144 is 0.0782 sec\n",
      "train AE loss : 0.9454204440116882, train ANN loss : 3.704399347305298\n",
      "AE loss : 0.9460413455963135, ANN loss : 3.6647326946258545, Total loss : 98.26885986328125\n",
      "learning rate A :  tf.Tensor(9.984208e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 145 is 0.0789 sec\n",
      "train AE loss : 0.9453803300857544, train ANN loss : 3.704899787902832\n",
      "AE loss : 0.9459623098373413, ANN loss : 3.6600279808044434, Total loss : 98.25625610351562\n",
      "learning rate A :  tf.Tensor(9.984208e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 146 is 0.0797 sec\n",
      "train AE loss : 0.9453786015510559, train ANN loss : 3.7019355297088623\n",
      "AE loss : 0.9459220767021179, ANN loss : 3.660031318664551, Total loss : 98.25224304199219\n",
      "learning rate A :  tf.Tensor(9.983998e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 147 is 0.0790 sec\n",
      "train AE loss : 0.9453379511833191, train ANN loss : 3.699766159057617\n",
      "AE loss : 0.945881724357605, ANN loss : 3.660034418106079, Total loss : 98.24819946289062\n",
      "learning rate A :  tf.Tensor(9.9837875e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 148 is 0.0781 sec\n",
      "train AE loss : 0.9452975392341614, train ANN loss : 3.699086904525757\n",
      "AE loss : 0.945841372013092, ANN loss : 3.6600375175476074, Total loss : 98.24417114257812\n",
      "learning rate A :  tf.Tensor(9.983577e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 149 is 0.0790 sec\n",
      "train AE loss : 0.9452568888664246, train ANN loss : 3.702350378036499\n",
      "AE loss : 0.9458010792732239, ANN loss : 3.660040855407715, Total loss : 98.24015045166016\n",
      "learning rate A :  tf.Tensor(9.983366e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 150 is 0.0784 sec\n",
      "train AE loss : 0.9452163577079773, train ANN loss : 3.702208995819092\n",
      "AE loss : 0.945681631565094, ANN loss : 3.655313730239868, Total loss : 98.22348022460938\n",
      "learning rate A :  tf.Tensor(9.983366e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 151 is 0.0809 sec\n",
      "train AE loss : 0.9451695680618286, train ANN loss : 3.6981489658355713\n",
      "AE loss : 0.9456409811973572, ANN loss : 3.6553170680999756, Total loss : 98.21940612792969\n",
      "learning rate A :  tf.Tensor(9.983156e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 152 is 0.0795 sec\n",
      "train AE loss : 0.945128858089447, train ANN loss : 3.6972556114196777\n",
      "AE loss : 0.945495069026947, ANN loss : 3.650420665740967, Total loss : 98.1999282836914\n",
      "learning rate A :  tf.Tensor(9.983156e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 153 is 0.0796 sec\n",
      "train AE loss : 0.9450564980506897, train ANN loss : 3.693897008895874\n",
      "AE loss : 0.9454541206359863, ANN loss : 3.650423526763916, Total loss : 98.19583892822266\n",
      "learning rate A :  tf.Tensor(9.9829456e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 154 is 0.0802 sec\n",
      "train AE loss : 0.9450151324272156, train ANN loss : 3.6934568881988525\n",
      "AE loss : 0.9452924728393555, ANN loss : 3.645514965057373, Total loss : 98.17476654052734\n",
      "learning rate A :  tf.Tensor(9.9829456e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 155 is 0.0809 sec\n",
      "train AE loss : 0.9449244737625122, train ANN loss : 3.6917126178741455\n",
      "AE loss : 0.9450410008430481, ANN loss : 3.6406991481781006, Total loss : 98.1447982788086\n",
      "learning rate A :  tf.Tensor(9.9829456e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 156 is 0.0797 sec\n",
      "train AE loss : 0.9447442889213562, train ANN loss : 3.686152935028076\n",
      "AE loss : 0.9447245001792908, ANN loss : 3.635906934738159, Total loss : 98.10835266113281\n",
      "learning rate A :  tf.Tensor(9.9829456e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 157 is 0.0803 sec\n",
      "train AE loss : 0.9444913864135742, train ANN loss : 3.6788785457611084\n",
      "AE loss : 0.9443811774253845, ANN loss : 3.6311259269714355, Total loss : 98.06924438476562\n",
      "learning rate A :  tf.Tensor(9.9829456e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 158 is 0.0804 sec\n",
      "train AE loss : 0.9442130327224731, train ANN loss : 3.6728873252868652\n",
      "AE loss : 0.9439190030097961, ANN loss : 3.626316547393799, Total loss : 98.01821899414062\n",
      "learning rate A :  tf.Tensor(9.9829456e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 159 is 0.0798 sec\n",
      "train AE loss : 0.9438067078590393, train ANN loss : 3.667642831802368\n",
      "AE loss : 0.9434819221496582, ANN loss : 3.6214349269866943, Total loss : 97.9696273803711\n",
      "learning rate A :  tf.Tensor(9.9829456e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 160 is 0.0793 sec\n",
      "train AE loss : 0.9434391260147095, train ANN loss : 3.665131092071533\n",
      "AE loss : 0.9429604411125183, ANN loss : 3.6165053844451904, Total loss : 97.91255187988281\n",
      "learning rate A :  tf.Tensor(9.9829456e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 161 is 0.0797 sec\n",
      "train AE loss : 0.9429877400398254, train ANN loss : 3.6603004932403564\n",
      "AE loss : 0.9429162740707397, ANN loss : 3.616508722305298, Total loss : 97.90813446044922\n",
      "learning rate A :  tf.Tensor(9.982735e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 162 is 0.0777 sec\n",
      "train AE loss : 0.942943274974823, train ANN loss : 3.660600185394287\n",
      "AE loss : 0.9428720474243164, ANN loss : 3.616511821746826, Total loss : 97.9037094116211\n",
      "learning rate A :  tf.Tensor(9.982526e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 163 is 0.0775 sec\n",
      "train AE loss : 0.9428988695144653, train ANN loss : 3.665235757827759\n",
      "AE loss : 0.9428278803825378, ANN loss : 3.6165149211883545, Total loss : 97.89930725097656\n",
      "learning rate A :  tf.Tensor(9.982315e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 164 is 0.0778 sec\n",
      "train AE loss : 0.9428543448448181, train ANN loss : 3.658261775970459\n",
      "AE loss : 0.9422823786735535, ANN loss : 3.6115384101867676, Total loss : 97.83978271484375\n",
      "learning rate A :  tf.Tensor(9.982315e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 165 is 0.0805 sec\n",
      "train AE loss : 0.9423719048500061, train ANN loss : 3.657233953475952\n",
      "AE loss : 0.9422375559806824, ANN loss : 3.611541509628296, Total loss : 97.83529663085938\n",
      "learning rate A :  tf.Tensor(9.9821045e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 166 is 0.0790 sec\n",
      "train AE loss : 0.9423268437385559, train ANN loss : 3.661395788192749\n",
      "AE loss : 0.942192792892456, ANN loss : 3.611544370651245, Total loss : 97.83081817626953\n",
      "learning rate A :  tf.Tensor(9.981894e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 167 is 0.0794 sec\n",
      "train AE loss : 0.9422816634178162, train ANN loss : 3.655341625213623\n",
      "AE loss : 0.9421480298042297, ANN loss : 3.6115477085113525, Total loss : 97.82635498046875\n",
      "learning rate A :  tf.Tensor(9.981684e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 168 is 0.0782 sec\n",
      "train AE loss : 0.9422364830970764, train ANN loss : 3.653076410293579\n",
      "AE loss : 0.9421032071113586, ANN loss : 3.611550807952881, Total loss : 97.82186889648438\n",
      "learning rate A :  tf.Tensor(9.981474e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 169 is 0.0785 sec\n",
      "train AE loss : 0.9421913623809814, train ANN loss : 3.6591577529907227\n",
      "AE loss : 0.9415497183799744, ANN loss : 3.606647491455078, Total loss : 97.76161193847656\n",
      "learning rate A :  tf.Tensor(9.981474e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 170 is 0.0802 sec\n",
      "train AE loss : 0.9416950941085815, train ANN loss : 3.6522953510284424\n",
      "AE loss : 0.9408528208732605, ANN loss : 3.60176682472229, Total loss : 97.68704986572266\n",
      "learning rate A :  tf.Tensor(9.981474e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 171 is 0.0790 sec\n",
      "train AE loss : 0.9410544037818909, train ANN loss : 3.6397926807403564\n",
      "AE loss : 0.9401689171791077, ANN loss : 3.596510648727417, Total loss : 97.6134033203125\n",
      "learning rate A :  tf.Tensor(9.981474e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 172 is 0.0796 sec\n",
      "train AE loss : 0.9404206871986389, train ANN loss : 3.6398062705993652\n",
      "AE loss : 0.9401219487190247, ANN loss : 3.5965137481689453, Total loss : 97.60870361328125\n",
      "learning rate A :  tf.Tensor(9.981263e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 173 is 0.0781 sec\n",
      "train AE loss : 0.9403730630874634, train ANN loss : 3.6440978050231934\n",
      "AE loss : 0.9393751621246338, ANN loss : 3.591080904006958, Total loss : 97.52859497070312\n",
      "learning rate A :  tf.Tensor(9.981263e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 174 is 0.0785 sec\n",
      "train AE loss : 0.9396700263023376, train ANN loss : 3.63739275932312\n",
      "AE loss : 0.9385687708854675, ANN loss : 3.5856728553771973, Total loss : 97.44255065917969\n",
      "learning rate A :  tf.Tensor(9.981263e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 175 is 0.0792 sec\n",
      "train AE loss : 0.9389054179191589, train ANN loss : 3.6407384872436523\n",
      "AE loss : 0.9385200142860413, ANN loss : 3.5856759548187256, Total loss : 97.43767547607422\n",
      "learning rate A :  tf.Tensor(9.981053e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 176 is 0.0778 sec\n",
      "train AE loss : 0.9388561844825745, train ANN loss : 3.634312868118286\n",
      "AE loss : 0.9376233220100403, ANN loss : 3.580209970474243, Total loss : 97.34253692626953\n",
      "learning rate A :  tf.Tensor(9.981053e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 177 is 0.0790 sec\n",
      "train AE loss : 0.9380064010620117, train ANN loss : 3.6288976669311523\n",
      "AE loss : 0.936721920967102, ANN loss : 3.5747392177581787, Total loss : 97.24693298339844\n",
      "learning rate A :  tf.Tensor(9.981053e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 178 is 0.0793 sec\n",
      "train AE loss : 0.9371464252471924, train ANN loss : 3.6273856163024902\n",
      "AE loss : 0.9366714358329773, ANN loss : 3.574742078781128, Total loss : 97.24188995361328\n",
      "learning rate A :  tf.Tensor(9.980843e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 179 is 0.0774 sec\n",
      "train AE loss : 0.9370954036712646, train ANN loss : 3.624359130859375\n",
      "AE loss : 0.9366208910942078, ANN loss : 3.5747456550598145, Total loss : 97.2368392944336\n",
      "learning rate A :  tf.Tensor(9.9806326e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 180 is 0.0774 sec\n",
      "train AE loss : 0.9370443820953369, train ANN loss : 3.6233787536621094\n",
      "AE loss : 0.936570405960083, ANN loss : 3.5747487545013428, Total loss : 97.2317886352539\n",
      "learning rate A :  tf.Tensor(9.980422e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 181 is 0.0770 sec\n",
      "train AE loss : 0.936993420124054, train ANN loss : 3.625534772872925\n",
      "AE loss : 0.9356450438499451, ANN loss : 3.5692667961120605, Total loss : 97.13377380371094\n",
      "learning rate A :  tf.Tensor(9.980422e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 182 is 0.0809 sec\n",
      "train AE loss : 0.9361006617546082, train ANN loss : 3.617682456970215\n",
      "AE loss : 0.9346083402633667, ANN loss : 3.5637686252593994, Total loss : 97.02460479736328\n",
      "learning rate A :  tf.Tensor(9.980422e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 183 is 0.0793 sec\n",
      "train AE loss : 0.9350936412811279, train ANN loss : 3.6194353103637695\n",
      "AE loss : 0.9345561265945435, ANN loss : 3.563771963119507, Total loss : 97.0193862915039\n",
      "learning rate A :  tf.Tensor(9.980211e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 184 is 0.0775 sec\n",
      "train AE loss : 0.9350408911705017, train ANN loss : 3.6139607429504395\n",
      "AE loss : 0.9334889650344849, ANN loss : 3.558229446411133, Total loss : 96.9071273803711\n",
      "learning rate A :  tf.Tensor(9.980211e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 185 is 0.0803 sec\n",
      "train AE loss : 0.9340073466300964, train ANN loss : 3.6103076934814453\n",
      "AE loss : 0.9334355592727661, ANN loss : 3.558232545852661, Total loss : 96.90179443359375\n",
      "learning rate A :  tf.Tensor(9.980001e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 186 is 0.0771 sec\n",
      "train AE loss : 0.9339534640312195, train ANN loss : 3.6091179847717285\n",
      "AE loss : 0.9333823323249817, ANN loss : 3.5582356452941895, Total loss : 96.89646911621094\n",
      "learning rate A :  tf.Tensor(9.9797915e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 187 is 0.0772 sec\n",
      "train AE loss : 0.9338995814323425, train ANN loss : 3.6070046424865723\n",
      "AE loss : 0.9333291053771973, ANN loss : 3.558238983154297, Total loss : 96.89114379882812\n",
      "learning rate A :  tf.Tensor(9.979581e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 188 is 0.0779 sec\n",
      "train AE loss : 0.9338458180427551, train ANN loss : 3.614968776702881\n",
      "AE loss : 0.9332758188247681, ANN loss : 3.5582423210144043, Total loss : 96.88582611083984\n",
      "learning rate A :  tf.Tensor(9.97937e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 189 is 0.0873 sec\n",
      "train AE loss : 0.9337919354438782, train ANN loss : 3.6124258041381836\n",
      "AE loss : 0.9332226514816284, ANN loss : 3.5582454204559326, Total loss : 96.88050842285156\n",
      "learning rate A :  tf.Tensor(9.97916e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 190 is 0.0766 sec\n",
      "train AE loss : 0.9337381720542908, train ANN loss : 3.6076090335845947\n",
      "AE loss : 0.9321171641349792, ANN loss : 3.552647829055786, Total loss : 96.76435852050781\n",
      "learning rate A :  tf.Tensor(9.97916e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 191 is 0.0803 sec\n",
      "train AE loss : 0.9326686263084412, train ANN loss : 3.6062283515930176\n",
      "AE loss : 0.9309003949165344, ANN loss : 3.5471231937408447, Total loss : 96.63716888427734\n",
      "learning rate A :  tf.Tensor(9.97916e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 192 is 0.0792 sec\n",
      "train AE loss : 0.9314870834350586, train ANN loss : 3.601897954940796\n",
      "AE loss : 0.9308449625968933, ANN loss : 3.547126293182373, Total loss : 96.63162994384766\n",
      "learning rate A :  tf.Tensor(9.9789504e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 193 is 0.0766 sec\n",
      "train AE loss : 0.9314311742782593, train ANN loss : 3.6017839908599854\n",
      "AE loss : 0.9307894706726074, ANN loss : 3.5471296310424805, Total loss : 96.6260757446289\n",
      "learning rate A :  tf.Tensor(9.97874e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 194 is 0.0789 sec\n",
      "train AE loss : 0.9313752055168152, train ANN loss : 3.5997204780578613\n",
      "AE loss : 0.9295312166213989, ANN loss : 3.541616916656494, Total loss : 96.49474334716797\n",
      "learning rate A :  tf.Tensor(9.97874e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 195 is 0.0796 sec\n",
      "train AE loss : 0.9301564693450928, train ANN loss : 3.5974602699279785\n",
      "AE loss : 0.9282737970352173, ANN loss : 3.5360987186431885, Total loss : 96.36347198486328\n",
      "learning rate A :  tf.Tensor(9.97874e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 196 is 0.0785 sec\n",
      "train AE loss : 0.9289393424987793, train ANN loss : 3.594752550125122\n",
      "AE loss : 0.926997721195221, ANN loss : 3.5306107997894287, Total loss : 96.23038482666016\n",
      "learning rate A :  tf.Tensor(9.97874e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 197 is 0.0813 sec\n",
      "train AE loss : 0.9277019500732422, train ANN loss : 3.5875537395477295\n",
      "AE loss : 0.9256938695907593, ANN loss : 3.525127410888672, Total loss : 96.09452056884766\n",
      "learning rate A :  tf.Tensor(9.97874e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 198 is 0.0790 sec\n",
      "train AE loss : 0.9264406561851501, train ANN loss : 3.582724094390869\n",
      "AE loss : 0.925634503364563, ANN loss : 3.5251307487487793, Total loss : 96.08859252929688\n",
      "learning rate A :  tf.Tensor(9.97853e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 199 is 0.0770 sec\n",
      "train AE loss : 0.9263806343078613, train ANN loss : 3.582810401916504\n",
      "AE loss : 0.924272358417511, ANN loss : 3.5196752548217773, Total loss : 95.94690704345703\n",
      "learning rate A :  tf.Tensor(9.97853e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 200 is 0.0820 sec\n",
      "train AE loss : 0.9250707030296326, train ANN loss : 3.5856246948242188\n",
      "AE loss : 0.9242120981216431, ANN loss : 3.519678831100464, Total loss : 95.9408950805664\n",
      "learning rate A :  tf.Tensor(9.978319e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 201 is 0.0781 sec\n",
      "train AE loss : 0.9250096678733826, train ANN loss : 3.5803990364074707\n",
      "AE loss : 0.9227962493896484, ANN loss : 3.5143041610717773, Total loss : 95.79393005371094\n",
      "learning rate A :  tf.Tensor(9.978319e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 202 is 0.0795 sec\n",
      "train AE loss : 0.9236299395561218, train ANN loss : 3.5779263973236084\n",
      "AE loss : 0.9227346777915955, ANN loss : 3.5143072605133057, Total loss : 95.78778076171875\n",
      "learning rate A :  tf.Tensor(9.978109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 203 is 0.0774 sec\n",
      "train AE loss : 0.9235673546791077, train ANN loss : 3.5721116065979004\n",
      "AE loss : 0.9211985468864441, ANN loss : 3.5090110301971436, Total loss : 95.62886810302734\n",
      "learning rate A :  tf.Tensor(9.978109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 204 is 0.0790 sec\n",
      "train AE loss : 0.9220528602600098, train ANN loss : 3.5754570960998535\n",
      "AE loss : 0.9211358428001404, ANN loss : 3.509014368057251, Total loss : 95.62259674072266\n",
      "learning rate A :  tf.Tensor(9.977899e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 205 is 0.0765 sec\n",
      "train AE loss : 0.9219895005226135, train ANN loss : 3.571924924850464\n",
      "AE loss : 0.9210731387138367, ANN loss : 3.5090174674987793, Total loss : 95.6163330078125\n",
      "learning rate A :  tf.Tensor(9.977688e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 206 is 0.0926 sec\n",
      "train AE loss : 0.9219261407852173, train ANN loss : 3.5757203102111816\n",
      "AE loss : 0.9210103750228882, ANN loss : 3.5090208053588867, Total loss : 95.61005401611328\n",
      "learning rate A :  tf.Tensor(9.977478e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 207 is 0.0800 sec\n",
      "train AE loss : 0.9218629002571106, train ANN loss : 3.560427665710449\n",
      "AE loss : 0.9209477305412292, ANN loss : 3.509024143218994, Total loss : 95.60379028320312\n",
      "learning rate A :  tf.Tensor(9.9772675e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 208 is 0.0743 sec\n",
      "train AE loss : 0.9217994213104248, train ANN loss : 3.5688869953155518\n",
      "AE loss : 0.9208852052688599, ANN loss : 3.5090270042419434, Total loss : 95.59754943847656\n",
      "learning rate A :  tf.Tensor(9.977057e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 209 is 0.0743 sec\n",
      "train AE loss : 0.9217361211776733, train ANN loss : 3.5728554725646973\n",
      "AE loss : 0.9193025827407837, ANN loss : 3.503791332244873, Total loss : 95.43404388427734\n",
      "learning rate A :  tf.Tensor(9.977057e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 210 is 0.0754 sec\n",
      "train AE loss : 0.9201589822769165, train ANN loss : 3.5637974739074707\n",
      "AE loss : 0.9192391633987427, ANN loss : 3.5037944316864014, Total loss : 95.42771911621094\n",
      "learning rate A :  tf.Tensor(9.976847e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 211 is 0.0762 sec\n",
      "train AE loss : 0.9200950860977173, train ANN loss : 3.566628932952881\n",
      "AE loss : 0.9191757440567017, ANN loss : 3.5037975311279297, Total loss : 95.42137145996094\n",
      "learning rate A :  tf.Tensor(9.976637e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 212 is 0.0737 sec\n",
      "train AE loss : 0.920030951499939, train ANN loss : 3.5700371265411377\n",
      "AE loss : 0.919112503528595, ANN loss : 3.503800630569458, Total loss : 95.41505432128906\n",
      "learning rate A :  tf.Tensor(9.9764264e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 213 is 0.0738 sec\n",
      "train AE loss : 0.9199670553207397, train ANN loss : 3.569068193435669\n",
      "AE loss : 0.919049084186554, ANN loss : 3.5038039684295654, Total loss : 95.40870666503906\n",
      "learning rate A :  tf.Tensor(9.976216e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 214 is 0.0765 sec\n",
      "train AE loss : 0.9199030995368958, train ANN loss : 3.566912889480591\n",
      "AE loss : 0.9173898696899414, ANN loss : 3.498638391494751, Total loss : 95.23762512207031\n",
      "learning rate A :  tf.Tensor(9.976216e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 215 is 0.0753 sec\n",
      "train AE loss : 0.9182369112968445, train ANN loss : 3.5616893768310547\n",
      "AE loss : 0.917325496673584, ANN loss : 3.4986412525177, Total loss : 95.23119354248047\n",
      "learning rate A :  tf.Tensor(9.976006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 216 is 0.0737 sec\n",
      "train AE loss : 0.9181717038154602, train ANN loss : 3.5617642402648926\n",
      "AE loss : 0.9172611236572266, ANN loss : 3.4986445903778076, Total loss : 95.2247543334961\n",
      "learning rate A :  tf.Tensor(9.975796e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 217 is 0.0768 sec\n",
      "train AE loss : 0.9181066155433655, train ANN loss : 3.5648529529571533\n",
      "AE loss : 0.9155958294868469, ANN loss : 3.493561267852783, Total loss : 95.05314636230469\n",
      "learning rate A :  tf.Tensor(9.975796e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 218 is 0.0757 sec\n",
      "train AE loss : 0.9164260625839233, train ANN loss : 3.555201292037964\n",
      "AE loss : 0.9155309200286865, ANN loss : 3.4935643672943115, Total loss : 95.04666137695312\n",
      "learning rate A :  tf.Tensor(9.975586e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 219 is 0.0743 sec\n",
      "train AE loss : 0.9163603782653809, train ANN loss : 3.5545859336853027\n",
      "AE loss : 0.9137758612632751, ANN loss : 3.4884610176086426, Total loss : 94.86605072021484\n",
      "learning rate A :  tf.Tensor(9.975586e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 220 is 0.0791 sec\n",
      "train AE loss : 0.9145886898040771, train ANN loss : 3.5510218143463135\n",
      "AE loss : 0.9119911193847656, ANN loss : 3.4833319187164307, Total loss : 94.68244171142578\n",
      "learning rate A :  tf.Tensor(9.975586e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 221 is 0.0757 sec\n",
      "train AE loss : 0.9127946496009827, train ANN loss : 3.5416221618652344\n",
      "AE loss : 0.911925196647644, ANN loss : 3.48333477973938, Total loss : 94.67585754394531\n",
      "learning rate A :  tf.Tensor(9.975375e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 222 is 0.0739 sec\n",
      "train AE loss : 0.9127277135848999, train ANN loss : 3.5464930534362793\n",
      "AE loss : 0.9118591547012329, ANN loss : 3.483337879180908, Total loss : 94.66925048828125\n",
      "learning rate A :  tf.Tensor(9.9751654e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 223 is 0.0752 sec\n",
      "train AE loss : 0.9126609563827515, train ANN loss : 3.548234701156616\n",
      "AE loss : 0.9100626111030579, ANN loss : 3.4781837463378906, Total loss : 94.48444366455078\n",
      "learning rate A :  tf.Tensor(9.9751654e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 224 is 0.0770 sec\n",
      "train AE loss : 0.9108672142028809, train ANN loss : 3.541525363922119\n",
      "AE loss : 0.9082224369049072, ANN loss : 3.473013162612915, Total loss : 94.29525756835938\n",
      "learning rate A :  tf.Tensor(9.9751654e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 225 is 0.0760 sec\n",
      "train AE loss : 0.9090431332588196, train ANN loss : 3.5385830402374268\n",
      "AE loss : 0.9061993360519409, ANN loss : 3.467846155166626, Total loss : 94.08778381347656\n",
      "learning rate A :  tf.Tensor(9.9751654e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 226 is 0.0764 sec\n",
      "train AE loss : 0.90703946352005, train ANN loss : 3.538571357727051\n",
      "AE loss : 0.9039522409439087, ANN loss : 3.46268630027771, Total loss : 93.85791015625\n",
      "learning rate A :  tf.Tensor(9.9751654e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 227 is 0.0762 sec\n",
      "train AE loss : 0.904826283454895, train ANN loss : 3.533078908920288\n",
      "AE loss : 0.9017450213432312, ANN loss : 3.457533836364746, Total loss : 93.63203430175781\n",
      "learning rate A :  tf.Tensor(9.9751654e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 228 is 0.0762 sec\n",
      "train AE loss : 0.9026395678520203, train ANN loss : 3.534545421600342\n",
      "AE loss : 0.8994874358177185, ANN loss : 3.4523704051971436, Total loss : 93.401123046875\n",
      "learning rate A :  tf.Tensor(9.9751654e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 229 is 0.0759 sec\n",
      "train AE loss : 0.9004251956939697, train ANN loss : 3.5245327949523926\n",
      "AE loss : 0.8994206190109253, ANN loss : 3.4523725509643555, Total loss : 93.39443969726562\n",
      "learning rate A :  tf.Tensor(9.974955e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 230 is 0.0740 sec\n",
      "train AE loss : 0.9003576636314392, train ANN loss : 3.5237343311309814\n",
      "AE loss : 0.8993537425994873, ANN loss : 3.4523744583129883, Total loss : 93.38774108886719\n",
      "learning rate A :  tf.Tensor(9.974745e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 231 is 0.0734 sec\n",
      "train AE loss : 0.9002901315689087, train ANN loss : 3.51411771774292\n",
      "AE loss : 0.8992870450019836, ANN loss : 3.452376127243042, Total loss : 93.3810806274414\n",
      "learning rate A :  tf.Tensor(9.9745346e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 232 is 0.0750 sec\n",
      "train AE loss : 0.9002227187156677, train ANN loss : 3.520331382751465\n",
      "AE loss : 0.8970330953598022, ANN loss : 3.4471514225006104, Total loss : 93.15045928955078\n",
      "learning rate A :  tf.Tensor(9.9745346e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 233 is 0.0759 sec\n",
      "train AE loss : 0.898007869720459, train ANN loss : 3.522181749343872\n",
      "AE loss : 0.8969665169715881, ANN loss : 3.447153091430664, Total loss : 93.14380645751953\n",
      "learning rate A :  tf.Tensor(9.974324e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 234 is 0.0740 sec\n",
      "train AE loss : 0.8979405164718628, train ANN loss : 3.519591808319092\n",
      "AE loss : 0.8947336077690125, ANN loss : 3.4418559074401855, Total loss : 92.91521453857422\n",
      "learning rate A :  tf.Tensor(9.974324e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 235 is 0.0759 sec\n",
      "train AE loss : 0.895743727684021, train ANN loss : 3.5143744945526123\n",
      "AE loss : 0.8925011157989502, ANN loss : 3.4364829063415527, Total loss : 92.68659973144531\n",
      "learning rate A :  tf.Tensor(9.974324e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 236 is 0.0757 sec\n",
      "train AE loss : 0.8935465812683105, train ANN loss : 3.505262613296509\n",
      "AE loss : 0.8924350738525391, ANN loss : 3.4364843368530273, Total loss : 92.67998504638672\n",
      "learning rate A :  tf.Tensor(9.974115e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 237 is 0.0743 sec\n",
      "train AE loss : 0.8934797644615173, train ANN loss : 3.5088183879852295\n",
      "AE loss : 0.8923689723014832, ANN loss : 3.436485528945923, Total loss : 92.67338562011719\n",
      "learning rate A :  tf.Tensor(9.9739045e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 238 is 0.0752 sec\n",
      "train AE loss : 0.8934128880500793, train ANN loss : 3.5082058906555176\n",
      "AE loss : 0.8923029899597168, ANN loss : 3.4364869594573975, Total loss : 92.66678619384766\n",
      "learning rate A :  tf.Tensor(9.9736935e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 239 is 0.0748 sec\n",
      "train AE loss : 0.8933459520339966, train ANN loss : 3.5105249881744385\n",
      "AE loss : 0.8901761174201965, ANN loss : 3.430964946746826, Total loss : 92.44857788085938\n",
      "learning rate A :  tf.Tensor(9.9736935e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 240 is 0.0759 sec\n",
      "train AE loss : 0.8912540674209595, train ANN loss : 3.49967622756958\n",
      "AE loss : 0.8901101350784302, ANN loss : 3.430966377258301, Total loss : 92.44198608398438\n",
      "learning rate A :  tf.Tensor(9.973484e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 241 is 0.0747 sec\n",
      "train AE loss : 0.8911873698234558, train ANN loss : 3.5053844451904297\n",
      "AE loss : 0.8880045413970947, ANN loss : 3.425452947616577, Total loss : 92.22589874267578\n",
      "learning rate A :  tf.Tensor(9.973484e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 242 is 0.0763 sec\n",
      "train AE loss : 0.8891065120697021, train ANN loss : 3.5046041011810303\n",
      "AE loss : 0.887938916683197, ANN loss : 3.4254539012908936, Total loss : 92.21934509277344\n",
      "learning rate A :  tf.Tensor(9.973274e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 243 is 0.0749 sec\n",
      "train AE loss : 0.8890400528907776, train ANN loss : 3.497786045074463\n",
      "AE loss : 0.8858760595321655, ANN loss : 3.4198856353759766, Total loss : 92.00749969482422\n",
      "learning rate A :  tf.Tensor(9.973274e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 244 is 0.0772 sec\n",
      "train AE loss : 0.8869859576225281, train ANN loss : 3.501244306564331\n",
      "AE loss : 0.8858106136322021, ANN loss : 3.419886589050293, Total loss : 92.00094604492188\n",
      "learning rate A :  tf.Tensor(9.973064e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 245 is 0.0738 sec\n",
      "train AE loss : 0.8869196772575378, train ANN loss : 3.490068197250366\n",
      "AE loss : 0.8838722705841064, ANN loss : 3.414318084716797, Total loss : 91.80155181884766\n",
      "learning rate A :  tf.Tensor(9.973064e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 246 is 0.0765 sec\n",
      "train AE loss : 0.8849666714668274, train ANN loss : 3.4860172271728516\n",
      "AE loss : 0.8818137049674988, ANN loss : 3.408651113510132, Total loss : 91.59002685546875\n",
      "learning rate A :  tf.Tensor(9.973064e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 247 is 0.0952 sec\n",
      "train AE loss : 0.8829034566879272, train ANN loss : 3.4849491119384766\n",
      "AE loss : 0.8817486763000488, ANN loss : 3.4086520671844482, Total loss : 91.5835189819336\n",
      "learning rate A :  tf.Tensor(9.972853e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 248 is 0.0808 sec\n",
      "train AE loss : 0.8828375935554504, train ANN loss : 3.4830431938171387\n",
      "AE loss : 0.8796656727790833, ANN loss : 3.4028451442718506, Total loss : 91.36941528320312\n",
      "learning rate A :  tf.Tensor(9.972853e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 249 is 0.0765 sec\n",
      "train AE loss : 0.8807399272918701, train ANN loss : 3.4873902797698975\n",
      "AE loss : 0.8775876760482788, ANN loss : 3.3969857692718506, Total loss : 91.15575408935547\n",
      "learning rate A :  tf.Tensor(9.972853e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 250 is 0.0762 sec\n",
      "train AE loss : 0.87863689661026, train ANN loss : 3.4689619541168213\n",
      "AE loss : 0.8775233030319214, ANN loss : 3.396986722946167, Total loss : 91.1493148803711\n",
      "learning rate A :  tf.Tensor(9.972643e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 251 is 0.0750 sec\n",
      "train AE loss : 0.8785715699195862, train ANN loss : 3.475820302963257\n",
      "AE loss : 0.8774589896202087, ANN loss : 3.396987199783325, Total loss : 91.14287567138672\n",
      "learning rate A :  tf.Tensor(9.972433e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 252 is 0.0743 sec\n",
      "train AE loss : 0.8785061836242676, train ANN loss : 3.4772307872772217\n",
      "AE loss : 0.8753623366355896, ANN loss : 3.391176223754883, Total loss : 90.92740631103516\n",
      "learning rate A :  tf.Tensor(9.972433e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 253 is 0.0760 sec\n",
      "train AE loss : 0.8763801455497742, train ANN loss : 3.470521926879883\n",
      "AE loss : 0.8752984404563904, ANN loss : 3.391176700592041, Total loss : 90.9210205078125\n",
      "learning rate A :  tf.Tensor(9.972223e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 254 is 0.0745 sec\n",
      "train AE loss : 0.8763150572776794, train ANN loss : 3.4694788455963135\n",
      "AE loss : 0.8732008934020996, ANN loss : 3.3853700160980225, Total loss : 90.70545959472656\n",
      "learning rate A :  tf.Tensor(9.972223e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 255 is 0.0761 sec\n",
      "train AE loss : 0.874183714389801, train ANN loss : 3.4759395122528076\n",
      "AE loss : 0.8710028529167175, ANN loss : 3.379559278488159, Total loss : 90.47985076904297\n",
      "learning rate A :  tf.Tensor(9.972223e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 256 is 0.0774 sec\n",
      "train AE loss : 0.8719568848609924, train ANN loss : 3.460155487060547\n",
      "AE loss : 0.8688356280326843, ANN loss : 3.37373685836792, Total loss : 90.2573013305664\n",
      "learning rate A :  tf.Tensor(9.972223e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 257 is 0.0747 sec\n",
      "train AE loss : 0.8697577714920044, train ANN loss : 3.4561352729797363\n",
      "AE loss : 0.8687730431556702, ANN loss : 3.3737375736236572, Total loss : 90.25103759765625\n",
      "learning rate A :  tf.Tensor(9.972013e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 258 is 0.0734 sec\n",
      "train AE loss : 0.8696939945220947, train ANN loss : 3.4597623348236084\n",
      "AE loss : 0.868710458278656, ANN loss : 3.3737382888793945, Total loss : 90.24478149414062\n",
      "learning rate A :  tf.Tensor(9.971803e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 259 is 0.0737 sec\n",
      "train AE loss : 0.8696302175521851, train ANN loss : 3.458235263824463\n",
      "AE loss : 0.8665902614593506, ANN loss : 3.3679215908050537, Total loss : 90.02694702148438\n",
      "learning rate A :  tf.Tensor(9.971803e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 260 is 0.0762 sec\n",
      "train AE loss : 0.8674703240394592, train ANN loss : 3.45390248298645\n",
      "AE loss : 0.866528332233429, ANN loss : 3.367922067642212, Total loss : 90.020751953125\n",
      "learning rate A :  tf.Tensor(9.971593e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 261 is 0.0744 sec\n",
      "train AE loss : 0.8674069046974182, train ANN loss : 3.454164743423462\n",
      "AE loss : 0.8643746972084045, ANN loss : 3.362257719039917, Total loss : 89.79972839355469\n",
      "learning rate A :  tf.Tensor(9.971593e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 262 is 0.0760 sec\n",
      "train AE loss : 0.8652031421661377, train ANN loss : 3.4527809619903564\n",
      "AE loss : 0.8643134236335754, ANN loss : 3.3622584342956543, Total loss : 89.7936019897461\n",
      "learning rate A :  tf.Tensor(9.971383e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 263 is 0.0735 sec\n",
      "train AE loss : 0.8651403784751892, train ANN loss : 3.451213836669922\n",
      "AE loss : 0.8642520904541016, ANN loss : 3.3622591495513916, Total loss : 89.78746795654297\n",
      "learning rate A :  tf.Tensor(9.9711724e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 264 is 0.0736 sec\n",
      "train AE loss : 0.8650776147842407, train ANN loss : 3.452883720397949\n",
      "AE loss : 0.8641908764839172, ANN loss : 3.362260103225708, Total loss : 89.7813491821289\n",
      "learning rate A :  tf.Tensor(9.970962e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 265 is 0.0749 sec\n",
      "train AE loss : 0.8650149703025818, train ANN loss : 3.4500091075897217\n",
      "AE loss : 0.8641296625137329, ANN loss : 3.3622610569000244, Total loss : 89.77522277832031\n",
      "learning rate A :  tf.Tensor(9.9707526e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 266 is 0.0739 sec\n",
      "train AE loss : 0.8649522662162781, train ANN loss : 3.4497151374816895\n",
      "AE loss : 0.8622426390647888, ANN loss : 3.356682538986206, Total loss : 89.58094787597656\n",
      "learning rate A :  tf.Tensor(9.9707526e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 267 is 0.0755 sec\n",
      "train AE loss : 0.8630136251449585, train ANN loss : 3.4492034912109375\n",
      "AE loss : 0.8621820211410522, ANN loss : 3.3566834926605225, Total loss : 89.57488250732422\n",
      "learning rate A :  tf.Tensor(9.970542e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 268 is 0.0752 sec\n",
      "train AE loss : 0.8629513382911682, train ANN loss : 3.444122314453125\n",
      "AE loss : 0.8603700399398804, ANN loss : 3.351186513900757, Total loss : 89.38819122314453\n",
      "learning rate A :  tf.Tensor(9.970542e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 269 is 0.0847 sec\n",
      "train AE loss : 0.8610758185386658, train ANN loss : 3.440721035003662\n",
      "AE loss : 0.8587051033973694, ANN loss : 3.3457744121551514, Total loss : 89.2162857055664\n",
      "learning rate A :  tf.Tensor(9.970542e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 270 is 0.0758 sec\n",
      "train AE loss : 0.8593343496322632, train ANN loss : 3.434684991836548\n",
      "AE loss : 0.8586453199386597, ANN loss : 3.345775604248047, Total loss : 89.2103042602539\n",
      "learning rate A :  tf.Tensor(9.970332e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 271 is 0.0743 sec\n",
      "train AE loss : 0.8592731356620789, train ANN loss : 3.435727596282959\n",
      "AE loss : 0.8571562170982361, ANN loss : 3.340369462966919, Total loss : 89.05599212646484\n",
      "learning rate A :  tf.Tensor(9.970332e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 272 is 0.0759 sec\n",
      "train AE loss : 0.8577097058296204, train ANN loss : 3.4294869899749756\n",
      "AE loss : 0.8570969104766846, ANN loss : 3.3403708934783936, Total loss : 89.05005645751953\n",
      "learning rate A :  tf.Tensor(9.9701225e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 273 is 0.0752 sec\n",
      "train AE loss : 0.8576489090919495, train ANN loss : 3.431584358215332\n",
      "AE loss : 0.8557645082473755, ANN loss : 3.3350253105163574, Total loss : 88.91148376464844\n",
      "learning rate A :  tf.Tensor(9.9701225e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 274 is 0.0764 sec\n",
      "train AE loss : 0.8562477231025696, train ANN loss : 3.4346885681152344\n",
      "AE loss : 0.8557056784629822, ANN loss : 3.335026741027832, Total loss : 88.90559387207031\n",
      "learning rate A :  tf.Tensor(9.969912e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 275 is 0.0734 sec\n",
      "train AE loss : 0.8561874032020569, train ANN loss : 3.426940679550171\n",
      "AE loss : 0.8545436263084412, ANN loss : 3.3298444747924805, Total loss : 88.78421020507812\n",
      "learning rate A :  tf.Tensor(9.969912e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 276 is 0.0775 sec\n",
      "train AE loss : 0.8549457788467407, train ANN loss : 3.4185197353363037\n",
      "AE loss : 0.854485034942627, ANN loss : 3.3298463821411133, Total loss : 88.77835083007812\n",
      "learning rate A :  tf.Tensor(9.969702e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 277 is 0.0757 sec\n",
      "train AE loss : 0.8548857569694519, train ANN loss : 3.420732021331787\n",
      "AE loss : 0.8535653352737427, ANN loss : 3.3245880603790283, Total loss : 88.68112182617188\n",
      "learning rate A :  tf.Tensor(9.969702e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 278 is 0.0767 sec\n",
      "train AE loss : 0.8538698554039001, train ANN loss : 3.420590877532959\n",
      "AE loss : 0.8535069823265076, ANN loss : 3.324589967727661, Total loss : 88.67529296875\n",
      "learning rate A :  tf.Tensor(9.969492e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 279 is 0.0735 sec\n",
      "train AE loss : 0.8538099527359009, train ANN loss : 3.407336711883545\n",
      "AE loss : 0.8528034090995789, ANN loss : 3.319267511367798, Total loss : 88.59960174560547\n",
      "learning rate A :  tf.Tensor(9.969492e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 280 is 0.0761 sec\n",
      "train AE loss : 0.8530136942863464, train ANN loss : 3.4215431213378906\n",
      "AE loss : 0.8527451157569885, ANN loss : 3.3192691802978516, Total loss : 88.59378814697266\n",
      "learning rate A :  tf.Tensor(9.969282e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 281 is 0.0733 sec\n",
      "train AE loss : 0.8529536724090576, train ANN loss : 3.4125258922576904\n",
      "AE loss : 0.8526868224143982, ANN loss : 3.3192715644836426, Total loss : 88.58795928955078\n",
      "learning rate A :  tf.Tensor(9.969072e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 282 is 0.0736 sec\n",
      "train AE loss : 0.8528938293457031, train ANN loss : 3.4122884273529053\n",
      "AE loss : 0.8521013259887695, ANN loss : 3.313878059387207, Total loss : 88.52400970458984\n",
      "learning rate A :  tf.Tensor(9.969072e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 283 is 0.0765 sec\n",
      "train AE loss : 0.852203905582428, train ANN loss : 3.4107885360717773\n",
      "AE loss : 0.8520428538322449, ANN loss : 3.313880443572998, Total loss : 88.5181655883789\n",
      "learning rate A :  tf.Tensor(9.9688616e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 284 is 0.0730 sec\n",
      "train AE loss : 0.8521436452865601, train ANN loss : 3.410658836364746\n",
      "AE loss : 0.851984441280365, ANN loss : 3.313882350921631, Total loss : 88.51232147216797\n",
      "learning rate A :  tf.Tensor(9.968652e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 285 is 0.0738 sec\n",
      "train AE loss : 0.8520836234092712, train ANN loss : 3.4118058681488037\n",
      "AE loss : 0.8519260883331299, ANN loss : 3.3138844966888428, Total loss : 88.5064926147461\n",
      "learning rate A :  tf.Tensor(9.968442e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 286 is 0.0747 sec\n",
      "train AE loss : 0.8520236015319824, train ANN loss : 3.4174742698669434\n",
      "AE loss : 0.8518677353858948, ANN loss : 3.313886880874634, Total loss : 88.50066375732422\n",
      "learning rate A :  tf.Tensor(9.9682315e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 287 is 0.0738 sec\n",
      "train AE loss : 0.851963460445404, train ANN loss : 3.4098291397094727\n",
      "AE loss : 0.8518093824386597, ANN loss : 3.3138890266418457, Total loss : 88.49482727050781\n",
      "learning rate A :  tf.Tensor(9.968022e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 288 is 0.0740 sec\n",
      "train AE loss : 0.85190349817276, train ANN loss : 3.403815269470215\n",
      "AE loss : 0.8517512083053589, ANN loss : 3.3138914108276367, Total loss : 88.48900604248047\n",
      "learning rate A :  tf.Tensor(9.967812e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 289 is 0.0744 sec\n",
      "train AE loss : 0.8518434762954712, train ANN loss : 3.4136242866516113\n",
      "AE loss : 0.8516930341720581, ANN loss : 3.3138937950134277, Total loss : 88.48320007324219\n",
      "learning rate A :  tf.Tensor(9.967601e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 290 is 0.0810 sec\n",
      "train AE loss : 0.8517836332321167, train ANN loss : 3.4120564460754395\n",
      "AE loss : 0.8516348600387573, ANN loss : 3.3138957023620605, Total loss : 88.47737884521484\n",
      "learning rate A :  tf.Tensor(9.967391e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 291 is 0.0734 sec\n",
      "train AE loss : 0.8517237901687622, train ANN loss : 3.4126527309417725\n",
      "AE loss : 0.8515766859054565, ANN loss : 3.3138978481292725, Total loss : 88.4715576171875\n",
      "learning rate A :  tf.Tensor(9.9671815e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 292 is 0.0750 sec\n",
      "train AE loss : 0.8516639471054077, train ANN loss : 3.4128262996673584\n",
      "AE loss : 0.851090133190155, ANN loss : 3.308534622192383, Total loss : 88.41754913330078\n",
      "learning rate A :  tf.Tensor(9.9671815e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 293 is 0.0754 sec\n",
      "train AE loss : 0.8510595560073853, train ANN loss : 3.405223846435547\n",
      "AE loss : 0.8510318398475647, ANN loss : 3.308537006378174, Total loss : 88.41172790527344\n",
      "learning rate A :  tf.Tensor(9.966971e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 294 is 0.0737 sec\n",
      "train AE loss : 0.8509995341300964, train ANN loss : 3.4059455394744873\n",
      "AE loss : 0.8509735465049744, ANN loss : 3.308539390563965, Total loss : 88.40589141845703\n",
      "learning rate A :  tf.Tensor(9.966761e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 295 is 0.0757 sec\n",
      "train AE loss : 0.8509395122528076, train ANN loss : 3.401017665863037\n",
      "AE loss : 0.8505020141601562, ANN loss : 3.302926778793335, Total loss : 88.3531265258789\n",
      "learning rate A :  tf.Tensor(9.966761e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 296 is 0.0764 sec\n",
      "train AE loss : 0.8503531813621521, train ANN loss : 3.4082698822021484\n",
      "AE loss : 0.8504435420036316, ANN loss : 3.302929162979126, Total loss : 88.34728240966797\n",
      "learning rate A :  tf.Tensor(9.966551e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 297 is 0.0848 sec\n",
      "train AE loss : 0.8502929210662842, train ANN loss : 3.3997018337249756\n",
      "AE loss : 0.8503852486610413, ANN loss : 3.302932024002075, Total loss : 88.34146118164062\n",
      "learning rate A :  tf.Tensor(9.9663404e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 298 is 0.0759 sec\n",
      "train AE loss : 0.8502327799797058, train ANN loss : 3.405813455581665\n",
      "AE loss : 0.8503268957138062, ANN loss : 3.3029346466064453, Total loss : 88.33562469482422\n",
      "learning rate A :  tf.Tensor(9.966131e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 299 is 0.0738 sec\n",
      "train AE loss : 0.850172758102417, train ANN loss : 3.406402111053467\n",
      "AE loss : 0.850268542766571, ANN loss : 3.3029372692108154, Total loss : 88.32979583740234\n",
      "learning rate A :  tf.Tensor(9.9659206e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 300 is 0.0751 sec\n",
      "train AE loss : 0.8501127362251282, train ANN loss : 3.405381679534912\n",
      "AE loss : 0.8499055504798889, ANN loss : 3.297234296798706, Total loss : 88.28779602050781\n",
      "learning rate A :  tf.Tensor(9.9659206e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 301 is 0.0764 sec\n",
      "train AE loss : 0.8496302962303162, train ANN loss : 3.3957808017730713\n",
      "AE loss : 0.8496295213699341, ANN loss : 3.291390895843506, Total loss : 88.25434112548828\n",
      "learning rate A :  tf.Tensor(9.9659206e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 302 is 0.0751 sec\n",
      "train AE loss : 0.849230945110321, train ANN loss : 3.3989243507385254\n",
      "AE loss : 0.8495704531669617, ANN loss : 3.291393756866455, Total loss : 88.2484359741211\n",
      "learning rate A :  tf.Tensor(9.96571e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 303 is 0.0733 sec\n",
      "train AE loss : 0.849169909954071, train ANN loss : 3.395030975341797\n",
      "AE loss : 0.8495113253593445, ANN loss : 3.2913970947265625, Total loss : 88.2425308227539\n",
      "learning rate A :  tf.Tensor(9.965501e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 304 is 0.0743 sec\n",
      "train AE loss : 0.8491089940071106, train ANN loss : 3.3949735164642334\n",
      "AE loss : 0.8492193222045898, ANN loss : 3.285456418991089, Total loss : 88.2073974609375\n",
      "learning rate A :  tf.Tensor(9.965501e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 305 is 0.0785 sec\n",
      "train AE loss : 0.8486871719360352, train ANN loss : 3.3855092525482178\n",
      "AE loss : 0.849087119102478, ANN loss : 3.2793941497802734, Total loss : 88.18810272216797\n",
      "learning rate A :  tf.Tensor(9.965501e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 306 is 0.0764 sec\n",
      "train AE loss : 0.8484286665916443, train ANN loss : 3.3938302993774414\n",
      "AE loss : 0.8489700555801392, ANN loss : 3.2735447883605957, Total loss : 88.17053985595703\n",
      "learning rate A :  tf.Tensor(9.965501e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 307 is 0.0774 sec\n",
      "train AE loss : 0.8481971621513367, train ANN loss : 3.3808319568634033\n",
      "AE loss : 0.8489089608192444, ANN loss : 3.2735486030578613, Total loss : 88.1644515991211\n",
      "learning rate A :  tf.Tensor(9.9652905e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 308 is 0.0740 sec\n",
      "train AE loss : 0.8481343388557434, train ANN loss : 3.3859143257141113\n",
      "AE loss : 0.8489453792572021, ANN loss : 3.267533779144287, Total loss : 88.16207122802734\n",
      "learning rate A :  tf.Tensor(9.9652905e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 309 is 0.0757 sec\n",
      "train AE loss : 0.8480542898178101, train ANN loss : 3.371751546859741\n",
      "AE loss : 0.8491064310073853, ANN loss : 3.261624574661255, Total loss : 88.17227172851562\n",
      "learning rate A :  tf.Tensor(9.9652905e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 310 is 0.0770 sec\n",
      "train AE loss : 0.8480916619300842, train ANN loss : 3.371201753616333\n",
      "AE loss : 0.8495399951934814, ANN loss : 3.2557685375213623, Total loss : 88.20977020263672\n",
      "learning rate A :  tf.Tensor(9.9652905e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 311 is 0.0767 sec\n",
      "train AE loss : 0.8483801484107971, train ANN loss : 3.362180471420288\n",
      "AE loss : 0.8502622246742249, ANN loss : 3.249875783920288, Total loss : 88.2761001586914\n",
      "learning rate A :  tf.Tensor(9.9652905e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 312 is 0.0769 sec\n",
      "train AE loss : 0.8489464521408081, train ANN loss : 3.364889144897461\n",
      "AE loss : 0.8513948917388916, ANN loss : 3.2439255714416504, Total loss : 88.38341522216797\n",
      "learning rate A :  tf.Tensor(9.9652905e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 313 is 0.0766 sec\n",
      "train AE loss : 0.8499119877815247, train ANN loss : 3.3563902378082275\n",
      "AE loss : 0.8513244986534119, ANN loss : 3.243931293487549, Total loss : 88.37637329101562\n",
      "learning rate A :  tf.Tensor(9.965081e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 314 is 0.0737 sec\n",
      "train AE loss : 0.8498400449752808, train ANN loss : 3.3606836795806885\n",
      "AE loss : 0.8526279330253601, ANN loss : 3.238354206085205, Total loss : 88.50115203857422\n",
      "learning rate A :  tf.Tensor(9.965081e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 315 is 0.0759 sec\n",
      "train AE loss : 0.8509691953659058, train ANN loss : 3.354434013366699\n",
      "AE loss : 0.8525546193122864, ANN loss : 3.238360643386841, Total loss : 88.49382019042969\n",
      "learning rate A :  tf.Tensor(9.964871e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 316 is 0.0751 sec\n",
      "train AE loss : 0.8508943319320679, train ANN loss : 3.352741241455078\n",
      "AE loss : 0.8540549874305725, ANN loss : 3.2327091693878174, Total loss : 88.6382064819336\n",
      "learning rate A :  tf.Tensor(9.964871e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 317 is 0.0759 sec\n",
      "train AE loss : 0.8522061109542847, train ANN loss : 3.349381446838379\n",
      "AE loss : 0.8539780974388123, ANN loss : 3.2327160835266113, Total loss : 88.63053131103516\n",
      "learning rate A :  tf.Tensor(9.9646604e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 318 is 0.0746 sec\n",
      "train AE loss : 0.8521279096603394, train ANN loss : 3.3435845375061035\n",
      "AE loss : 0.8539012670516968, ANN loss : 3.232722520828247, Total loss : 88.62286376953125\n",
      "learning rate A :  tf.Tensor(9.964451e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 319 is 0.0745 sec\n",
      "train AE loss : 0.8520496487617493, train ANN loss : 3.349644660949707\n",
      "AE loss : 0.8554466366767883, ANN loss : 3.227180004119873, Total loss : 88.77184295654297\n",
      "learning rate A :  tf.Tensor(9.964451e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 320 is 0.0757 sec\n",
      "train AE loss : 0.8533945679664612, train ANN loss : 3.345597982406616\n",
      "AE loss : 0.8553659319877625, ANN loss : 3.227187395095825, Total loss : 88.76377868652344\n",
      "learning rate A :  tf.Tensor(9.964241e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 321 is 0.0733 sec\n",
      "train AE loss : 0.8533128499984741, train ANN loss : 3.3468716144561768\n",
      "AE loss : 0.8552852869033813, ANN loss : 3.227194309234619, Total loss : 88.75572204589844\n",
      "learning rate A :  tf.Tensor(9.964031e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 322 is 0.0752 sec\n",
      "train AE loss : 0.8532313108444214, train ANN loss : 3.3532042503356934\n",
      "AE loss : 0.8552048802375793, ANN loss : 3.227201223373413, Total loss : 88.7476806640625\n",
      "learning rate A :  tf.Tensor(9.963821e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 323 is 0.0891 sec\n",
      "train AE loss : 0.8531497716903687, train ANN loss : 3.3470211029052734\n",
      "AE loss : 0.8551245927810669, ANN loss : 3.2272086143493652, Total loss : 88.73966979980469\n",
      "learning rate A :  tf.Tensor(9.963611e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 324 is 0.0916 sec\n",
      "train AE loss : 0.8530683517456055, train ANN loss : 3.3473384380340576\n",
      "AE loss : 0.8550443649291992, ANN loss : 3.227215528488159, Total loss : 88.73165893554688\n",
      "learning rate A :  tf.Tensor(9.963401e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 325 is 0.0748 sec\n",
      "train AE loss : 0.8529869914054871, train ANN loss : 3.3496592044830322\n",
      "AE loss : 0.856545627117157, ANN loss : 3.2217860221862793, Total loss : 88.87635040283203\n",
      "learning rate A :  tf.Tensor(9.963401e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 326 is 0.0843 sec\n",
      "train AE loss : 0.8542793393135071, train ANN loss : 3.340139627456665\n",
      "AE loss : 0.8583760261535645, ANN loss : 3.2162535190582275, Total loss : 89.05384826660156\n",
      "learning rate A :  tf.Tensor(9.963401e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 327 is 0.0778 sec\n",
      "train AE loss : 0.855895459651947, train ANN loss : 3.3347928524017334\n",
      "AE loss : 0.8602189421653748, ANN loss : 3.2107040882110596, Total loss : 89.23259735107422\n",
      "learning rate A :  tf.Tensor(9.963401e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 328 is 0.0754 sec\n",
      "train AE loss : 0.857525646686554, train ANN loss : 3.3249893188476562\n",
      "AE loss : 0.8601254224777222, ANN loss : 3.2107129096984863, Total loss : 89.22325897216797\n",
      "learning rate A :  tf.Tensor(9.963191e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 329 is 0.0736 sec\n",
      "train AE loss : 0.8574314713478088, train ANN loss : 3.3248376846313477\n",
      "AE loss : 0.8622353076934814, ANN loss : 3.2050185203552246, Total loss : 89.42855834960938\n",
      "learning rate A :  tf.Tensor(9.963191e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 330 is 0.0771 sec\n",
      "train AE loss : 0.859330952167511, train ANN loss : 3.323028087615967\n",
      "AE loss : 0.864843487739563, ANN loss : 3.1993184089660645, Total loss : 89.68367004394531\n",
      "learning rate A :  tf.Tensor(9.963191e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 331 is 0.0749 sec\n",
      "train AE loss : 0.8617228865623474, train ANN loss : 3.321453094482422\n",
      "AE loss : 0.8676659464836121, ANN loss : 3.1933817863464355, Total loss : 89.95997619628906\n",
      "learning rate A :  tf.Tensor(9.963191e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 332 is 0.0751 sec\n",
      "train AE loss : 0.8643115758895874, train ANN loss : 3.31699538230896\n",
      "AE loss : 0.867553174495697, ANN loss : 3.193392038345337, Total loss : 89.94871520996094\n",
      "learning rate A :  tf.Tensor(9.962981e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 333 is 0.0801 sec\n",
      "train AE loss : 0.8641983866691589, train ANN loss : 3.316241502761841\n",
      "AE loss : 0.8674406409263611, ANN loss : 3.1934027671813965, Total loss : 89.93746948242188\n",
      "learning rate A :  tf.Tensor(9.9627716e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 334 is 0.0760 sec\n",
      "train AE loss : 0.8640852570533752, train ANN loss : 3.3157076835632324\n",
      "AE loss : 0.8673281073570251, ANN loss : 3.1934127807617188, Total loss : 89.92622375488281\n",
      "learning rate A :  tf.Tensor(9.962561e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 335 is 0.0748 sec\n",
      "train AE loss : 0.8639723062515259, train ANN loss : 3.3176891803741455\n",
      "AE loss : 0.8704494833946228, ANN loss : 3.1873652935028076, Total loss : 90.23230743408203\n",
      "learning rate A :  tf.Tensor(9.962561e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 336 is 0.0770 sec\n",
      "train AE loss : 0.8668648600578308, train ANN loss : 3.318134069442749\n",
      "AE loss : 0.8737327456474304, ANN loss : 3.181309938430786, Total loss : 90.55458068847656\n",
      "learning rate A :  tf.Tensor(9.962561e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 337 is 0.0747 sec\n",
      "train AE loss : 0.8699321150779724, train ANN loss : 3.3131699562072754\n",
      "AE loss : 0.8736027479171753, ANN loss : 3.181321382522583, Total loss : 90.54159545898438\n",
      "learning rate A :  tf.Tensor(9.962352e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 338 is 0.0735 sec\n",
      "train AE loss : 0.8698015213012695, train ANN loss : 3.309699773788452\n",
      "AE loss : 0.8734728097915649, ANN loss : 3.181333065032959, Total loss : 90.52861785888672\n",
      "learning rate A :  tf.Tensor(9.962142e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 339 is 0.0749 sec\n",
      "train AE loss : 0.8696712851524353, train ANN loss : 3.305412530899048\n",
      "AE loss : 0.8733432292938232, ANN loss : 3.181344509124756, Total loss : 90.51566314697266\n",
      "learning rate A :  tf.Tensor(9.961931e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 340 is 0.0740 sec\n",
      "train AE loss : 0.8695411682128906, train ANN loss : 3.3048653602600098\n",
      "AE loss : 0.8732138276100159, ANN loss : 3.181356191635132, Total loss : 90.50273895263672\n",
      "learning rate A :  tf.Tensor(9.961722e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 341 is 0.0732 sec\n",
      "train AE loss : 0.8694115281105042, train ANN loss : 3.3142547607421875\n",
      "AE loss : 0.8770682215690613, ANN loss : 3.1752421855926514, Total loss : 90.88207244873047\n",
      "learning rate A :  tf.Tensor(9.961722e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 342 is 0.0764 sec\n",
      "train AE loss : 0.8730202913284302, train ANN loss : 3.3017404079437256\n",
      "AE loss : 0.8769288063049316, ANN loss : 3.1752541065216064, Total loss : 90.8681411743164\n",
      "learning rate A :  tf.Tensor(9.961512e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 343 is 0.0733 sec\n",
      "train AE loss : 0.8728809356689453, train ANN loss : 3.302535057067871\n",
      "AE loss : 0.8767895102500916, ANN loss : 3.1752662658691406, Total loss : 90.85420989990234\n",
      "learning rate A :  tf.Tensor(9.961302e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 344 is 0.0734 sec\n",
      "train AE loss : 0.8727415204048157, train ANN loss : 3.305452823638916\n",
      "AE loss : 0.881212055683136, ANN loss : 3.1688449382781982, Total loss : 91.29005432128906\n",
      "learning rate A :  tf.Tensor(9.961302e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 345 is 0.0761 sec\n",
      "train AE loss : 0.8768855333328247, train ANN loss : 3.3011910915374756\n",
      "AE loss : 0.8810607194900513, ANN loss : 3.1688578128814697, Total loss : 91.2749252319336\n",
      "learning rate A :  tf.Tensor(9.961092e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 346 is 0.0729 sec\n",
      "train AE loss : 0.8767344951629639, train ANN loss : 3.298222780227661\n",
      "AE loss : 0.8809098601341248, ANN loss : 3.1688709259033203, Total loss : 91.25985717773438\n",
      "learning rate A :  tf.Tensor(9.960883e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 347 is 0.0734 sec\n",
      "train AE loss : 0.8765838146209717, train ANN loss : 3.2995445728302\n",
      "AE loss : 0.8859097957611084, ANN loss : 3.1623616218566895, Total loss : 91.75333404541016\n",
      "learning rate A :  tf.Tensor(9.960883e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 348 is 0.0763 sec\n",
      "train AE loss : 0.8812848925590515, train ANN loss : 3.299973964691162\n",
      "AE loss : 0.8909589052200317, ANN loss : 3.1558191776275635, Total loss : 92.251708984375\n",
      "learning rate A :  tf.Tensor(9.960883e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 349 is 0.0755 sec\n",
      "train AE loss : 0.886014997959137, train ANN loss : 3.2879559993743896\n",
      "AE loss : 0.8907780051231384, ANN loss : 3.1558334827423096, Total loss : 92.23363494873047\n",
      "learning rate A :  tf.Tensor(9.960672e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 350 is 0.0735 sec\n",
      "train AE loss : 0.885835587978363, train ANN loss : 3.2874128818511963\n",
      "AE loss : 0.8905975222587585, ANN loss : 3.1558480262756348, Total loss : 92.2155990600586\n",
      "learning rate A :  tf.Tensor(9.960462e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 351 is 0.0746 sec\n",
      "train AE loss : 0.885656476020813, train ANN loss : 3.28544020652771\n",
      "AE loss : 0.8962997794151306, ANN loss : 3.149311065673828, Total loss : 92.77928161621094\n",
      "learning rate A :  tf.Tensor(9.960462e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 352 is 0.0760 sec\n",
      "train AE loss : 0.8910260796546936, train ANN loss : 3.278533935546875\n",
      "AE loss : 0.8960915803909302, ANN loss : 3.1493265628814697, Total loss : 92.75848388671875\n",
      "learning rate A :  tf.Tensor(9.960253e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 353 is 0.0735 sec\n",
      "train AE loss : 0.8908188343048096, train ANN loss : 3.286936044692993\n",
      "AE loss : 0.8958837389945984, ANN loss : 3.1493418216705322, Total loss : 92.73770904541016\n",
      "learning rate A :  tf.Tensor(9.9600424e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 354 is 0.0752 sec\n",
      "train AE loss : 0.8906122446060181, train ANN loss : 3.2908122539520264\n",
      "AE loss : 0.9018427729606628, ANN loss : 3.142672061920166, Total loss : 93.32695007324219\n",
      "learning rate A :  tf.Tensor(9.9600424e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 355 is 0.0763 sec\n",
      "train AE loss : 0.8962634205818176, train ANN loss : 3.283520221710205\n",
      "AE loss : 0.9016157388687134, ANN loss : 3.142688751220703, Total loss : 93.30426788330078\n",
      "learning rate A :  tf.Tensor(9.959833e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 356 is 0.0743 sec\n",
      "train AE loss : 0.8960378170013428, train ANN loss : 3.28043532371521\n",
      "AE loss : 0.9013891816139221, ANN loss : 3.1427054405212402, Total loss : 93.28162384033203\n",
      "learning rate A :  tf.Tensor(9.959623e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 357 is 0.0756 sec\n",
      "train AE loss : 0.8958126306533813, train ANN loss : 3.28464412689209\n",
      "AE loss : 0.9011632800102234, ANN loss : 3.1427223682403564, Total loss : 93.25904846191406\n",
      "learning rate A :  tf.Tensor(9.959413e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 358 is 0.0741 sec\n",
      "train AE loss : 0.8955880403518677, train ANN loss : 3.283184289932251\n",
      "AE loss : 0.9077172875404358, ANN loss : 3.1358401775360107, Total loss : 93.9075698852539\n",
      "learning rate A :  tf.Tensor(9.959413e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 359 is 0.0769 sec\n",
      "train AE loss : 0.9018503427505493, train ANN loss : 3.2704315185546875\n",
      "AE loss : 0.9148431420326233, ANN loss : 3.1288650035858154, Total loss : 94.6131820678711\n",
      "learning rate A :  tf.Tensor(9.959413e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 360 is 0.0780 sec\n",
      "train AE loss : 0.9087166786193848, train ANN loss : 3.27105712890625\n",
      "AE loss : 0.9145596027374268, ANN loss : 3.1288845539093018, Total loss : 94.58484649658203\n",
      "learning rate A :  tf.Tensor(9.9592035e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 361 is 0.0752 sec\n",
      "train AE loss : 0.9084339737892151, train ANN loss : 3.265624523162842\n",
      "AE loss : 0.9142767786979675, ANN loss : 3.128904342651367, Total loss : 94.55657958984375\n",
      "learning rate A :  tf.Tensor(9.958993e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 362 is 0.0800 sec\n",
      "train AE loss : 0.9081519842147827, train ANN loss : 3.2714338302612305\n",
      "AE loss : 0.9139948487281799, ANN loss : 3.1289238929748535, Total loss : 94.52841186523438\n",
      "learning rate A :  tf.Tensor(9.9587836e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 363 is 0.0783 sec\n",
      "train AE loss : 0.9078707695007324, train ANN loss : 3.2655882835388184\n",
      "AE loss : 0.9137134552001953, ANN loss : 3.1289432048797607, Total loss : 94.50028991699219\n",
      "learning rate A :  tf.Tensor(9.958574e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 364 is 0.0753 sec\n",
      "train AE loss : 0.9075902104377747, train ANN loss : 3.272357702255249\n",
      "AE loss : 0.9217476844787598, ANN loss : 3.12206768989563, Total loss : 95.29684448242188\n",
      "learning rate A :  tf.Tensor(9.958574e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 365 is 0.0771 sec\n",
      "train AE loss : 0.9153590798377991, train ANN loss : 3.266683340072632\n",
      "AE loss : 0.9305201172828674, ANN loss : 3.1150639057159424, Total loss : 96.16707611083984\n",
      "learning rate A :  tf.Tensor(9.958574e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 366 is 0.0775 sec\n",
      "train AE loss : 0.923860490322113, train ANN loss : 3.261810779571533\n",
      "AE loss : 0.9301773905754089, ANN loss : 3.1150858402252197, Total loss : 96.13282012939453\n",
      "learning rate A :  tf.Tensor(9.958364e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 367 is 0.0758 sec\n",
      "train AE loss : 0.9235204458236694, train ANN loss : 3.2636008262634277\n",
      "AE loss : 0.929835855960846, ANN loss : 3.115107536315918, Total loss : 96.09870147705078\n",
      "learning rate A :  tf.Tensor(9.958154e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 368 is 0.0754 sec\n",
      "train AE loss : 0.9231814742088318, train ANN loss : 3.2661068439483643\n",
      "AE loss : 0.9294951558113098, ANN loss : 3.1151297092437744, Total loss : 96.06464385986328\n",
      "learning rate A :  tf.Tensor(9.957945e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 369 is 0.0760 sec\n",
      "train AE loss : 0.9228434562683105, train ANN loss : 3.258789300918579\n",
      "AE loss : 0.9388777017593384, ANN loss : 3.1080729961395264, Total loss : 96.99584197998047\n",
      "learning rate A :  tf.Tensor(9.957945e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 370 is 0.0783 sec\n",
      "train AE loss : 0.9319339394569397, train ANN loss : 3.2585713863372803\n",
      "AE loss : 0.9385024905204773, ANN loss : 3.108096122741699, Total loss : 96.95834350585938\n",
      "learning rate A :  tf.Tensor(9.9577344e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 371 is 0.0759 sec\n",
      "train AE loss : 0.9315617680549622, train ANN loss : 3.259558916091919\n",
      "AE loss : 0.9381283521652222, ANN loss : 3.108119249343872, Total loss : 96.92095947265625\n",
      "learning rate A :  tf.Tensor(9.957525e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 372 is 0.0756 sec\n",
      "train AE loss : 0.9311906695365906, train ANN loss : 3.251593828201294\n",
      "AE loss : 0.9377552270889282, ANN loss : 3.108142137527466, Total loss : 96.88365936279297\n",
      "learning rate A :  tf.Tensor(9.957315e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 373 is 0.0754 sec\n",
      "train AE loss : 0.9308207035064697, train ANN loss : 3.255988836288452\n",
      "AE loss : 0.9373830556869507, ANN loss : 3.1081652641296387, Total loss : 96.84646606445312\n",
      "learning rate A :  tf.Tensor(9.957105e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 374 is 0.0746 sec\n",
      "train AE loss : 0.9304516315460205, train ANN loss : 3.249196767807007\n",
      "AE loss : 0.9370118975639343, ANN loss : 3.1081883907318115, Total loss : 96.80937957763672\n",
      "learning rate A :  tf.Tensor(9.9568955e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 375 is 0.0760 sec\n",
      "train AE loss : 0.930083692073822, train ANN loss : 3.2616329193115234\n",
      "AE loss : 0.9468693137168884, ANN loss : 3.1010584831237793, Total loss : 97.7879867553711\n",
      "learning rate A :  tf.Tensor(9.9568955e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 376 is 0.0765 sec\n",
      "train AE loss : 0.9396365880966187, train ANN loss : 3.249932289123535\n",
      "AE loss : 0.9573061466217041, ANN loss : 3.093874216079712, Total loss : 98.82449340820312\n",
      "learning rate A :  tf.Tensor(9.9568955e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 377 is 0.0781 sec\n",
      "train AE loss : 0.9497384428977966, train ANN loss : 3.24601411819458\n",
      "AE loss : 0.9680572748184204, ANN loss : 3.086566686630249, Total loss : 99.89228820800781\n",
      "learning rate A :  tf.Tensor(9.9568955e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 378 is 0.0786 sec\n",
      "train AE loss : 0.9601191282272339, train ANN loss : 3.246699094772339\n",
      "AE loss : 0.9675614237785339, ANN loss : 3.086594343185425, Total loss : 99.84273529052734\n",
      "learning rate A :  tf.Tensor(9.956686e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 379 is 0.0749 sec\n",
      "train AE loss : 0.9596289992332458, train ANN loss : 3.244614601135254\n",
      "AE loss : 0.9792481064796448, ANN loss : 3.0792627334594727, Total loss : 101.00407409667969\n",
      "learning rate A :  tf.Tensor(9.956686e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 380 is 0.0772 sec\n",
      "train AE loss : 0.9709134697914124, train ANN loss : 3.248654365539551\n",
      "AE loss : 0.978702962398529, ANN loss : 3.079292058944702, Total loss : 100.9495849609375\n",
      "learning rate A :  tf.Tensor(9.956476e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 381 is 0.0756 sec\n",
      "train AE loss : 0.9703755378723145, train ANN loss : 3.2331316471099854\n",
      "AE loss : 0.9781596064567566, ANN loss : 3.0793213844299316, Total loss : 100.89529418945312\n",
      "learning rate A :  tf.Tensor(9.956266e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 382 is 0.0751 sec\n",
      "train AE loss : 0.9698397517204285, train ANN loss : 3.222630500793457\n",
      "AE loss : 0.991016685962677, ANN loss : 3.071796178817749, Total loss : 102.1734619140625\n",
      "learning rate A :  tf.Tensor(9.956266e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 383 is 0.0774 sec\n",
      "train AE loss : 0.982265293598175, train ANN loss : 3.223816156387329\n",
      "AE loss : 0.9904182553291321, ANN loss : 3.0718274116516113, Total loss : 102.1136474609375\n",
      "learning rate A :  tf.Tensor(9.956056e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 384 is 0.0760 sec\n",
      "train AE loss : 0.9816747307777405, train ANN loss : 3.2325265407562256\n",
      "AE loss : 1.0046557188034058, ANN loss : 3.064223051071167, Total loss : 103.52979278564453\n",
      "learning rate A :  tf.Tensor(9.956056e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 385 is 0.0770 sec\n",
      "train AE loss : 0.9954642653465271, train ANN loss : 3.2208101749420166\n",
      "AE loss : 1.0039931535720825, ANN loss : 3.0642552375793457, Total loss : 103.46356964111328\n",
      "learning rate A :  tf.Tensor(9.955846e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 386 is 0.0755 sec\n",
      "train AE loss : 0.9948116540908813, train ANN loss : 3.223482847213745\n",
      "AE loss : 1.0033330917358398, ANN loss : 3.0642881393432617, Total loss : 103.39759826660156\n",
      "learning rate A :  tf.Tensor(9.955637e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 387 is 0.0766 sec\n",
      "train AE loss : 0.9941615462303162, train ANN loss : 3.2209808826446533\n",
      "AE loss : 1.0026755332946777, ANN loss : 3.0643205642700195, Total loss : 103.33187866210938\n",
      "learning rate A :  tf.Tensor(9.955426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 388 is 0.0762 sec\n",
      "train AE loss : 0.9935140013694763, train ANN loss : 3.2287817001342773\n",
      "AE loss : 1.017051100730896, ANN loss : 3.0566022396087646, Total loss : 104.76171875\n",
      "learning rate A :  tf.Tensor(9.955426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 389 is 0.0856 sec\n",
      "train AE loss : 1.0074142217636108, train ANN loss : 3.2192184925079346\n",
      "AE loss : 1.0320817232131958, ANN loss : 3.0488336086273193, Total loss : 106.25701141357422\n",
      "learning rate A :  tf.Tensor(9.955426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 390 is 0.0929 sec\n",
      "train AE loss : 1.0219569206237793, train ANN loss : 3.2123024463653564\n",
      "AE loss : 1.0460878610610962, ANN loss : 3.0412893295288086, Total loss : 107.65007781982422\n",
      "learning rate A :  tf.Tensor(9.955426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 391 is 0.0755 sec\n",
      "train AE loss : 1.0354597568511963, train ANN loss : 3.2107961177825928\n",
      "AE loss : 1.0604002475738525, ANN loss : 3.033720016479492, Total loss : 109.07374572753906\n",
      "learning rate A :  tf.Tensor(9.955426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 392 is 0.0754 sec\n",
      "train AE loss : 1.0492455959320068, train ANN loss : 3.2053041458129883\n",
      "AE loss : 1.0768823623657227, ANN loss : 3.0262036323547363, Total loss : 110.71443176269531\n",
      "learning rate A :  tf.Tensor(9.955426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 393 is 0.0759 sec\n",
      "train AE loss : 1.065193772315979, train ANN loss : 3.201901435852051\n",
      "AE loss : 1.0953233242034912, ANN loss : 3.018540143966675, Total loss : 112.55087280273438\n",
      "learning rate A :  tf.Tensor(9.955426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 394 is 0.0744 sec\n",
      "train AE loss : 1.0830729007720947, train ANN loss : 3.195967435836792\n",
      "AE loss : 1.0941932201385498, ANN loss : 3.0185909271240234, Total loss : 112.43791198730469\n",
      "learning rate A :  tf.Tensor(9.955216e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 395 is 0.0738 sec\n",
      "train AE loss : 1.0819627046585083, train ANN loss : 3.1900413036346436\n",
      "AE loss : 1.0930684804916382, ANN loss : 3.018641948699951, Total loss : 112.32548522949219\n",
      "learning rate A :  tf.Tensor(9.955007e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 396 is 0.0770 sec\n",
      "train AE loss : 1.080857515335083, train ANN loss : 3.1925666332244873\n",
      "AE loss : 1.1146539449691772, ANN loss : 3.010877847671509, Total loss : 114.47627258300781\n",
      "learning rate A :  tf.Tensor(9.955007e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 397 is 0.0757 sec\n",
      "train AE loss : 1.1018515825271606, train ANN loss : 3.1870715618133545\n",
      "AE loss : 1.1134133338928223, ANN loss : 3.010929584503174, Total loss : 114.35225677490234\n",
      "learning rate A :  tf.Tensor(9.954797e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 398 is 0.0725 sec\n",
      "train AE loss : 1.1006333827972412, train ANN loss : 3.179797887802124\n",
      "AE loss : 1.112179160118103, ANN loss : 3.010981798171997, Total loss : 114.22889709472656\n",
      "learning rate A :  tf.Tensor(9.954587e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 399 is 0.0733 sec\n",
      "train AE loss : 1.099421739578247, train ANN loss : 3.1901700496673584\n",
      "AE loss : 1.1354588270187378, ANN loss : 3.003272533416748, Total loss : 116.54915618896484\n",
      "learning rate A :  tf.Tensor(9.954587e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 400 is 0.0752 sec\n",
      "train AE loss : 1.1220777034759521, train ANN loss : 3.184561252593994\n",
      "AE loss : 1.1576071977615356, ANN loss : 2.995814800262451, Total loss : 118.75653839111328\n",
      "learning rate A :  tf.Tensor(9.954587e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 401 is 0.0830 sec\n",
      "train AE loss : 1.1435948610305786, train ANN loss : 3.181788206100464\n",
      "AE loss : 1.1561079025268555, ANN loss : 2.995868682861328, Total loss : 118.6066665649414\n",
      "learning rate A :  tf.Tensor(9.954377e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 402 is 0.0752 sec\n",
      "train AE loss : 1.142124891281128, train ANN loss : 3.1800971031188965\n",
      "AE loss : 1.1546169519424438, ANN loss : 2.995922565460205, Total loss : 118.4576187133789\n",
      "learning rate A :  tf.Tensor(9.954167e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 403 is 0.0734 sec\n",
      "train AE loss : 1.1406630277633667, train ANN loss : 3.1726810932159424\n",
      "AE loss : 1.1531339883804321, ANN loss : 2.995976686477661, Total loss : 118.30937957763672\n",
      "learning rate A :  tf.Tensor(9.9539575e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 404 is 0.0754 sec\n",
      "train AE loss : 1.1392091512680054, train ANN loss : 3.1794450283050537\n",
      "AE loss : 1.1516590118408203, ANN loss : 2.996030807495117, Total loss : 118.16193389892578\n",
      "learning rate A :  tf.Tensor(9.953748e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 405 is 0.0735 sec\n",
      "train AE loss : 1.1377629041671753, train ANN loss : 3.1688716411590576\n",
      "AE loss : 1.1742459535598755, ANN loss : 2.988450527191162, Total loss : 120.41304779052734\n",
      "learning rate A :  tf.Tensor(9.953748e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 406 is 0.0750 sec\n",
      "train AE loss : 1.1596953868865967, train ANN loss : 3.1738593578338623\n",
      "AE loss : 1.1726346015930176, ANN loss : 2.9885060787200928, Total loss : 120.25196075439453\n",
      "learning rate A :  tf.Tensor(9.953538e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 407 is 0.0726 sec\n",
      "train AE loss : 1.1581165790557861, train ANN loss : 3.183011531829834\n",
      "AE loss : 1.195146083831787, ANN loss : 2.980896234512329, Total loss : 122.49551391601562\n",
      "learning rate A :  tf.Tensor(9.953538e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 408 is 0.0762 sec\n",
      "train AE loss : 1.1799277067184448, train ANN loss : 3.171459674835205\n",
      "AE loss : 1.2168893814086914, ANN loss : 2.9734444618225098, Total loss : 124.66238403320312\n",
      "learning rate A :  tf.Tensor(9.953538e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 409 is 0.0742 sec\n",
      "train AE loss : 1.2009170055389404, train ANN loss : 3.155038356781006\n",
      "AE loss : 1.2149893045425415, ANN loss : 2.973505735397339, Total loss : 124.4724349975586\n",
      "learning rate A :  tf.Tensor(9.953329e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 410 is 0.0736 sec\n",
      "train AE loss : 1.1990569829940796, train ANN loss : 3.1670470237731934\n",
      "AE loss : 1.2131001949310303, ANN loss : 2.9735665321350098, Total loss : 124.2835922241211\n",
      "learning rate A :  tf.Tensor(9.9531186e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 411 is 0.0738 sec\n",
      "train AE loss : 1.1972074508666992, train ANN loss : 3.164951801300049\n",
      "AE loss : 1.2112222909927368, ANN loss : 2.973628044128418, Total loss : 124.09585571289062\n",
      "learning rate A :  tf.Tensor(9.952909e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 412 is 0.0737 sec\n",
      "train AE loss : 1.1953682899475098, train ANN loss : 3.1616780757904053\n",
      "AE loss : 1.2334703207015991, ANN loss : 2.9662773609161377, Total loss : 126.31330871582031\n",
      "learning rate A :  tf.Tensor(9.952909e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 413 is 0.0745 sec\n",
      "train AE loss : 1.2168543338775635, train ANN loss : 3.145416259765625\n",
      "AE loss : 1.2314503192901611, ANN loss : 2.966341257095337, Total loss : 126.11138153076172\n",
      "learning rate A :  tf.Tensor(9.9526995e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 414 is 0.0740 sec\n",
      "train AE loss : 1.2148751020431519, train ANN loss : 3.1539552211761475\n",
      "AE loss : 1.2294429540634155, ANN loss : 2.9664053916931152, Total loss : 125.91069793701172\n",
      "learning rate A :  tf.Tensor(9.952489e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 415 is 0.0731 sec\n",
      "train AE loss : 1.2129082679748535, train ANN loss : 3.1612393856048584\n",
      "AE loss : 1.251482367515564, ANN loss : 2.9590752124786377, Total loss : 128.10731506347656\n",
      "learning rate A :  tf.Tensor(9.952489e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 416 is 0.0747 sec\n",
      "train AE loss : 1.2341821193695068, train ANN loss : 3.1512694358825684\n",
      "AE loss : 1.273901343345642, ANN loss : 2.951533794403076, Total loss : 130.3416748046875\n",
      "learning rate A :  tf.Tensor(9.952489e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 417 is 0.0760 sec\n",
      "train AE loss : 1.255799412727356, train ANN loss : 3.1370010375976562\n",
      "AE loss : 1.271583080291748, ANN loss : 2.9516046047210693, Total loss : 130.10992431640625\n",
      "learning rate A :  tf.Tensor(9.95228e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 418 is 0.0732 sec\n",
      "train AE loss : 1.2535306215286255, train ANN loss : 3.150357484817505\n",
      "AE loss : 1.2947551012039185, ANN loss : 2.9439282417297363, Total loss : 132.41943359375\n",
      "learning rate A :  tf.Tensor(9.95228e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 419 is 0.0749 sec\n",
      "train AE loss : 1.2758889198303223, train ANN loss : 3.1381826400756836\n",
      "AE loss : 1.2922769784927368, ANN loss : 2.944002151489258, Total loss : 132.17169189453125\n",
      "learning rate A :  tf.Tensor(9.95207e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 420 is 0.0739 sec\n",
      "train AE loss : 1.2734642028808594, train ANN loss : 3.134127616882324\n",
      "AE loss : 1.3185278177261353, ANN loss : 2.9362359046936035, Total loss : 134.7890167236328\n",
      "learning rate A :  tf.Tensor(9.95207e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 421 is 0.0749 sec\n",
      "train AE loss : 1.2988883256912231, train ANN loss : 3.1375467777252197\n",
      "AE loss : 1.3460967540740967, ANN loss : 2.9286859035491943, Total loss : 137.53836059570312\n",
      "learning rate A :  tf.Tensor(9.95207e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 422 is 0.0753 sec\n",
      "train AE loss : 1.325631856918335, train ANN loss : 3.1300442218780518\n",
      "AE loss : 1.3432044982910156, ANN loss : 2.928760051727295, Total loss : 137.24920654296875\n",
      "learning rate A :  tf.Tensor(9.9518606e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 423 is 0.0751 sec\n",
      "train AE loss : 1.3228005170822144, train ANN loss : 3.1352741718292236\n",
      "AE loss : 1.3403323888778687, ANN loss : 2.9288344383239746, Total loss : 136.96206665039062\n",
      "learning rate A :  tf.Tensor(9.951651e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 424 is 0.0752 sec\n",
      "train AE loss : 1.3199890851974487, train ANN loss : 3.133740186691284\n",
      "AE loss : 1.3690685033798218, ANN loss : 2.921525239944458, Total loss : 139.828369140625\n",
      "learning rate A :  tf.Tensor(9.951651e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 425 is 0.0798 sec\n",
      "train AE loss : 1.3478668928146362, train ANN loss : 3.134644031524658\n",
      "AE loss : 1.3659729957580566, ANN loss : 2.9215996265411377, Total loss : 139.51889038085938\n",
      "learning rate A :  tf.Tensor(9.951441e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 426 is 0.0767 sec\n",
      "train AE loss : 1.344835877418518, train ANN loss : 3.127957582473755\n",
      "AE loss : 1.3629006147384644, ANN loss : 2.9216747283935547, Total loss : 139.21173095703125\n",
      "learning rate A :  tf.Tensor(9.951231e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 427 is 0.0743 sec\n",
      "train AE loss : 1.3418277502059937, train ANN loss : 3.124811887741089\n",
      "AE loss : 1.3598506450653076, ANN loss : 2.9217495918273926, Total loss : 138.90679931640625\n",
      "learning rate A :  tf.Tensor(9.9510224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 428 is 0.0736 sec\n",
      "train AE loss : 1.3388413190841675, train ANN loss : 3.1327197551727295\n",
      "AE loss : 1.392633080482483, ANN loss : 2.914971113204956, Total loss : 142.17828369140625\n",
      "learning rate A :  tf.Tensor(9.9510224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 429 is 0.0761 sec\n",
      "train AE loss : 1.370712399482727, train ANN loss : 3.119952917098999\n",
      "AE loss : 1.427175760269165, ANN loss : 2.9083750247955322, Total loss : 145.62594604492188\n",
      "learning rate A :  tf.Tensor(9.9510224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 430 is 0.0758 sec\n",
      "train AE loss : 1.4043091535568237, train ANN loss : 3.1199982166290283\n",
      "AE loss : 1.4626786708831787, ANN loss : 2.901811122894287, Total loss : 149.16969299316406\n",
      "learning rate A :  tf.Tensor(9.9510224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 431 is 0.0762 sec\n",
      "train AE loss : 1.4388049840927124, train ANN loss : 3.1046125888824463\n",
      "AE loss : 1.458768367767334, ANN loss : 2.901883363723755, Total loss : 148.77871704101562\n",
      "learning rate A :  tf.Tensor(9.950812e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 432 is 0.0750 sec\n",
      "train AE loss : 1.434971809387207, train ANN loss : 3.0956923961639404\n",
      "AE loss : 1.4923419952392578, ANN loss : 2.895211935043335, Total loss : 152.12939453125\n",
      "learning rate A :  tf.Tensor(9.950812e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 433 is 0.0759 sec\n",
      "train AE loss : 1.4674770832061768, train ANN loss : 3.103179693222046\n",
      "AE loss : 1.4881591796875, ANN loss : 2.89528751373291, Total loss : 151.71121215820312\n",
      "learning rate A :  tf.Tensor(9.9506025e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 434 is 0.0742 sec\n",
      "train AE loss : 1.4633793830871582, train ANN loss : 3.1103007793426514\n",
      "AE loss : 1.5158565044403076, ANN loss : 2.8888254165649414, Total loss : 154.47447204589844\n",
      "learning rate A :  tf.Tensor(9.9506025e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 435 is 0.0775 sec\n",
      "train AE loss : 1.49003267288208, train ANN loss : 3.0990149974823\n",
      "AE loss : 1.51144540309906, ANN loss : 2.888909339904785, Total loss : 154.03346252441406\n",
      "learning rate A :  tf.Tensor(9.950392e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 436 is 0.0766 sec\n",
      "train AE loss : 1.4857152700424194, train ANN loss : 3.0961315631866455\n",
      "AE loss : 1.5070722103118896, ANN loss : 2.888993501663208, Total loss : 153.59620666503906\n",
      "learning rate A :  tf.Tensor(9.9501834e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 437 is 0.0749 sec\n",
      "train AE loss : 1.4814341068267822, train ANN loss : 3.091503143310547\n",
      "AE loss : 1.5027360916137695, ANN loss : 2.889078140258789, Total loss : 153.16268920898438\n",
      "learning rate A :  tf.Tensor(9.949974e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 438 is 0.0756 sec\n",
      "train AE loss : 1.4771898984909058, train ANN loss : 3.0867350101470947\n",
      "AE loss : 1.498437523841858, ANN loss : 2.889163017272949, Total loss : 152.73291015625\n",
      "learning rate A :  tf.Tensor(9.9497636e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 439 is 0.0742 sec\n",
      "train AE loss : 1.4729822874069214, train ANN loss : 3.097856283187866\n",
      "AE loss : 1.5229649543762207, ANN loss : 2.8823940753936768, Total loss : 155.17889404296875\n",
      "learning rate A :  tf.Tensor(9.9497636e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 440 is 0.0760 sec\n",
      "train AE loss : 1.4964845180511475, train ANN loss : 3.092991828918457\n",
      "AE loss : 1.5486726760864258, ANN loss : 2.8753933906555176, Total loss : 157.74266052246094\n",
      "learning rate A :  tf.Tensor(9.9497636e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 441 is 0.0775 sec\n",
      "train AE loss : 1.5211528539657593, train ANN loss : 3.087428569793701\n",
      "AE loss : 1.5793921947479248, ANN loss : 2.868054151535034, Total loss : 160.80726623535156\n",
      "learning rate A :  tf.Tensor(9.9497636e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 442 is 0.0757 sec\n",
      "train AE loss : 1.550784945487976, train ANN loss : 3.0800085067749023\n",
      "AE loss : 1.5743238925933838, ANN loss : 2.868168830871582, Total loss : 160.30056762695312\n",
      "learning rate A :  tf.Tensor(9.949554e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 443 is 0.0833 sec\n",
      "train AE loss : 1.5458284616470337, train ANN loss : 3.0844788551330566\n",
      "AE loss : 1.5693018436431885, ANN loss : 2.868283748626709, Total loss : 159.7984619140625\n",
      "learning rate A :  tf.Tensor(9.9493445e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 444 is 0.0747 sec\n",
      "train AE loss : 1.540917158126831, train ANN loss : 3.08237886428833\n",
      "AE loss : 1.564323902130127, ANN loss : 2.8683993816375732, Total loss : 159.30076599121094\n",
      "learning rate A :  tf.Tensor(9.949135e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 445 is 0.0744 sec\n",
      "train AE loss : 1.5360500812530518, train ANN loss : 3.0799169540405273\n",
      "AE loss : 1.5593907833099365, ANN loss : 2.868515729904175, Total loss : 158.80758666992188\n",
      "learning rate A :  tf.Tensor(9.9489254e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 446 is 0.0739 sec\n",
      "train AE loss : 1.5312273502349854, train ANN loss : 3.0903804302215576\n",
      "AE loss : 1.5545024871826172, ANN loss : 2.8686323165893555, Total loss : 158.3188934326172\n",
      "learning rate A :  tf.Tensor(9.948715e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 447 is 0.0744 sec\n",
      "train AE loss : 1.5264478921890259, train ANN loss : 3.0914199352264404\n",
      "AE loss : 1.5496573448181152, ANN loss : 2.8687496185302734, Total loss : 157.83447265625\n",
      "learning rate A :  tf.Tensor(9.948506e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 448 is 0.0748 sec\n",
      "train AE loss : 1.5217093229293823, train ANN loss : 3.0838074684143066\n",
      "AE loss : 1.5448565483093262, ANN loss : 2.8688666820526123, Total loss : 157.35452270507812\n",
      "learning rate A :  tf.Tensor(9.948296e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 449 is 0.0743 sec\n",
      "train AE loss : 1.5170143842697144, train ANN loss : 3.080486536026001\n",
      "AE loss : 1.5400991439819336, ANN loss : 2.8689844608306885, Total loss : 156.87889099121094\n",
      "learning rate A :  tf.Tensor(9.9480865e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 450 is 0.0756 sec\n",
      "train AE loss : 1.5123623609542847, train ANN loss : 3.076411485671997\n",
      "AE loss : 1.579310655593872, ANN loss : 2.861410140991211, Total loss : 160.79248046875\n",
      "learning rate A :  tf.Tensor(9.9480865e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 451 is 0.0771 sec\n",
      "train AE loss : 1.5504833459854126, train ANN loss : 3.074467897415161\n",
      "AE loss : 1.5742181539535522, ANN loss : 2.861525058746338, Total loss : 160.28334045410156\n",
      "learning rate A :  tf.Tensor(9.947877e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 452 is 0.0744 sec\n",
      "train AE loss : 1.5455052852630615, train ANN loss : 3.080760955810547\n",
      "AE loss : 1.614906668663025, ANN loss : 2.853863000869751, Total loss : 164.3445281982422\n",
      "learning rate A :  tf.Tensor(9.947877e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 453 is 0.0769 sec\n",
      "train AE loss : 1.5850998163223267, train ANN loss : 3.069077491760254\n",
      "AE loss : 1.6599560976028442, ANN loss : 2.846500873565674, Total loss : 168.8421173095703\n",
      "learning rate A :  tf.Tensor(9.947877e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 454 is 0.0772 sec\n",
      "train AE loss : 1.628983974456787, train ANN loss : 3.0708911418914795\n",
      "AE loss : 1.703651785850525, ANN loss : 2.839278221130371, Total loss : 173.20445251464844\n",
      "learning rate A :  tf.Tensor(9.947877e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 455 is 0.1211 sec\n",
      "train AE loss : 1.671501636505127, train ANN loss : 3.0629453659057617\n",
      "AE loss : 1.69731867313385, ANN loss : 2.8393709659576416, Total loss : 172.5712432861328\n",
      "learning rate A :  tf.Tensor(9.9476674e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 456 is 0.0893 sec\n",
      "train AE loss : 1.6653121709823608, train ANN loss : 3.055111885070801\n",
      "AE loss : 1.691048502922058, ANN loss : 2.8394644260406494, Total loss : 171.94430541992188\n",
      "learning rate A :  tf.Tensor(9.947458e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 457 is 0.0734 sec\n",
      "train AE loss : 1.6591846942901611, train ANN loss : 3.068230390548706\n",
      "AE loss : 1.684841275215149, ANN loss : 2.8395588397979736, Total loss : 171.3236846923828\n",
      "learning rate A :  tf.Tensor(9.947248e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 458 is 0.1770 sec\n",
      "train AE loss : 1.6531193256378174, train ANN loss : 3.0656538009643555\n",
      "AE loss : 1.7262210845947266, ANN loss : 2.832545042037964, Total loss : 175.45465087890625\n",
      "learning rate A :  tf.Tensor(9.947248e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 459 is 0.0776 sec\n",
      "train AE loss : 1.6933683156967163, train ANN loss : 3.051171064376831\n",
      "AE loss : 1.7624319791793823, ANN loss : 2.8256452083587646, Total loss : 179.06884765625\n",
      "learning rate A :  tf.Tensor(9.947248e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 460 is 0.0754 sec\n",
      "train AE loss : 1.7284986972808838, train ANN loss : 3.0485332012176514\n",
      "AE loss : 1.7943538427352905, ANN loss : 2.8189785480499268, Total loss : 182.25436401367188\n",
      "learning rate A :  tf.Tensor(9.947248e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 461 is 0.0749 sec\n",
      "train AE loss : 1.7593713998794556, train ANN loss : 3.0465264320373535\n",
      "AE loss : 1.8240586519241333, ANN loss : 2.812634229660034, Total loss : 185.218505859375\n",
      "learning rate A :  tf.Tensor(9.947248e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 462 is 0.0770 sec\n",
      "train AE loss : 1.7880768775939941, train ANN loss : 3.0535011291503906\n",
      "AE loss : 1.8163855075836182, ANN loss : 2.8127450942993164, Total loss : 184.4512939453125\n",
      "learning rate A :  tf.Tensor(9.947039e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 463 is 0.0738 sec\n",
      "train AE loss : 1.7805726528167725, train ANN loss : 3.046062469482422\n",
      "AE loss : 1.8497763872146606, ANN loss : 2.8066766262054443, Total loss : 187.78431701660156\n",
      "learning rate A :  tf.Tensor(9.947039e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 464 is 0.0761 sec\n",
      "train AE loss : 1.812904715538025, train ANN loss : 3.0297563076019287\n",
      "AE loss : 1.8417963981628418, ANN loss : 2.8067996501922607, Total loss : 186.98643493652344\n",
      "learning rate A :  tf.Tensor(9.946829e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 465 is 0.0746 sec\n",
      "train AE loss : 1.8051023483276367, train ANN loss : 3.039841413497925\n",
      "AE loss : 1.8818448781967163, ANN loss : 2.8004109859466553, Total loss : 190.98492431640625\n",
      "learning rate A :  tf.Tensor(9.946829e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 466 is 0.0748 sec\n",
      "train AE loss : 1.8439583778381348, train ANN loss : 3.026980400085449\n",
      "AE loss : 1.9251298904418945, ANN loss : 2.794175624847412, Total loss : 195.30715942382812\n",
      "learning rate A :  tf.Tensor(9.946829e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 467 is 0.0752 sec\n",
      "train AE loss : 1.8859338760375977, train ANN loss : 3.0265467166900635\n",
      "AE loss : 1.9162259101867676, ANN loss : 2.7943074703216553, Total loss : 194.41690063476562\n",
      "learning rate A :  tf.Tensor(9.94662e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 468 is 0.0737 sec\n",
      "train AE loss : 1.8772375583648682, train ANN loss : 3.027818202972412\n",
      "AE loss : 1.9662188291549683, ANN loss : 2.7882673740386963, Total loss : 199.41015625\n",
      "learning rate A :  tf.Tensor(9.94662e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 469 is 0.0750 sec\n",
      "train AE loss : 1.9258182048797607, train ANN loss : 3.0134074687957764\n",
      "AE loss : 1.9567995071411133, ANN loss : 2.788398027420044, Total loss : 198.4683380126953\n",
      "learning rate A :  tf.Tensor(9.94641e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 470 is 0.0737 sec\n",
      "train AE loss : 1.9166216850280762, train ANN loss : 3.0207138061523438\n",
      "AE loss : 2.0075161457061768, ANN loss : 2.7820780277252197, Total loss : 203.53370666503906\n",
      "learning rate A :  tf.Tensor(9.94641e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 471 is 0.0756 sec\n",
      "train AE loss : 1.9659422636032104, train ANN loss : 3.0185952186584473\n",
      "AE loss : 2.059868335723877, ANN loss : 2.7755768299102783, Total loss : 208.7624053955078\n",
      "learning rate A :  tf.Tensor(9.94641e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 472 is 0.0754 sec\n",
      "train AE loss : 2.0168347358703613, train ANN loss : 3.0064537525177\n",
      "AE loss : 2.0492360591888428, ANN loss : 2.775702476501465, Total loss : 207.69931030273438\n",
      "learning rate A :  tf.Tensor(9.9462006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 473 is 0.0735 sec\n",
      "train AE loss : 2.0064618587493896, train ANN loss : 3.0142147541046143\n",
      "AE loss : 2.105076789855957, ANN loss : 2.7692010402679443, Total loss : 213.27688598632812\n",
      "learning rate A :  tf.Tensor(9.9462006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 474 is 0.0756 sec\n",
      "train AE loss : 2.0607216358184814, train ANN loss : 3.0073330402374268\n",
      "AE loss : 2.1640145778656006, ANN loss : 2.7625784873962402, Total loss : 219.16404724121094\n",
      "learning rate A :  tf.Tensor(9.9462006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 475 is 0.0745 sec\n",
      "train AE loss : 2.1180121898651123, train ANN loss : 2.996474504470825\n",
      "AE loss : 2.2207696437835693, ANN loss : 2.7557809352874756, Total loss : 224.83273315429688\n",
      "learning rate A :  tf.Tensor(9.9462006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 476 is 0.0743 sec\n",
      "train AE loss : 2.1730332374572754, train ANN loss : 2.9972455501556396\n",
      "AE loss : 2.2730581760406494, ANN loss : 2.748671770095825, Total loss : 230.0544891357422\n",
      "learning rate A :  tf.Tensor(9.9462006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 477 is 0.0758 sec\n",
      "train AE loss : 2.2236428260803223, train ANN loss : 2.988846778869629\n",
      "AE loss : 2.2594709396362305, ANN loss : 2.7487924098968506, Total loss : 228.69589233398438\n",
      "learning rate A :  tf.Tensor(9.945991e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 478 is 0.0731 sec\n",
      "train AE loss : 2.210407257080078, train ANN loss : 2.9918532371520996\n",
      "AE loss : 2.2460758686065674, ANN loss : 2.7489163875579834, Total loss : 227.35650634765625\n",
      "learning rate A :  tf.Tensor(9.945781e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 479 is 0.0729 sec\n",
      "train AE loss : 2.1973581314086914, train ANN loss : 2.9802768230438232\n",
      "AE loss : 2.232863426208496, ANN loss : 2.7490415573120117, Total loss : 226.03538513183594\n",
      "learning rate A :  tf.Tensor(9.945572e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 480 is 0.0742 sec\n",
      "train AE loss : 2.1844825744628906, train ANN loss : 2.9895074367523193\n",
      "AE loss : 2.219836473464966, ANN loss : 2.74916934967041, Total loss : 224.73281860351562\n",
      "learning rate A :  tf.Tensor(9.945362e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 481 is 0.0734 sec\n",
      "train AE loss : 2.171783924102783, train ANN loss : 2.991907835006714\n",
      "AE loss : 2.2708146572113037, ANN loss : 2.7424089908599854, Total loss : 229.82388305664062\n",
      "learning rate A :  tf.Tensor(9.945362e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 482 is 0.0753 sec\n",
      "train AE loss : 2.2210419178009033, train ANN loss : 2.9924111366271973\n",
      "AE loss : 2.3283469676971436, ANN loss : 2.736140489578247, Total loss : 235.57083129882812\n",
      "learning rate A :  tf.Tensor(9.945362e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 483 is 0.0761 sec\n",
      "train AE loss : 2.276730537414551, train ANN loss : 2.9703516960144043\n",
      "AE loss : 2.3920066356658936, ANN loss : 2.7299466133117676, Total loss : 241.93060302734375\n",
      "learning rate A :  tf.Tensor(9.945362e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 484 is 0.0747 sec\n",
      "train AE loss : 2.3384060859680176, train ANN loss : 2.9783780574798584\n",
      "AE loss : 2.376567840576172, ANN loss : 2.7300922870635986, Total loss : 240.38690185546875\n",
      "learning rate A :  tf.Tensor(9.945153e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 485 is 0.0736 sec\n",
      "train AE loss : 2.323378086090088, train ANN loss : 2.9736087322235107\n",
      "AE loss : 2.361356735229492, ANN loss : 2.730240821838379, Total loss : 238.86590576171875\n",
      "learning rate A :  tf.Tensor(9.9449426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 486 is 0.0738 sec\n",
      "train AE loss : 2.308570384979248, train ANN loss : 2.96970534324646\n",
      "AE loss : 2.4284141063690186, ANN loss : 2.7245137691497803, Total loss : 245.56591796875\n",
      "learning rate A :  tf.Tensor(9.9449426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 487 is 0.0753 sec\n",
      "train AE loss : 2.373584270477295, train ANN loss : 2.964211940765381\n",
      "AE loss : 2.41237211227417, ANN loss : 2.7246546745300293, Total loss : 243.9618682861328\n",
      "learning rate A :  tf.Tensor(9.944734e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 488 is 0.0745 sec\n",
      "train AE loss : 2.3579673767089844, train ANN loss : 2.970717430114746\n",
      "AE loss : 2.48335337638855, ANN loss : 2.7190334796905518, Total loss : 251.0543670654297\n",
      "learning rate A :  tf.Tensor(9.944734e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 489 is 0.0770 sec\n",
      "train AE loss : 2.426764965057373, train ANN loss : 2.9590866565704346\n",
      "AE loss : 2.556816339492798, ANN loss : 2.7133865356445312, Total loss : 258.3950500488281\n",
      "learning rate A :  tf.Tensor(9.944734e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 490 is 0.0756 sec\n",
      "train AE loss : 2.497974157333374, train ANN loss : 2.960523843765259\n",
      "AE loss : 2.622084617614746, ANN loss : 2.707587242126465, Total loss : 264.9160461425781\n",
      "learning rate A :  tf.Tensor(9.944734e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 491 is 0.0757 sec\n",
      "train AE loss : 2.5610644817352295, train ANN loss : 2.9532361030578613\n",
      "AE loss : 2.6856746673583984, ANN loss : 2.701613187789917, Total loss : 271.26910400390625\n",
      "learning rate A :  tf.Tensor(9.944734e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 492 is 0.0819 sec\n",
      "train AE loss : 2.6224446296691895, train ANN loss : 2.952406644821167\n",
      "AE loss : 2.6655232906341553, ANN loss : 2.7017228603363037, Total loss : 269.2540588378906\n",
      "learning rate A :  tf.Tensor(9.9445235e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 493 is 0.0766 sec\n",
      "train AE loss : 2.602900505065918, train ANN loss : 2.947467803955078\n",
      "AE loss : 2.7253236770629883, ANN loss : 2.6960208415985107, Total loss : 275.2283935546875\n",
      "learning rate A :  tf.Tensor(9.9445235e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 494 is 0.0779 sec\n",
      "train AE loss : 2.660573959350586, train ANN loss : 2.941610097885132\n",
      "AE loss : 2.788760185241699, ANN loss : 2.6900596618652344, Total loss : 281.5660705566406\n",
      "learning rate A :  tf.Tensor(9.9445235e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 495 is 0.0776 sec\n",
      "train AE loss : 2.7218480110168457, train ANN loss : 2.9343338012695312\n",
      "AE loss : 2.851357936859131, ANN loss : 2.6840832233428955, Total loss : 287.81988525390625\n",
      "learning rate A :  tf.Tensor(9.9445235e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 496 is 0.0886 sec\n",
      "train AE loss : 2.782374382019043, train ANN loss : 2.9439122676849365\n",
      "AE loss : 2.8281867504119873, ANN loss : 2.6842100620269775, Total loss : 285.5028991699219\n",
      "learning rate A :  tf.Tensor(9.944313e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 497 is 0.0755 sec\n",
      "train AE loss : 2.759904623031616, train ANN loss : 2.939607858657837\n",
      "AE loss : 2.805429458618164, ANN loss : 2.684342384338379, Total loss : 283.2272644042969\n",
      "learning rate A :  tf.Tensor(9.9441044e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 498 is 0.0868 sec\n",
      "train AE loss : 2.7378342151641846, train ANN loss : 2.932358980178833\n",
      "AE loss : 2.8683671951293945, ANN loss : 2.678067922592163, Total loss : 289.5148010253906\n",
      "learning rate A :  tf.Tensor(9.9441044e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 499 is 0.0757 sec\n",
      "train AE loss : 2.7986810207366943, train ANN loss : 2.945582389831543\n",
      "AE loss : 2.931666374206543, ANN loss : 2.671531915664673, Total loss : 295.8381652832031\n",
      "learning rate A :  tf.Tensor(9.9441044e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 500 is 0.0780 sec\n",
      "train AE loss : 2.859811544418335, train ANN loss : 2.9293196201324463\n",
      "AE loss : 2.9069583415985107, ANN loss : 2.671689987182617, Total loss : 293.3675231933594\n",
      "learning rate A :  tf.Tensor(9.943895e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 501 is 0.0758 sec\n",
      "train AE loss : 2.8358545303344727, train ANN loss : 2.9288105964660645\n",
      "AE loss : 2.970320224761963, ANN loss : 2.665104627609253, Total loss : 299.6971130371094\n",
      "learning rate A :  tf.Tensor(9.943895e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 502 is 0.0766 sec\n",
      "train AE loss : 2.8969786167144775, train ANN loss : 2.925384283065796\n",
      "AE loss : 3.0382890701293945, ANN loss : 2.659104824066162, Total loss : 306.4880065917969\n",
      "learning rate A :  tf.Tensor(9.943895e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 503 is 0.0771 sec\n",
      "train AE loss : 2.962576150894165, train ANN loss : 2.9131011962890625\n",
      "AE loss : 3.0115344524383545, ANN loss : 2.6592931747436523, Total loss : 303.8127136230469\n",
      "learning rate A :  tf.Tensor(9.943685e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 504 is 0.0750 sec\n",
      "train AE loss : 2.9366354942321777, train ANN loss : 2.929182767868042\n",
      "AE loss : 2.9852819442749023, ANN loss : 2.65948748588562, Total loss : 301.1876525878906\n",
      "learning rate A :  tf.Tensor(9.943476e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 505 is 0.0752 sec\n",
      "train AE loss : 2.9111812114715576, train ANN loss : 2.9079818725585938\n",
      "AE loss : 3.0652594566345215, ANN loss : 2.6539807319641113, Total loss : 309.179931640625\n",
      "learning rate A :  tf.Tensor(9.943476e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 506 is 0.0771 sec\n",
      "train AE loss : 2.9885387420654297, train ANN loss : 2.913097381591797\n",
      "AE loss : 3.037949562072754, ANN loss : 2.654172420501709, Total loss : 306.4491271972656\n",
      "learning rate A :  tf.Tensor(9.943266e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 507 is 0.0749 sec\n",
      "train AE loss : 2.962066173553467, train ANN loss : 2.9152700901031494\n",
      "AE loss : 3.126838207244873, ANN loss : 2.6489639282226562, Total loss : 315.3327941894531\n",
      "learning rate A :  tf.Tensor(9.943266e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 508 is 0.0776 sec\n",
      "train AE loss : 3.0480847358703613, train ANN loss : 2.9073681831359863\n",
      "AE loss : 3.098297595977783, ANN loss : 2.6491434574127197, Total loss : 312.4789123535156\n",
      "learning rate A :  tf.Tensor(9.943057e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 509 is 0.0754 sec\n",
      "train AE loss : 3.020423412322998, train ANN loss : 2.8995649814605713\n",
      "AE loss : 3.1932716369628906, ANN loss : 2.6439096927642822, Total loss : 321.9710693359375\n",
      "learning rate A :  tf.Tensor(9.943057e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 510 is 0.0799 sec\n",
      "train AE loss : 3.112353563308716, train ANN loss : 2.90480899810791\n",
      "AE loss : 3.163389205932617, ANN loss : 2.644068956375122, Total loss : 318.9830017089844\n",
      "learning rate A :  tf.Tensor(9.942847e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 511 is 0.0759 sec\n",
      "train AE loss : 3.083385705947876, train ANN loss : 2.905043840408325\n",
      "AE loss : 3.256056785583496, ANN loss : 2.639234781265259, Total loss : 328.24493408203125\n",
      "learning rate A :  tf.Tensor(9.942847e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 512 is 0.0768 sec\n",
      "train AE loss : 3.173069715499878, train ANN loss : 2.9080097675323486\n",
      "AE loss : 3.3473060131073, ANN loss : 2.6347227096557617, Total loss : 337.3653259277344\n",
      "learning rate A :  tf.Tensor(9.942847e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 513 is 0.0772 sec\n",
      "train AE loss : 3.2612929344177246, train ANN loss : 2.8911752700805664\n",
      "AE loss : 3.427987813949585, ANN loss : 2.629770040512085, Total loss : 345.4284973144531\n",
      "learning rate A :  tf.Tensor(9.942847e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 514 is 0.0868 sec\n",
      "train AE loss : 3.3391916751861572, train ANN loss : 2.892343521118164\n",
      "AE loss : 3.393547773361206, ANN loss : 2.629899740219116, Total loss : 341.9846496582031\n",
      "learning rate A :  tf.Tensor(9.9426376e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 515 is 0.0749 sec\n",
      "train AE loss : 3.3058347702026367, train ANN loss : 2.887378454208374\n",
      "AE loss : 3.468921661376953, ANN loss : 2.624473810195923, Total loss : 349.5166320800781\n",
      "learning rate A :  tf.Tensor(9.9426376e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 516 is 0.0769 sec\n",
      "train AE loss : 3.3784711360931396, train ANN loss : 2.898435115814209\n",
      "AE loss : 3.54596209526062, ANN loss : 2.6190295219421387, Total loss : 357.2152404785156\n",
      "learning rate A :  tf.Tensor(9.9426376e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 517 is 0.0757 sec\n",
      "train AE loss : 3.4527385234832764, train ANN loss : 2.8905885219573975\n",
      "AE loss : 3.5088653564453125, ANN loss : 2.6191940307617188, Total loss : 353.5057373046875\n",
      "learning rate A :  tf.Tensor(9.942428e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 518 is 0.0746 sec\n",
      "train AE loss : 3.416820526123047, train ANN loss : 2.8816518783569336\n",
      "AE loss : 3.5817711353302, ANN loss : 2.6137502193450928, Total loss : 360.7908935546875\n",
      "learning rate A :  tf.Tensor(9.942428e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 519 is 0.0768 sec\n",
      "train AE loss : 3.4870445728302, train ANN loss : 2.8792645931243896\n",
      "AE loss : 3.5438320636749268, ANN loss : 2.613940954208374, Total loss : 356.99713134765625\n",
      "learning rate A :  tf.Tensor(9.9422185e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 520 is 0.0735 sec\n",
      "train AE loss : 3.4503209590911865, train ANN loss : 2.881931781768799\n",
      "AE loss : 3.5067152976989746, ANN loss : 2.61413836479187, Total loss : 353.28564453125\n",
      "learning rate A :  tf.Tensor(9.942009e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 521 is 0.0740 sec\n",
      "train AE loss : 3.414398431777954, train ANN loss : 2.883092164993286\n",
      "AE loss : 3.5825977325439453, ANN loss : 2.608471155166626, Total loss : 360.8682556152344\n",
      "learning rate A :  tf.Tensor(9.942009e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 522 is 0.0765 sec\n",
      "train AE loss : 3.4876177310943604, train ANN loss : 2.8691279888153076\n",
      "AE loss : 3.544588565826416, ANN loss : 2.608689785003662, Total loss : 357.0675354003906\n",
      "learning rate A :  tf.Tensor(9.941799e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 523 is 0.0745 sec\n",
      "train AE loss : 3.4508440494537354, train ANN loss : 2.8736109733581543\n",
      "AE loss : 3.6434781551361084, ANN loss : 2.6027140617370605, Total loss : 366.9505310058594\n",
      "learning rate A :  tf.Tensor(9.941799e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 524 is 0.0763 sec\n",
      "train AE loss : 3.5463943481445312, train ANN loss : 2.8754403591156006\n",
      "AE loss : 3.6040608882904053, ANN loss : 2.602928876876831, Total loss : 363.009033203125\n",
      "learning rate A :  tf.Tensor(9.94159e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 525 is 0.0749 sec\n",
      "train AE loss : 3.5082547664642334, train ANN loss : 2.873303174972534\n",
      "AE loss : 3.7196669578552246, ANN loss : 2.597524404525757, Total loss : 374.5642395019531\n",
      "learning rate A :  tf.Tensor(9.94159e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 526 is 0.0806 sec\n",
      "train AE loss : 3.620168685913086, train ANN loss : 2.864022970199585\n",
      "AE loss : 3.8360185623168945, ANN loss : 2.592036247253418, Total loss : 386.19390869140625\n",
      "learning rate A :  tf.Tensor(9.94159e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 527 is 0.0760 sec\n",
      "train AE loss : 3.7327518463134766, train ANN loss : 2.860460042953491\n",
      "AE loss : 3.9440414905548096, ANN loss : 2.5867421627044678, Total loss : 396.99090576171875\n",
      "learning rate A :  tf.Tensor(9.94159e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 528 is 0.0764 sec\n",
      "train AE loss : 3.837254762649536, train ANN loss : 2.8579821586608887\n",
      "AE loss : 4.046541690826416, ANN loss : 2.5818567276000977, Total loss : 407.2360534667969\n",
      "learning rate A :  tf.Tensor(9.94159e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 529 is 0.0751 sec\n",
      "train AE loss : 3.9363434314727783, train ANN loss : 2.8647334575653076\n",
      "AE loss : 4.134896755218506, ANN loss : 2.5768558979034424, Total loss : 416.0665283203125\n",
      "learning rate A :  tf.Tensor(9.94159e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 530 is 0.0752 sec\n",
      "train AE loss : 4.021694183349609, train ANN loss : 2.85306715965271\n",
      "AE loss : 4.08364200592041, ANN loss : 2.5770163536071777, Total loss : 410.9411926269531\n",
      "learning rate A :  tf.Tensor(9.94138e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 531 is 0.0750 sec\n",
      "train AE loss : 3.9720797538757324, train ANN loss : 2.8501603603363037\n",
      "AE loss : 4.033658027648926, ANN loss : 2.57718825340271, Total loss : 405.9429931640625\n",
      "learning rate A :  tf.Tensor(9.9411714e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 532 is 0.0738 sec\n",
      "train AE loss : 3.9237003326416016, train ANN loss : 2.843437433242798\n",
      "AE loss : 3.984898805618286, ANN loss : 2.5773727893829346, Total loss : 401.0672302246094\n",
      "learning rate A :  tf.Tensor(9.940962e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 533 is 0.0741 sec\n",
      "train AE loss : 3.876509189605713, train ANN loss : 2.8519084453582764\n",
      "AE loss : 4.082296371459961, ANN loss : 2.572552442550659, Total loss : 410.8022155761719\n",
      "learning rate A :  tf.Tensor(9.940962e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 534 is 0.0752 sec\n",
      "train AE loss : 3.970611810684204, train ANN loss : 2.841376781463623\n",
      "AE loss : 4.185503005981445, ANN loss : 2.5679409503936768, Total loss : 421.1182556152344\n",
      "learning rate A :  tf.Tensor(9.940962e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 535 is 0.0758 sec\n",
      "train AE loss : 4.070383548736572, train ANN loss : 2.838585615158081\n",
      "AE loss : 4.285251140594482, ANN loss : 2.562908887863159, Total loss : 431.0880126953125\n",
      "learning rate A :  tf.Tensor(9.940962e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 536 is 0.0770 sec\n",
      "train AE loss : 4.166701793670654, train ANN loss : 2.8506205081939697\n",
      "AE loss : 4.392849922180176, ANN loss : 2.557910680770874, Total loss : 441.8429260253906\n",
      "learning rate A :  tf.Tensor(9.940962e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 537 is 0.0760 sec\n",
      "train AE loss : 4.27077054977417, train ANN loss : 2.8398802280426025\n",
      "AE loss : 4.495765209197998, ANN loss : 2.5534613132476807, Total loss : 452.1299743652344\n",
      "learning rate A :  tf.Tensor(9.940962e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 538 is 0.0773 sec\n",
      "train AE loss : 4.370236873626709, train ANN loss : 2.8393023014068604\n",
      "AE loss : 4.6110711097717285, ANN loss : 2.5492382049560547, Total loss : 463.65631103515625\n",
      "learning rate A :  tf.Tensor(9.940962e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 539 is 0.0762 sec\n",
      "train AE loss : 4.481862545013428, train ANN loss : 2.8263607025146484\n",
      "AE loss : 4.728627681732178, ANN loss : 2.5449695587158203, Total loss : 475.4077453613281\n",
      "learning rate A :  tf.Tensor(9.940962e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 540 is 0.0758 sec\n",
      "train AE loss : 4.595888614654541, train ANN loss : 2.8243181705474854\n",
      "AE loss : 4.661337375640869, ANN loss : 2.545182943344116, Total loss : 468.6789245605469\n",
      "learning rate A :  tf.Tensor(9.940752e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 541 is 0.0740 sec\n",
      "train AE loss : 4.53081750869751, train ANN loss : 2.820613145828247\n",
      "AE loss : 4.595938205718994, ANN loss : 2.545410633087158, Total loss : 462.13922119140625\n",
      "learning rate A :  tf.Tensor(9.940543e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 542 is 0.0738 sec\n",
      "train AE loss : 4.467565536499023, train ANN loss : 2.8233673572540283\n",
      "AE loss : 4.5323381423950195, ANN loss : 2.545654773712158, Total loss : 455.7794494628906\n",
      "learning rate A :  tf.Tensor(9.940333e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 543 is 0.0754 sec\n",
      "train AE loss : 4.40605354309082, train ANN loss : 2.8144333362579346\n",
      "AE loss : 4.470480442047119, ANN loss : 2.5459139347076416, Total loss : 449.5939636230469\n",
      "learning rate A :  tf.Tensor(9.940124e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 544 is 0.0753 sec\n",
      "train AE loss : 4.346217155456543, train ANN loss : 2.8198747634887695\n",
      "AE loss : 4.601835250854492, ANN loss : 2.54133939743042, Total loss : 462.7248840332031\n",
      "learning rate A :  tf.Tensor(9.940124e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 545 is 0.0775 sec\n",
      "train AE loss : 4.473682403564453, train ANN loss : 2.8254997730255127\n",
      "AE loss : 4.538084983825684, ANN loss : 2.5415759086608887, Total loss : 456.35009765625\n",
      "learning rate A :  tf.Tensor(9.939915e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 546 is 0.0756 sec\n",
      "train AE loss : 4.412014007568359, train ANN loss : 2.8054561614990234\n",
      "AE loss : 4.476072311401367, ANN loss : 2.5418241024017334, Total loss : 450.1490478515625\n",
      "learning rate A :  tf.Tensor(9.9397046e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 547 is 0.0858 sec\n",
      "train AE loss : 4.352018356323242, train ANN loss : 2.8164308071136475\n",
      "AE loss : 4.415722370147705, ANN loss : 2.542084217071533, Total loss : 444.1143493652344\n",
      "learning rate A :  tf.Tensor(9.939496e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 548 is 0.0754 sec\n",
      "train AE loss : 4.293638229370117, train ANN loss : 2.817850351333618\n",
      "AE loss : 4.537908554077148, ANN loss : 2.537468433380127, Total loss : 456.3283386230469\n",
      "learning rate A :  tf.Tensor(9.939496e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 549 is 0.0786 sec\n",
      "train AE loss : 4.412413597106934, train ANN loss : 2.8159072399139404\n",
      "AE loss : 4.475943088531494, ANN loss : 2.5377092361450195, Total loss : 450.1319885253906\n",
      "learning rate A :  tf.Tensor(9.9392855e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 550 is 0.0748 sec\n",
      "train AE loss : 4.352445602416992, train ANN loss : 2.8218836784362793\n",
      "AE loss : 4.415638446807861, ANN loss : 2.537961721420288, Total loss : 444.101806640625\n",
      "learning rate A :  tf.Tensor(9.939077e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 551 is 0.0755 sec\n",
      "train AE loss : 4.294091701507568, train ANN loss : 2.820742607116699\n",
      "AE loss : 4.356934070587158, ANN loss : 2.538224935531616, Total loss : 438.23162841796875\n",
      "learning rate A :  tf.Tensor(9.938867e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 552 is 0.0761 sec\n",
      "train AE loss : 4.237278461456299, train ANN loss : 2.8270459175109863\n",
      "AE loss : 4.5032639503479, ANN loss : 2.533665418624878, Total loss : 452.86004638671875\n",
      "learning rate A :  tf.Tensor(9.938867e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 553 is 0.0772 sec\n",
      "train AE loss : 4.37937068939209, train ANN loss : 2.8076095581054688\n",
      "AE loss : 4.652297496795654, ANN loss : 2.529054641723633, Total loss : 467.7587890625\n",
      "learning rate A :  tf.Tensor(9.938867e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 554 is 0.0776 sec\n",
      "train AE loss : 4.524031162261963, train ANN loss : 2.8010499477386475\n",
      "AE loss : 4.5871453285217285, ANN loss : 2.529224395751953, Total loss : 461.2437438964844\n",
      "learning rate A :  tf.Tensor(9.9386576e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 555 is 0.0771 sec\n",
      "train AE loss : 4.460967063903809, train ANN loss : 2.807124376296997\n",
      "AE loss : 4.523767471313477, ANN loss : 2.5294065475463867, Total loss : 454.9061279296875\n",
      "learning rate A :  tf.Tensor(9.938448e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 556 is 0.0758 sec\n",
      "train AE loss : 4.3996171951293945, train ANN loss : 2.802891969680786\n",
      "AE loss : 4.664568901062012, ANN loss : 2.524531364440918, Total loss : 468.9814147949219\n",
      "learning rate A :  tf.Tensor(9.938448e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 557 is 0.0780 sec\n",
      "train AE loss : 4.536280632019043, train ANN loss : 2.801223039627075\n",
      "AE loss : 4.790701866149902, ANN loss : 2.5196263790130615, Total loss : 481.58984375\n",
      "learning rate A :  tf.Tensor(9.938448e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 558 is 0.0777 sec\n",
      "train AE loss : 4.658733367919922, train ANN loss : 2.802417516708374\n",
      "AE loss : 4.895132064819336, ANN loss : 2.514620065689087, Total loss : 492.0278625488281\n",
      "learning rate A :  tf.Tensor(9.938448e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 559 is 0.0773 sec\n",
      "train AE loss : 4.7599663734436035, train ANN loss : 2.7976558208465576\n",
      "AE loss : 4.988959789276123, ANN loss : 2.50974440574646, Total loss : 501.4056701660156\n",
      "learning rate A :  tf.Tensor(9.938448e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 560 is 0.0790 sec\n",
      "train AE loss : 4.850747585296631, train ANN loss : 2.7972145080566406\n",
      "AE loss : 4.913962364196777, ANN loss : 2.5100326538085938, Total loss : 493.90625\n",
      "learning rate A :  tf.Tensor(9.938239e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 561 is 0.0764 sec\n",
      "train AE loss : 4.778132915496826, train ANN loss : 2.7846145629882812\n",
      "AE loss : 5.015918254852295, ANN loss : 2.504746437072754, Total loss : 504.0965881347656\n",
      "learning rate A :  tf.Tensor(9.938239e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 562 is 0.0768 sec\n",
      "train AE loss : 4.8769330978393555, train ANN loss : 2.786756992340088\n",
      "AE loss : 4.940086841583252, ANN loss : 2.505101203918457, Total loss : 496.5138244628906\n",
      "learning rate A :  tf.Tensor(9.93803e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 563 is 0.0752 sec\n",
      "train AE loss : 4.803499698638916, train ANN loss : 2.7944958209991455\n",
      "AE loss : 5.072559833526611, ANN loss : 2.499912977218628, Total loss : 509.755859375\n",
      "learning rate A :  tf.Tensor(9.93803e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 564 is 0.0785 sec\n",
      "train AE loss : 4.93198299407959, train ANN loss : 2.7891643047332764\n",
      "AE loss : 4.994998455047607, ANN loss : 2.500279426574707, Total loss : 502.0001220703125\n",
      "learning rate A :  tf.Tensor(9.93782e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 565 is 0.0754 sec\n",
      "train AE loss : 4.856865406036377, train ANN loss : 2.7895939350128174\n",
      "AE loss : 5.140888214111328, ANN loss : 2.4949164390563965, Total loss : 516.5836791992188\n",
      "learning rate A :  tf.Tensor(9.93782e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 566 is 0.0855 sec\n",
      "train AE loss : 4.998510360717773, train ANN loss : 2.780085325241089\n",
      "AE loss : 5.061269760131836, ANN loss : 2.4952731132507324, Total loss : 508.62225341796875\n",
      "learning rate A :  tf.Tensor(9.937611e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 567 is 0.0769 sec\n",
      "train AE loss : 4.921398162841797, train ANN loss : 2.785567045211792\n",
      "AE loss : 5.217948913574219, ANN loss : 2.4901504516601562, Total loss : 524.2850341796875\n",
      "learning rate A :  tf.Tensor(9.937611e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 568 is 0.0777 sec\n",
      "train AE loss : 5.073516845703125, train ANN loss : 2.7783010005950928\n",
      "AE loss : 5.136034965515137, ANN loss : 2.4904706478118896, Total loss : 516.093994140625\n",
      "learning rate A :  tf.Tensor(9.937401e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 569 is 0.0836 sec\n",
      "train AE loss : 4.994194984436035, train ANN loss : 2.783146858215332\n",
      "AE loss : 5.301340579986572, ANN loss : 2.486121654510498, Total loss : 532.6201171875\n",
      "learning rate A :  tf.Tensor(9.937401e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 570 is 0.0795 sec\n",
      "train AE loss : 5.154707908630371, train ANN loss : 2.7822470664978027\n",
      "AE loss : 5.216912746429443, ANN loss : 2.486389636993408, Total loss : 524.1776733398438\n",
      "learning rate A :  tf.Tensor(9.937192e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 571 is 0.0757 sec\n",
      "train AE loss : 5.072954177856445, train ANN loss : 2.7821152210235596\n",
      "AE loss : 5.135044574737549, ANN loss : 2.4866750240325928, Total loss : 515.9911499023438\n",
      "learning rate A :  tf.Tensor(9.936983e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 572 is 0.0759 sec\n",
      "train AE loss : 4.993680000305176, train ANN loss : 2.7699739933013916\n",
      "AE loss : 5.055617809295654, ANN loss : 2.486978054046631, Total loss : 508.04876708984375\n",
      "learning rate A :  tf.Tensor(9.936774e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 573 is 0.0779 sec\n",
      "train AE loss : 4.916764736175537, train ANN loss : 2.7814619541168213\n",
      "AE loss : 5.220602989196777, ANN loss : 2.483311414718628, Total loss : 524.5436401367188\n",
      "learning rate A :  tf.Tensor(9.936774e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 574 is 0.0777 sec\n",
      "train AE loss : 5.076913833618164, train ANN loss : 2.781468629837036\n",
      "AE loss : 5.138616561889648, ANN loss : 2.4835643768310547, Total loss : 516.34521484375\n",
      "learning rate A :  tf.Tensor(9.9365636e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 575 is 0.0761 sec\n",
      "train AE loss : 4.997506141662598, train ANN loss : 2.7658262252807617\n",
      "AE loss : 5.299182891845703, ANN loss : 2.4797186851501465, Total loss : 532.3980102539062\n",
      "learning rate A :  tf.Tensor(9.9365636e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 576 is 0.0781 sec\n",
      "train AE loss : 5.153220176696777, train ANN loss : 2.7540042400360107\n",
      "AE loss : 5.448729515075684, ANN loss : 2.4754841327667236, Total loss : 547.348388671875\n",
      "learning rate A :  tf.Tensor(9.9365636e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 577 is 0.0775 sec\n",
      "train AE loss : 5.2982940673828125, train ANN loss : 2.7624173164367676\n",
      "AE loss : 5.5606584548950195, ANN loss : 2.470463752746582, Total loss : 558.536376953125\n",
      "learning rate A :  tf.Tensor(9.9365636e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 578 is 0.0783 sec\n",
      "train AE loss : 5.406764984130859, train ANN loss : 2.7727622985839844\n",
      "AE loss : 5.467918872833252, ANN loss : 2.470712900161743, Total loss : 549.2625732421875\n",
      "learning rate A :  tf.Tensor(9.936355e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 579 is 0.0773 sec\n",
      "train AE loss : 5.316949844360352, train ANN loss : 2.7656166553497314\n",
      "AE loss : 5.56584358215332, ANN loss : 2.4667446613311768, Total loss : 559.0510864257812\n",
      "learning rate A :  tf.Tensor(9.936355e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 580 is 0.0761 sec\n",
      "train AE loss : 5.411920547485352, train ANN loss : 2.762810707092285\n",
      "AE loss : 5.6734442710876465, ANN loss : 2.463231086730957, Total loss : 569.8076782226562\n",
      "learning rate A :  tf.Tensor(9.936355e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 581 is 0.0758 sec\n",
      "train AE loss : 5.51638126373291, train ANN loss : 2.758833646774292\n",
      "AE loss : 5.811634063720703, ANN loss : 2.4600119590759277, Total loss : 583.6233520507812\n",
      "learning rate A :  tf.Tensor(9.936355e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 582 is 0.0764 sec\n",
      "train AE loss : 5.650702953338623, train ANN loss : 2.7508599758148193\n",
      "AE loss : 5.976219654083252, ANN loss : 2.4566895961761475, Total loss : 600.07861328125\n",
      "learning rate A :  tf.Tensor(9.936355e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 583 is 0.0769 sec\n",
      "train AE loss : 5.810654640197754, train ANN loss : 2.756479263305664\n",
      "AE loss : 6.162943363189697, ANN loss : 2.453061819076538, Total loss : 618.7473754882812\n",
      "learning rate A :  tf.Tensor(9.936355e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 584 is 0.0758 sec\n",
      "train AE loss : 5.992091178894043, train ANN loss : 2.745394229888916\n",
      "AE loss : 6.049826145172119, ANN loss : 2.4533934593200684, Total loss : 607.4359741210938\n",
      "learning rate A :  tf.Tensor(9.936145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 585 is 0.0739 sec\n",
      "train AE loss : 5.882543563842773, train ANN loss : 2.748715877532959\n",
      "AE loss : 6.234233856201172, ANN loss : 2.449655055999756, Total loss : 625.8731079101562\n",
      "learning rate A :  tf.Tensor(9.936145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 586 is 0.0759 sec\n",
      "train AE loss : 6.061715602874756, train ANN loss : 2.748853921890259\n",
      "AE loss : 6.11856746673584, ANN loss : 2.449951171875, Total loss : 614.3067016601562\n",
      "learning rate A :  tf.Tensor(9.9359364e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 587 is 0.0741 sec\n",
      "train AE loss : 5.949679851531982, train ANN loss : 2.7357289791107178\n",
      "AE loss : 6.287134647369385, ANN loss : 2.445528745651245, Total loss : 631.1590576171875\n",
      "learning rate A :  tf.Tensor(9.9359364e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 588 is 0.0776 sec\n",
      "train AE loss : 6.113383769989014, train ANN loss : 2.7429869174957275\n",
      "AE loss : 6.461296558380127, ANN loss : 2.441796064376831, Total loss : 648.5714111328125\n",
      "learning rate A :  tf.Tensor(9.9359364e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 589 is 0.0765 sec\n",
      "train AE loss : 6.282517910003662, train ANN loss : 2.7421059608459473\n",
      "AE loss : 6.599056720733643, ANN loss : 2.4383344650268555, Total loss : 662.3440551757812\n",
      "learning rate A :  tf.Tensor(9.9359364e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 590 is 0.0761 sec\n",
      "train AE loss : 6.415990352630615, train ANN loss : 2.731135129928589\n",
      "AE loss : 6.470261096954346, ANN loss : 2.438596248626709, Total loss : 649.4647216796875\n",
      "learning rate A :  tf.Tensor(9.935726e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 591 is 0.0747 sec\n",
      "train AE loss : 6.291215896606445, train ANN loss : 2.735910177230835\n",
      "AE loss : 6.346188068389893, ANN loss : 2.438882827758789, Total loss : 637.0577392578125\n",
      "learning rate A :  tf.Tensor(9.935517e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 592 is 0.0743 sec\n",
      "train AE loss : 6.171018123626709, train ANN loss : 2.7388110160827637\n",
      "AE loss : 6.226550102233887, ANN loss : 2.4391980171203613, Total loss : 625.09423828125\n",
      "learning rate A :  tf.Tensor(9.935308e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 593 is 0.0760 sec\n",
      "train AE loss : 6.055116653442383, train ANN loss : 2.731261730194092\n",
      "AE loss : 6.363636016845703, ANN loss : 2.4353761672973633, Total loss : 638.7989501953125\n",
      "learning rate A :  tf.Tensor(9.935308e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 594 is 0.0779 sec\n",
      "train AE loss : 6.187870979309082, train ANN loss : 2.737456798553467\n",
      "AE loss : 6.243346214294434, ANN loss : 2.435755729675293, Total loss : 626.7703857421875\n",
      "learning rate A :  tf.Tensor(9.935099e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 595 is 0.0743 sec\n",
      "train AE loss : 6.0713419914245605, train ANN loss : 2.734678030014038\n",
      "AE loss : 6.127253532409668, ANN loss : 2.436162233352661, Total loss : 615.1614990234375\n",
      "learning rate A :  tf.Tensor(9.934889e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 596 is 0.0746 sec\n",
      "train AE loss : 5.958886623382568, train ANN loss : 2.726685047149658\n",
      "AE loss : 6.282967567443848, ANN loss : 2.4317498207092285, Total loss : 630.728515625\n",
      "learning rate A :  tf.Tensor(9.934889e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 597 is 0.0767 sec\n",
      "train AE loss : 6.109883785247803, train ANN loss : 2.7157247066497803\n",
      "AE loss : 6.4662981033325195, ANN loss : 2.4275665283203125, Total loss : 649.057373046875\n",
      "learning rate A :  tf.Tensor(9.934889e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 598 is 0.0801 sec\n",
      "train AE loss : 6.287774562835693, train ANN loss : 2.7299718856811523\n",
      "AE loss : 6.646476745605469, ANN loss : 2.4223620891571045, Total loss : 667.0700073242188\n",
      "learning rate A :  tf.Tensor(9.934889e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 599 is 0.0908 sec\n",
      "train AE loss : 6.462543964385986, train ANN loss : 2.7227721214294434\n",
      "AE loss : 6.515720844268799, ANN loss : 2.422736406326294, Total loss : 653.9948120117188\n",
      "learning rate A :  tf.Tensor(9.93468e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 600 is 0.0746 sec\n",
      "train AE loss : 6.3359222412109375, train ANN loss : 2.717686653137207\n",
      "AE loss : 6.389717102050781, ANN loss : 2.4231419563293457, Total loss : 641.394775390625\n",
      "learning rate A :  tf.Tensor(9.93447e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 601 is 0.0752 sec\n",
      "train AE loss : 6.213902473449707, train ANN loss : 2.7277350425720215\n",
      "AE loss : 6.580170631408691, ANN loss : 2.4172074794769287, Total loss : 660.434326171875\n",
      "learning rate A :  tf.Tensor(9.93447e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 602 is 0.0775 sec\n",
      "train AE loss : 6.398835182189941, train ANN loss : 2.7244105339050293\n",
      "AE loss : 6.451786518096924, ANN loss : 2.41758131980896, Total loss : 647.5962524414062\n",
      "learning rate A :  tf.Tensor(9.9342615e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 603 is 0.0744 sec\n",
      "train AE loss : 6.27449893951416, train ANN loss : 2.7314281463623047\n",
      "AE loss : 6.328004837036133, ANN loss : 2.417984962463379, Total loss : 635.218505859375\n",
      "learning rate A :  tf.Tensor(9.934052e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 604 is 0.0740 sec\n",
      "train AE loss : 6.1545915603637695, train ANN loss : 2.707245111465454\n",
      "AE loss : 6.525269508361816, ANN loss : 2.4131698608398438, Total loss : 654.9401245117188\n",
      "learning rate A :  tf.Tensor(9.934052e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 605 is 0.0771 sec\n",
      "train AE loss : 6.346418380737305, train ANN loss : 2.7159111499786377\n",
      "AE loss : 6.727811813354492, ANN loss : 2.4097790718078613, Total loss : 675.1909790039062\n",
      "learning rate A :  tf.Tensor(9.934052e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 606 is 0.0755 sec\n",
      "train AE loss : 6.543366432189941, train ANN loss : 2.7126305103302\n",
      "AE loss : 6.593993186950684, ANN loss : 2.4100699424743652, Total loss : 661.809326171875\n",
      "learning rate A :  tf.Tensor(9.933843e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 607 is 0.0740 sec\n",
      "train AE loss : 6.413717746734619, train ANN loss : 2.713761806488037\n",
      "AE loss : 6.465061187744141, ANN loss : 2.4103918075561523, Total loss : 648.91650390625\n",
      "learning rate A :  tf.Tensor(9.933633e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 608 is 0.0747 sec\n",
      "train AE loss : 6.288788318634033, train ANN loss : 2.7153279781341553\n",
      "AE loss : 6.340773582458496, ANN loss : 2.410743236541748, Total loss : 636.4880981445312\n",
      "learning rate A :  tf.Tensor(9.933423e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 609 is 0.0739 sec\n",
      "train AE loss : 6.168342113494873, train ANN loss : 2.710684299468994\n",
      "AE loss : 6.220898151397705, ANN loss : 2.4111239910125732, Total loss : 624.5009155273438\n",
      "learning rate A :  tf.Tensor(9.933214e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 610 is 0.0758 sec\n",
      "train AE loss : 6.052140235900879, train ANN loss : 2.7065529823303223\n",
      "AE loss : 6.412318229675293, ANN loss : 2.407402515411377, Total loss : 643.6392211914062\n",
      "learning rate A :  tf.Tensor(9.933214e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 611 is 0.0772 sec\n",
      "train AE loss : 6.23834228515625, train ANN loss : 2.7163782119750977\n",
      "AE loss : 6.28992223739624, ANN loss : 2.407742977142334, Total loss : 631.4000244140625\n",
      "learning rate A :  tf.Tensor(9.933005e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 612 is 0.0755 sec\n",
      "train AE loss : 6.1196818351745605, train ANN loss : 2.710280418395996\n",
      "AE loss : 6.171841144561768, ANN loss : 2.408118724822998, Total loss : 619.59228515625\n",
      "learning rate A :  tf.Tensor(9.932795e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 613 is 0.0758 sec\n",
      "train AE loss : 6.005202770233154, train ANN loss : 2.709656000137329\n",
      "AE loss : 6.368919372558594, ANN loss : 2.4052810668945312, Total loss : 639.2972412109375\n",
      "learning rate A :  tf.Tensor(9.932795e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 614 is 0.0772 sec\n",
      "train AE loss : 6.1969313621521, train ANN loss : 2.7120141983032227\n",
      "AE loss : 6.248094081878662, ANN loss : 2.4055979251861572, Total loss : 627.2149658203125\n",
      "learning rate A :  tf.Tensor(9.932586e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 615 is 0.0757 sec\n",
      "train AE loss : 6.079777717590332, train ANN loss : 2.700511932373047\n",
      "AE loss : 6.43834924697876, ANN loss : 2.4035913944244385, Total loss : 646.2384643554688\n",
      "learning rate A :  tf.Tensor(9.932586e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 616 is 0.0863 sec\n",
      "train AE loss : 6.2648396492004395, train ANN loss : 2.7089169025421143\n",
      "AE loss : 6.315070629119873, ANN loss : 2.403873920440674, Total loss : 633.9109497070312\n",
      "learning rate A :  tf.Tensor(9.932376e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 617 is 0.0767 sec\n",
      "train AE loss : 6.145290374755859, train ANN loss : 2.709271192550659\n",
      "AE loss : 6.196114540100098, ANN loss : 2.4041857719421387, Total loss : 622.015625\n",
      "learning rate A :  tf.Tensor(9.9321674e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 618 is 0.0759 sec\n",
      "train AE loss : 6.029935359954834, train ANN loss : 2.7112557888031006\n",
      "AE loss : 6.400115966796875, ANN loss : 2.402503252029419, Total loss : 642.4140625\n",
      "learning rate A :  tf.Tensor(9.9321674e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 619 is 0.0776 sec\n",
      "train AE loss : 6.228544235229492, train ANN loss : 2.717540740966797\n",
      "AE loss : 6.278139591217041, ANN loss : 2.4027748107910156, Total loss : 630.2167358398438\n",
      "learning rate A :  tf.Tensor(9.931958e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 620 is 0.0763 sec\n",
      "train AE loss : 6.110250949859619, train ANN loss : 2.70748233795166\n",
      "AE loss : 6.465244293212891, ANN loss : 2.400383949279785, Total loss : 648.9248046875\n",
      "learning rate A :  tf.Tensor(9.931958e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 621 is 0.0779 sec\n",
      "train AE loss : 6.292280673980713, train ANN loss : 2.7028844356536865\n",
      "AE loss : 6.638116836547852, ANN loss : 2.396857500076294, Total loss : 666.2085571289062\n",
      "learning rate A :  tf.Tensor(9.931958e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 622 is 0.0765 sec\n",
      "train AE loss : 6.460132122039795, train ANN loss : 2.689271926879883\n",
      "AE loss : 6.805037498474121, ANN loss : 2.391404390335083, Total loss : 682.8951416015625\n",
      "learning rate A :  tf.Tensor(9.931958e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 623 is 0.0788 sec\n",
      "train AE loss : 6.6220383644104, train ANN loss : 2.698044538497925\n",
      "AE loss : 6.9606218338012695, ANN loss : 2.3864924907684326, Total loss : 698.4486694335938\n",
      "learning rate A :  tf.Tensor(9.931958e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 624 is 0.0773 sec\n",
      "train AE loss : 6.7728986740112305, train ANN loss : 2.690584421157837\n",
      "AE loss : 6.817686080932617, ANN loss : 2.386868715286255, Total loss : 684.155517578125\n",
      "learning rate A :  tf.Tensor(9.931749e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 625 is 0.0763 sec\n",
      "train AE loss : 6.634282112121582, train ANN loss : 2.6843650341033936\n",
      "AE loss : 6.680117130279541, ANN loss : 2.387281656265259, Total loss : 670.3989868164062\n",
      "learning rate A :  tf.Tensor(9.9315395e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 626 is 0.0761 sec\n",
      "train AE loss : 6.500850200653076, train ANN loss : 2.6945788860321045\n",
      "AE loss : 6.547596454620361, ANN loss : 2.387735605239868, Total loss : 657.1473999023438\n",
      "learning rate A :  tf.Tensor(9.931331e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 627 is 0.0755 sec\n",
      "train AE loss : 6.372325420379639, train ANN loss : 2.6895856857299805\n",
      "AE loss : 6.4198832511901855, ANN loss : 2.3882248401641846, Total loss : 644.3765258789062\n",
      "learning rate A :  tf.Tensor(9.931121e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 628 is 0.0759 sec\n",
      "train AE loss : 6.248468399047852, train ANN loss : 2.6883482933044434\n",
      "AE loss : 6.2967071533203125, ANN loss : 2.3887462615966797, Total loss : 632.0595092773438\n",
      "learning rate A :  tf.Tensor(9.930912e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 629 is 0.0760 sec\n",
      "train AE loss : 6.1290202140808105, train ANN loss : 2.6927688121795654\n",
      "AE loss : 6.177829742431641, ANN loss : 2.389296293258667, Total loss : 620.1722412109375\n",
      "learning rate A :  tf.Tensor(9.930702e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 630 is 0.0758 sec\n",
      "train AE loss : 6.013752460479736, train ANN loss : 2.6880407333374023\n",
      "AE loss : 6.063061237335205, ANN loss : 2.38986873626709, Total loss : 608.6959838867188\n",
      "learning rate A :  tf.Tensor(9.930493e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 631 is 0.0750 sec\n",
      "train AE loss : 5.902446269989014, train ANN loss : 2.6984143257141113\n",
      "AE loss : 6.269918918609619, ANN loss : 2.3857192993164062, Total loss : 629.3775634765625\n",
      "learning rate A :  tf.Tensor(9.930493e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 632 is 0.0861 sec\n",
      "train AE loss : 6.103134632110596, train ANN loss : 2.6990060806274414\n",
      "AE loss : 6.537432670593262, ANN loss : 2.383056879043579, Total loss : 656.1263427734375\n",
      "learning rate A :  tf.Tensor(9.930493e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 633 is 0.0775 sec\n",
      "train AE loss : 6.362822532653809, train ANN loss : 2.6876511573791504\n",
      "AE loss : 6.409814357757568, ANN loss : 2.383399486541748, Total loss : 643.3648071289062\n",
      "learning rate A :  tf.Tensor(9.930284e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 634 is 0.0760 sec\n",
      "train AE loss : 6.23905086517334, train ANN loss : 2.684230327606201\n",
      "AE loss : 6.286743640899658, ANN loss : 2.383777379989624, Total loss : 631.0581665039062\n",
      "learning rate A :  tf.Tensor(9.930075e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 635 is 0.0759 sec\n",
      "train AE loss : 6.119695663452148, train ANN loss : 2.6866343021392822\n",
      "AE loss : 6.167989253997803, ANN loss : 2.3841910362243652, Total loss : 619.18310546875\n",
      "learning rate A :  tf.Tensor(9.929865e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 636 is 0.0759 sec\n",
      "train AE loss : 6.004524230957031, train ANN loss : 2.681697368621826\n",
      "AE loss : 6.053319454193115, ANN loss : 2.3846404552459717, Total loss : 607.7166137695312\n",
      "learning rate A :  tf.Tensor(9.929656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 637 is 0.0743 sec\n",
      "train AE loss : 5.893332004547119, train ANN loss : 2.6837611198425293\n",
      "AE loss : 6.334369659423828, ANN loss : 2.3823060989379883, Total loss : 635.8192749023438\n",
      "learning rate A :  tf.Tensor(9.929656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 638 is 0.0783 sec\n",
      "train AE loss : 6.166213035583496, train ANN loss : 2.6873273849487305\n",
      "AE loss : 6.587616443634033, ANN loss : 2.380876064300537, Total loss : 661.1425170898438\n",
      "learning rate A :  tf.Tensor(9.929656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 639 is 0.0769 sec\n",
      "train AE loss : 6.412087440490723, train ANN loss : 2.6812379360198975\n",
      "AE loss : 6.779086589813232, ANN loss : 2.378743886947632, Total loss : 680.287353515625\n",
      "learning rate A :  tf.Tensor(9.929656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 640 is 0.0775 sec\n",
      "train AE loss : 6.597978115081787, train ANN loss : 2.6748769283294678\n",
      "AE loss : 6.903840065002441, ANN loss : 2.375386953353882, Total loss : 692.7593994140625\n",
      "learning rate A :  tf.Tensor(9.929656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 641 is 0.0801 sec\n",
      "train AE loss : 6.718829154968262, train ANN loss : 2.671434164047241\n",
      "AE loss : 6.762428283691406, ANN loss : 2.3754851818084717, Total loss : 678.6182861328125\n",
      "learning rate A :  tf.Tensor(9.929447e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 642 is 0.0758 sec\n",
      "train AE loss : 6.5816779136657715, train ANN loss : 2.6703414916992188\n",
      "AE loss : 6.847465991973877, ANN loss : 2.3716189861297607, Total loss : 687.1181640625\n",
      "learning rate A :  tf.Tensor(9.929447e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 643 is 0.0776 sec\n",
      "train AE loss : 6.663891315460205, train ANN loss : 2.6767020225524902\n",
      "AE loss : 6.708045482635498, ANN loss : 2.3719334602355957, Total loss : 673.176513671875\n",
      "learning rate A :  tf.Tensor(9.9292374e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 644 is 0.0762 sec\n",
      "train AE loss : 6.528678894042969, train ANN loss : 2.6726677417755127\n",
      "AE loss : 6.573770999908447, ANN loss : 2.372283458709717, Total loss : 659.7493286132812\n",
      "learning rate A :  tf.Tensor(9.9290286e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 645 is 0.0776 sec\n",
      "train AE loss : 6.398448944091797, train ANN loss : 2.6757869720458984\n",
      "AE loss : 6.444366455078125, ANN loss : 2.3726654052734375, Total loss : 646.809326171875\n",
      "learning rate A :  tf.Tensor(9.928819e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 646 is 0.0749 sec\n",
      "train AE loss : 6.272952556610107, train ANN loss : 2.6692826747894287\n",
      "AE loss : 6.53612756729126, ANN loss : 2.368755578994751, Total loss : 655.9814453125\n",
      "learning rate A :  tf.Tensor(9.928819e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 647 is 0.0763 sec\n",
      "train AE loss : 6.361835479736328, train ANN loss : 2.6743788719177246\n",
      "AE loss : 6.407930850982666, ANN loss : 2.3693301677703857, Total loss : 643.1624755859375\n",
      "learning rate A :  tf.Tensor(9.92861e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 648 is 0.0746 sec\n",
      "train AE loss : 6.237525939941406, train ANN loss : 2.670492172241211\n",
      "AE loss : 6.559098243713379, ANN loss : 2.364788293838501, Total loss : 658.274658203125\n",
      "learning rate A :  tf.Tensor(9.92861e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 649 is 0.0772 sec\n",
      "train AE loss : 6.384050369262695, train ANN loss : 2.668217420578003\n",
      "AE loss : 6.429863929748535, ANN loss : 2.3654329776763916, Total loss : 645.351806640625\n",
      "learning rate A :  tf.Tensor(9.928401e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 650 is 0.0757 sec\n",
      "train AE loss : 6.258736610412598, train ANN loss : 2.675956964492798\n",
      "AE loss : 6.305217742919922, ANN loss : 2.366095542907715, Total loss : 632.8878784179688\n",
      "learning rate A :  tf.Tensor(9.928192e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 651 is 0.0740 sec\n",
      "train AE loss : 6.13787841796875, train ANN loss : 2.6835227012634277\n",
      "AE loss : 6.522639274597168, ANN loss : 2.360910177230835, Total loss : 654.6248168945312\n",
      "learning rate A :  tf.Tensor(9.928192e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 652 is 0.0754 sec\n",
      "train AE loss : 6.3488030433654785, train ANN loss : 2.6632330417633057\n",
      "AE loss : 6.7895188331604, ANN loss : 2.356337547302246, Total loss : 681.3082885742188\n",
      "learning rate A :  tf.Tensor(9.928192e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 653 is 0.0850 sec\n",
      "train AE loss : 6.607777118682861, train ANN loss : 2.6703438758850098\n",
      "AE loss : 6.651443958282471, ANN loss : 2.356721878051758, Total loss : 667.5010986328125\n",
      "learning rate A :  tf.Tensor(9.927982e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 654 is 0.0740 sec\n",
      "train AE loss : 6.4738850593566895, train ANN loss : 2.669243574142456\n",
      "AE loss : 6.922704219818115, ANN loss : 2.354246139526367, Total loss : 694.6246948242188\n",
      "learning rate A :  tf.Tensor(9.927982e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 655 is 0.0753 sec\n",
      "train AE loss : 6.73732852935791, train ANN loss : 2.664184093475342\n",
      "AE loss : 6.779429912567139, ANN loss : 2.3544273376464844, Total loss : 680.2974243164062\n",
      "learning rate A :  tf.Tensor(9.9277735e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 656 is 0.0744 sec\n",
      "train AE loss : 6.598300933837891, train ANN loss : 2.661761522293091\n",
      "AE loss : 6.641481399536133, ANN loss : 2.3546574115753174, Total loss : 666.5028076171875\n",
      "learning rate A :  tf.Tensor(9.927565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 657 is 0.0754 sec\n",
      "train AE loss : 6.464466571807861, train ANN loss : 2.6631345748901367\n",
      "AE loss : 6.87494421005249, ANN loss : 2.3522891998291016, Total loss : 689.8466796875\n",
      "learning rate A :  tf.Tensor(9.927565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 658 is 0.0748 sec\n",
      "train AE loss : 6.691532611846924, train ANN loss : 2.658355474472046\n",
      "AE loss : 7.062678337097168, ANN loss : 2.3500401973724365, Total loss : 708.6177978515625\n",
      "learning rate A :  tf.Tensor(9.927565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 659 is 0.0757 sec\n",
      "train AE loss : 6.874207496643066, train ANN loss : 2.6481258869171143\n",
      "AE loss : 7.202113151550293, ANN loss : 2.3478505611419678, Total loss : 722.5591430664062\n",
      "learning rate A :  tf.Tensor(9.927565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 660 is 0.0758 sec\n",
      "train AE loss : 7.00988245010376, train ANN loss : 2.652255058288574\n",
      "AE loss : 7.295941352844238, ANN loss : 2.344971179962158, Total loss : 731.9390869140625\n",
      "learning rate A :  tf.Tensor(9.927565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 661 is 0.0753 sec\n",
      "train AE loss : 7.101253509521484, train ANN loss : 2.6413965225219727\n",
      "AE loss : 7.383747100830078, ANN loss : 2.343188524246216, Total loss : 740.7178955078125\n",
      "learning rate A :  tf.Tensor(9.927565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 662 is 0.0754 sec\n",
      "train AE loss : 7.187039852142334, train ANN loss : 2.652186393737793\n",
      "AE loss : 7.222349166870117, ANN loss : 2.343614101409912, Total loss : 724.5784912109375\n",
      "learning rate A :  tf.Tensor(9.927355e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 663 is 0.0736 sec\n",
      "train AE loss : 7.030457019805908, train ANN loss : 2.637831211090088\n",
      "AE loss : 7.355464458465576, ANN loss : 2.3412318229675293, Total loss : 737.8876342773438\n",
      "learning rate A :  tf.Tensor(9.927355e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 664 is 0.0758 sec\n",
      "train AE loss : 7.160147190093994, train ANN loss : 2.6500754356384277\n",
      "AE loss : 7.195098400115967, ANN loss : 2.3417820930480957, Total loss : 721.8516235351562\n",
      "learning rate A :  tf.Tensor(9.927146e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 665 is 0.0741 sec\n",
      "train AE loss : 7.004587650299072, train ANN loss : 2.6453733444213867\n",
      "AE loss : 7.372358322143555, ANN loss : 2.3390769958496094, Total loss : 739.5748901367188\n",
      "learning rate A :  tf.Tensor(9.927146e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 666 is 0.0763 sec\n",
      "train AE loss : 7.176980972290039, train ANN loss : 2.653756856918335\n",
      "AE loss : 7.211178302764893, ANN loss : 2.3396525382995605, Total loss : 723.45751953125\n",
      "learning rate A :  tf.Tensor(9.926937e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 667 is 0.0751 sec\n",
      "train AE loss : 7.020618915557861, train ANN loss : 2.645212411880493\n",
      "AE loss : 7.056304931640625, ANN loss : 2.340258836746216, Total loss : 707.970703125\n",
      "learning rate A :  tf.Tensor(9.926728e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 668 is 0.0748 sec\n",
      "train AE loss : 6.8703694343566895, train ANN loss : 2.6524367332458496\n",
      "AE loss : 7.283543109893799, ANN loss : 2.3363587856292725, Total loss : 730.690673828125\n",
      "learning rate A :  tf.Tensor(9.926728e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 669 is 0.0760 sec\n",
      "train AE loss : 7.091207027435303, train ANN loss : 2.6383485794067383\n",
      "AE loss : 7.125612735748291, ANN loss : 2.3368842601776123, Total loss : 714.898193359375\n",
      "learning rate A :  tf.Tensor(9.9265184e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 670 is 0.0742 sec\n",
      "train AE loss : 6.937983512878418, train ANN loss : 2.645914077758789\n",
      "AE loss : 7.3792524337768555, ANN loss : 2.3334569931030273, Total loss : 740.2586669921875\n",
      "learning rate A :  tf.Tensor(9.9265184e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 671 is 0.0759 sec\n",
      "train AE loss : 7.184650421142578, train ANN loss : 2.648597478866577\n",
      "AE loss : 7.627630710601807, ANN loss : 2.331204414367676, Total loss : 765.0942993164062\n",
      "learning rate A :  tf.Tensor(9.9265184e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 672 is 0.0763 sec\n",
      "train AE loss : 7.426445007324219, train ANN loss : 2.634960174560547\n",
      "AE loss : 7.455523490905762, ANN loss : 2.331373691558838, Total loss : 747.8837890625\n",
      "learning rate A :  tf.Tensor(9.9263096e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 673 is 0.0734 sec\n",
      "train AE loss : 7.259374618530273, train ANN loss : 2.638345718383789\n",
      "AE loss : 7.290321350097656, ANN loss : 2.331597328186035, Total loss : 731.36376953125\n",
      "learning rate A :  tf.Tensor(9.9261e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 674 is 0.0741 sec\n",
      "train AE loss : 7.099008083343506, train ANN loss : 2.6257266998291016\n",
      "AE loss : 7.516608238220215, ANN loss : 2.329706907272339, Total loss : 753.9905395507812\n",
      "learning rate A :  tf.Tensor(9.9261e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 675 is 0.0756 sec\n",
      "train AE loss : 7.319295883178711, train ANN loss : 2.631352663040161\n",
      "AE loss : 7.695857524871826, ANN loss : 2.3280622959136963, Total loss : 771.913818359375\n",
      "learning rate A :  tf.Tensor(9.9261e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 676 is 0.0773 sec\n",
      "train AE loss : 7.493747234344482, train ANN loss : 2.635590076446533\n",
      "AE loss : 7.8237481117248535, ANN loss : 2.3262808322906494, Total loss : 784.7011108398438\n",
      "learning rate A :  tf.Tensor(9.9261e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 677 is 0.0772 sec\n",
      "train AE loss : 7.618104457855225, train ANN loss : 2.6272289752960205\n",
      "AE loss : 7.916553020477295, ANN loss : 2.324570417404175, Total loss : 793.9797973632812\n",
      "learning rate A :  tf.Tensor(9.9261e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 678 is 0.0771 sec\n",
      "train AE loss : 7.708286762237549, train ANN loss : 2.6310908794403076\n",
      "AE loss : 7.732240676879883, ANN loss : 2.324910879135132, Total loss : 775.5490112304688\n",
      "learning rate A :  tf.Tensor(9.925891e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 679 is 0.0753 sec\n",
      "train AE loss : 7.52935791015625, train ANN loss : 2.6353654861450195\n",
      "AE loss : 7.835650444030762, ANN loss : 2.3234798908233643, Total loss : 785.8885498046875\n",
      "learning rate A :  tf.Tensor(9.925891e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 680 is 0.0772 sec\n",
      "train AE loss : 7.629702568054199, train ANN loss : 2.6180896759033203\n",
      "AE loss : 7.972800254821777, ANN loss : 2.3210103511810303, Total loss : 799.60107421875\n",
      "learning rate A :  tf.Tensor(9.925891e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 681 is 0.0762 sec\n",
      "train AE loss : 7.762853145599365, train ANN loss : 2.615445613861084\n",
      "AE loss : 8.146838188171387, ANN loss : 2.3172762393951416, Total loss : 817.0010375976562\n",
      "learning rate A :  tf.Tensor(9.925891e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 682 is 0.0824 sec\n",
      "train AE loss : 7.9321794509887695, train ANN loss : 2.621293783187866\n",
      "AE loss : 8.351407051086426, ANN loss : 2.3132033348083496, Total loss : 837.453857421875\n",
      "learning rate A :  tf.Tensor(9.925891e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 683 is 0.0793 sec\n",
      "train AE loss : 8.131441116333008, train ANN loss : 2.6120901107788086\n",
      "AE loss : 8.147825241088867, ANN loss : 2.313739061355591, Total loss : 817.0962524414062\n",
      "learning rate A :  tf.Tensor(9.925682e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 684 is 0.0750 sec\n",
      "train AE loss : 7.933799743652344, train ANN loss : 2.605405330657959\n",
      "AE loss : 8.379261016845703, ANN loss : 2.309839963912964, Total loss : 840.2359619140625\n",
      "learning rate A :  tf.Tensor(9.925682e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 685 is 0.0766 sec\n",
      "train AE loss : 8.159186363220215, train ANN loss : 2.614281177520752\n",
      "AE loss : 8.62598991394043, ANN loss : 2.306688070297241, Total loss : 864.9056396484375\n",
      "learning rate A :  tf.Tensor(9.925682e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 686 is 0.0775 sec\n",
      "train AE loss : 8.399492263793945, train ANN loss : 2.617494583129883\n",
      "AE loss : 8.40980339050293, ANN loss : 2.3070008754730225, Total loss : 843.2872924804688\n",
      "learning rate A :  tf.Tensor(9.925473e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 687 is 0.0745 sec\n",
      "train AE loss : 8.189579963684082, train ANN loss : 2.6150035858154297\n",
      "AE loss : 8.640861511230469, ANN loss : 2.30533766746521, Total loss : 866.3915405273438\n",
      "learning rate A :  tf.Tensor(9.925473e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 688 is 0.0764 sec\n",
      "train AE loss : 8.414811134338379, train ANN loss : 2.6087217330932617\n",
      "AE loss : 8.845622062683105, ANN loss : 2.304736375808716, Total loss : 886.866943359375\n",
      "learning rate A :  tf.Tensor(9.925473e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 689 is 0.0778 sec\n",
      "train AE loss : 8.614568710327148, train ANN loss : 2.613206386566162\n",
      "AE loss : 8.619352340698242, ANN loss : 2.304948329925537, Total loss : 864.2401123046875\n",
      "learning rate A :  tf.Tensor(9.925264e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 690 is 0.0748 sec\n",
      "train AE loss : 8.39478588104248, train ANN loss : 2.612722873687744\n",
      "AE loss : 8.403258323669434, ANN loss : 2.30523419380188, Total loss : 842.6310424804688\n",
      "learning rate A :  tf.Tensor(9.9250545e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 691 is 0.0746 sec\n",
      "train AE loss : 8.18486213684082, train ANN loss : 2.6128222942352295\n",
      "AE loss : 8.196674346923828, ANN loss : 2.305586338043213, Total loss : 821.9729614257812\n",
      "learning rate A :  tf.Tensor(9.924846e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 692 is 0.0763 sec\n",
      "train AE loss : 7.984195709228516, train ANN loss : 2.6059353351593018\n",
      "AE loss : 7.999029636383057, ANN loss : 2.305987596511841, Total loss : 802.208984375\n",
      "learning rate A :  tf.Tensor(9.924636e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 693 is 0.0749 sec\n",
      "train AE loss : 7.792214393615723, train ANN loss : 2.596856117248535\n",
      "AE loss : 8.20119857788086, ANN loss : 2.305047035217285, Total loss : 822.4249267578125\n",
      "learning rate A :  tf.Tensor(9.924636e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 694 is 0.0770 sec\n",
      "train AE loss : 7.989151954650879, train ANN loss : 2.612661838531494\n",
      "AE loss : 8.003220558166504, ANN loss : 2.3054425716400146, Total loss : 802.6275634765625\n",
      "learning rate A :  tf.Tensor(9.924427e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 695 is 0.0755 sec\n",
      "train AE loss : 7.796834468841553, train ANN loss : 2.608635663986206\n",
      "AE loss : 7.8136677742004395, ANN loss : 2.305880069732666, Total loss : 783.672607421875\n",
      "learning rate A :  tf.Tensor(9.924218e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 696 is 0.0748 sec\n",
      "train AE loss : 7.612675666809082, train ANN loss : 2.612431049346924\n",
      "AE loss : 8.051107406616211, ANN loss : 2.3040575981140137, Total loss : 807.4147338867188\n",
      "learning rate A :  tf.Tensor(9.924218e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 697 is 0.0773 sec\n",
      "train AE loss : 7.843997478485107, train ANN loss : 2.598945379257202\n",
      "AE loss : 7.859310626983643, ANN loss : 2.304431915283203, Total loss : 788.2354736328125\n",
      "learning rate A :  tf.Tensor(9.924009e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 698 is 0.0756 sec\n",
      "train AE loss : 7.657665252685547, train ANN loss : 2.5990028381347656\n",
      "AE loss : 7.675542831420898, ANN loss : 2.3048577308654785, Total loss : 769.859130859375\n",
      "learning rate A :  tf.Tensor(9.9238e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 699 is 0.0752 sec\n",
      "train AE loss : 7.479119300842285, train ANN loss : 2.602205991744995\n",
      "AE loss : 7.499354362487793, ANN loss : 2.305323362350464, Total loss : 752.24072265625\n",
      "learning rate A :  tf.Tensor(9.9235906e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 700 is 0.0754 sec\n",
      "train AE loss : 7.307933330535889, train ANN loss : 2.6026833057403564\n",
      "AE loss : 7.330291748046875, ANN loss : 2.3058266639709473, Total loss : 735.3350219726562\n",
      "learning rate A :  tf.Tensor(9.923382e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 701 is 0.0754 sec\n",
      "train AE loss : 7.14367151260376, train ANN loss : 2.599274158477783\n",
      "AE loss : 7.580990314483643, ANN loss : 2.302983283996582, Total loss : 760.4019775390625\n",
      "learning rate A :  tf.Tensor(9.923382e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 702 is 0.0768 sec\n",
      "train AE loss : 7.387860298156738, train ANN loss : 2.608394145965576\n",
      "AE loss : 7.850668907165527, ANN loss : 2.300088882446289, Total loss : 787.3670043945312\n",
      "learning rate A :  tf.Tensor(9.923382e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 703 is 0.0772 sec\n",
      "train AE loss : 7.650633811950684, train ANN loss : 2.5846714973449707\n",
      "AE loss : 8.088228225708008, ANN loss : 2.2972915172576904, Total loss : 811.1200561523438\n",
      "learning rate A :  tf.Tensor(9.923382e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 704 is 0.0777 sec\n",
      "train AE loss : 7.882029056549072, train ANN loss : 2.602329730987549\n",
      "AE loss : 8.29559326171875, ANN loss : 2.294170618057251, Total loss : 831.8534545898438\n",
      "learning rate A :  tf.Tensor(9.923382e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 705 is 0.0770 sec\n",
      "train AE loss : 8.08365249633789, train ANN loss : 2.590846300125122\n",
      "AE loss : 8.091402053833008, ANN loss : 2.2942628860473633, Total loss : 811.4344482421875\n",
      "learning rate A :  tf.Tensor(9.923172e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 706 is 0.0760 sec\n",
      "train AE loss : 7.8852219581604, train ANN loss : 2.5922083854675293\n",
      "AE loss : 8.268933296203613, ANN loss : 2.290499210357666, Total loss : 829.183837890625\n",
      "learning rate A :  tf.Tensor(9.923172e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 707 is 0.0772 sec\n",
      "train AE loss : 8.05751895904541, train ANN loss : 2.598402261734009\n",
      "AE loss : 8.065488815307617, ANN loss : 2.290719985961914, Total loss : 808.8395385742188\n",
      "learning rate A :  tf.Tensor(9.922963e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 708 is 0.0747 sec\n",
      "train AE loss : 7.859817981719971, train ANN loss : 2.6114349365234375\n",
      "AE loss : 8.237171173095703, ANN loss : 2.2876408100128174, Total loss : 826.0046997070312\n",
      "learning rate A :  tf.Tensor(9.922963e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 709 is 0.0779 sec\n",
      "train AE loss : 8.026247024536133, train ANN loss : 2.5868616104125977\n",
      "AE loss : 8.422450065612793, ANN loss : 2.2850615978240967, Total loss : 844.5300903320312\n",
      "learning rate A :  tf.Tensor(9.922963e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 710 is 0.0774 sec\n",
      "train AE loss : 8.206123352050781, train ANN loss : 2.58586049079895\n",
      "AE loss : 8.625407218933105, ANN loss : 2.282515525817871, Total loss : 864.8231811523438\n",
      "learning rate A :  tf.Tensor(9.922963e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 711 is 0.0783 sec\n",
      "train AE loss : 8.403331756591797, train ANN loss : 2.5862205028533936\n",
      "AE loss : 8.840276718139648, ANN loss : 2.279533863067627, Total loss : 886.3071899414062\n",
      "learning rate A :  tf.Tensor(9.922963e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 712 is 0.0749 sec\n",
      "train AE loss : 8.612098693847656, train ANN loss : 2.5991008281707764\n",
      "AE loss : 9.072183609008789, ANN loss : 2.2770159244537354, Total loss : 909.4954223632812\n",
      "learning rate A :  tf.Tensor(9.922963e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 713 is 0.0761 sec\n",
      "train AE loss : 8.83747673034668, train ANN loss : 2.578617572784424\n",
      "AE loss : 8.830739974975586, ANN loss : 2.277359962463379, Total loss : 885.3513793945312\n",
      "learning rate A :  tf.Tensor(9.9227545e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 714 is 0.0734 sec\n",
      "train AE loss : 8.602959632873535, train ANN loss : 2.594520330429077\n",
      "AE loss : 9.066546440124512, ANN loss : 2.2756240367889404, Total loss : 908.9302978515625\n",
      "learning rate A :  tf.Tensor(9.9227545e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 715 is 0.0750 sec\n",
      "train AE loss : 8.83234691619873, train ANN loss : 2.574652671813965\n",
      "AE loss : 8.825090408325195, ANN loss : 2.275944232940674, Total loss : 884.7850341796875\n",
      "learning rate A :  tf.Tensor(9.922545e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 716 is 0.0744 sec\n",
      "train AE loss : 8.59782886505127, train ANN loss : 2.576474189758301\n",
      "AE loss : 9.04199504852295, ANN loss : 2.2743172645568848, Total loss : 906.473876953125\n",
      "learning rate A :  tf.Tensor(9.922545e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 717 is 0.0759 sec\n",
      "train AE loss : 8.808838844299316, train ANN loss : 2.580178737640381\n",
      "AE loss : 8.801518440246582, ANN loss : 2.2746493816375732, Total loss : 882.4264526367188\n",
      "learning rate A :  tf.Tensor(9.9223354e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 718 is 0.0726 sec\n",
      "train AE loss : 8.575263023376465, train ANN loss : 2.5906786918640137\n",
      "AE loss : 9.016048431396484, ANN loss : 2.273103713989258, Total loss : 903.8779907226562\n",
      "learning rate A :  tf.Tensor(9.9223354e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 719 is 0.0770 sec\n",
      "train AE loss : 8.7841796875, train ANN loss : 2.5808539390563965\n",
      "AE loss : 9.229551315307617, ANN loss : 2.2718520164489746, Total loss : 925.2269897460938\n",
      "learning rate A :  tf.Tensor(9.9223354e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 720 is 0.0852 sec\n",
      "train AE loss : 8.992055892944336, train ANN loss : 2.5547356605529785\n",
      "AE loss : 8.980060577392578, ANN loss : 2.272087574005127, Total loss : 900.278076171875\n",
      "learning rate A :  tf.Tensor(9.9221266e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 721 is 0.0732 sec\n",
      "train AE loss : 8.749673843383789, train ANN loss : 2.579562187194824\n",
      "AE loss : 8.742388725280762, ANN loss : 2.2723989486694336, Total loss : 876.5112915039062\n",
      "learning rate A :  tf.Tensor(9.921917e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 722 is 0.0777 sec\n",
      "train AE loss : 8.518793106079102, train ANN loss : 2.5805015563964844\n",
      "AE loss : 8.9561128616333, ANN loss : 2.2710633277893066, Total loss : 897.88232421875\n",
      "learning rate A :  tf.Tensor(9.921917e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 723 is 0.0782 sec\n",
      "train AE loss : 8.727005958557129, train ANN loss : 2.570063591003418\n",
      "AE loss : 8.719552993774414, ANN loss : 2.2713706493377686, Total loss : 874.2266845703125\n",
      "learning rate A :  tf.Tensor(9.921708e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 724 is 0.0752 sec\n",
      "train AE loss : 8.497180938720703, train ANN loss : 2.5809428691864014\n",
      "AE loss : 8.493922233581543, ANN loss : 2.271746873855591, Total loss : 851.6639404296875\n",
      "learning rate A :  tf.Tensor(9.9214994e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 725 is 0.0747 sec\n",
      "train AE loss : 8.277985572814941, train ANN loss : 2.5763165950775146\n",
      "AE loss : 8.722195625305176, ANN loss : 2.269273519515991, Total loss : 874.48876953125\n",
      "learning rate A :  tf.Tensor(9.9214994e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 726 is 0.0754 sec\n",
      "train AE loss : 8.500551223754883, train ANN loss : 2.5713117122650146\n",
      "AE loss : 8.496403694152832, ANN loss : 2.26961350440979, Total loss : 851.9100341796875\n",
      "learning rate A :  tf.Tensor(9.92129e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 727 is 0.0727 sec\n",
      "train AE loss : 8.281179428100586, train ANN loss : 2.5608396530151367\n",
      "AE loss : 8.725113868713379, ANN loss : 2.2655954360961914, Total loss : 874.7769775390625\n",
      "learning rate A :  tf.Tensor(9.92129e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 728 is 0.0762 sec\n",
      "train AE loss : 8.50403118133545, train ANN loss : 2.5658907890319824\n",
      "AE loss : 8.962363243103027, ANN loss : 2.261521339416504, Total loss : 898.4978637695312\n",
      "learning rate A :  tf.Tensor(9.92129e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 729 is 0.0757 sec\n",
      "train AE loss : 8.735239028930664, train ANN loss : 2.5660953521728516\n",
      "AE loss : 9.19424057006836, ANN loss : 2.25696063041687, Total loss : 921.6810302734375\n",
      "learning rate A :  tf.Tensor(9.92129e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 730 is 0.0766 sec\n",
      "train AE loss : 8.961065292358398, train ANN loss : 2.5645699501037598\n",
      "AE loss : 9.403924942016602, ANN loss : 2.252845048904419, Total loss : 942.6453247070312\n",
      "learning rate A :  tf.Tensor(9.92129e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 731 is 0.0766 sec\n",
      "train AE loss : 9.164976119995117, train ANN loss : 2.563594341278076\n",
      "AE loss : 9.144796371459961, ANN loss : 2.252981185913086, Total loss : 916.7326049804688\n",
      "learning rate A :  tf.Tensor(9.921081e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 732 is 0.0740 sec\n",
      "train AE loss : 8.913151741027832, train ANN loss : 2.564858913421631\n",
      "AE loss : 9.328792572021484, ANN loss : 2.2497291564941406, Total loss : 935.1289672851562\n",
      "learning rate A :  tf.Tensor(9.921081e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 733 is 0.0756 sec\n",
      "train AE loss : 9.091812133789062, train ANN loss : 2.5639700889587402\n",
      "AE loss : 9.501104354858398, ANN loss : 2.2469189167022705, Total loss : 952.3572998046875\n",
      "learning rate A :  tf.Tensor(9.921081e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 734 is 0.0765 sec\n",
      "train AE loss : 9.259271621704102, train ANN loss : 2.5483896732330322\n",
      "AE loss : 9.680334091186523, ANN loss : 2.2445788383483887, Total loss : 970.2778930664062\n",
      "learning rate A :  tf.Tensor(9.921081e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 735 is 0.0755 sec\n",
      "train AE loss : 9.433622360229492, train ANN loss : 2.5609219074249268\n",
      "AE loss : 9.407303810119629, ANN loss : 2.2449920177459717, Total loss : 942.9754028320312\n",
      "learning rate A :  tf.Tensor(9.920872e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 736 is 0.0741 sec\n",
      "train AE loss : 9.168445587158203, train ANN loss : 2.5500378608703613\n",
      "AE loss : 9.147665023803711, ANN loss : 2.2454988956451416, Total loss : 917.0120239257812\n",
      "learning rate A :  tf.Tensor(9.920663e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 737 is 0.0742 sec\n",
      "train AE loss : 8.916261672973633, train ANN loss : 2.5488386154174805\n",
      "AE loss : 9.390758514404297, ANN loss : 2.2442920207977295, Total loss : 941.3201904296875\n",
      "learning rate A :  tf.Tensor(9.920663e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 738 is 0.0756 sec\n",
      "train AE loss : 9.15289306640625, train ANN loss : 2.5499279499053955\n",
      "AE loss : 9.66348934173584, ANN loss : 2.243215560913086, Total loss : 968.5921630859375\n",
      "learning rate A :  tf.Tensor(9.920663e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 739 is 0.0752 sec\n",
      "train AE loss : 9.418464660644531, train ANN loss : 2.550011396408081\n",
      "AE loss : 9.390470504760742, ANN loss : 2.243513822555542, Total loss : 941.29052734375\n",
      "learning rate A :  tf.Tensor(9.920454e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 740 is 0.0759 sec\n",
      "train AE loss : 9.153239250183105, train ANN loss : 2.5472519397735596\n",
      "AE loss : 9.6658935546875, ANN loss : 2.242246627807617, Total loss : 968.8316650390625\n",
      "learning rate A :  tf.Tensor(9.920454e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 741 is 0.0756 sec\n",
      "train AE loss : 9.421483993530273, train ANN loss : 2.5504298210144043\n",
      "AE loss : 9.392239570617676, ANN loss : 2.242431402206421, Total loss : 941.4663696289062\n",
      "learning rate A :  tf.Tensor(9.920245e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 742 is 0.0741 sec\n",
      "train AE loss : 9.155622482299805, train ANN loss : 2.54392671585083\n",
      "AE loss : 9.131980895996094, ANN loss : 2.242705821990967, Total loss : 915.4408569335938\n",
      "learning rate A :  tf.Tensor(9.920036e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 743 is 0.0751 sec\n",
      "train AE loss : 8.902766227722168, train ANN loss : 2.533130407333374\n",
      "AE loss : 8.884294509887695, ANN loss : 2.2430670261383057, Total loss : 890.6724853515625\n",
      "learning rate A :  tf.Tensor(9.919827e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 744 is 0.0749 sec\n",
      "train AE loss : 8.66215705871582, train ANN loss : 2.544339179992676\n",
      "AE loss : 8.648306846618652, ANN loss : 2.243501901626587, Total loss : 867.07421875\n",
      "learning rate A :  tf.Tensor(9.919618e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 745 is 0.0741 sec\n",
      "train AE loss : 8.432879447937012, train ANN loss : 2.5447659492492676\n",
      "AE loss : 8.423299789428711, ANN loss : 2.2440109252929688, Total loss : 844.5739135742188\n",
      "learning rate A :  tf.Tensor(9.919409e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 746 is 0.0754 sec\n",
      "train AE loss : 8.214211463928223, train ANN loss : 2.547165632247925\n",
      "AE loss : 8.706605911254883, ANN loss : 2.242556571960449, Total loss : 872.9031982421875\n",
      "learning rate A :  tf.Tensor(9.919409e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 747 is 0.0775 sec\n",
      "train AE loss : 8.490324974060059, train ANN loss : 2.548330545425415\n",
      "AE loss : 8.987214088439941, ANN loss : 2.2408430576324463, Total loss : 900.9622192382812\n",
      "learning rate A :  tf.Tensor(9.919409e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 748 is 0.0770 sec\n",
      "train AE loss : 8.763800621032715, train ANN loss : 2.5539379119873047\n",
      "AE loss : 9.235859870910645, ANN loss : 2.2371675968170166, Total loss : 925.8231201171875\n",
      "learning rate A :  tf.Tensor(9.919409e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 749 is 0.0779 sec\n",
      "train AE loss : 9.006061553955078, train ANN loss : 2.545808792114258\n",
      "AE loss : 8.980998992919922, ANN loss : 2.2370083332061768, Total loss : 900.3369140625\n",
      "learning rate A :  tf.Tensor(9.9191995e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 750 is 0.0753 sec\n",
      "train AE loss : 8.758340835571289, train ANN loss : 2.551459312438965\n",
      "AE loss : 8.73831558227539, ANN loss : 2.2369487285614014, Total loss : 876.0684814453125\n",
      "learning rate A :  tf.Tensor(9.9189914e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 751 is 0.0749 sec\n",
      "train AE loss : 8.522440910339355, train ANN loss : 2.5397086143493652\n",
      "AE loss : 8.961383819580078, ANN loss : 2.2328336238861084, Total loss : 898.3712158203125\n",
      "learning rate A :  tf.Tensor(9.9189914e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 752 is 0.0773 sec\n",
      "train AE loss : 8.73971176147461, train ANN loss : 2.5270798206329346\n",
      "AE loss : 9.154485702514648, ANN loss : 2.2275021076202393, Total loss : 917.676025390625\n",
      "learning rate A :  tf.Tensor(9.9189914e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 753 is 0.0777 sec\n",
      "train AE loss : 8.927511215209961, train ANN loss : 2.5362486839294434\n",
      "AE loss : 8.902417182922363, ANN loss : 2.2274863719940186, Total loss : 892.4691772460938\n",
      "learning rate A :  tf.Tensor(9.918782e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 754 is 0.0743 sec\n",
      "train AE loss : 8.682478904724121, train ANN loss : 2.5305497646331787\n",
      "AE loss : 9.075028419494629, ANN loss : 2.223477602005005, Total loss : 909.726318359375\n",
      "learning rate A :  tf.Tensor(9.918782e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 755 is 0.0778 sec\n",
      "train AE loss : 8.8502779006958, train ANN loss : 2.5427088737487793\n",
      "AE loss : 8.826495170593262, ANN loss : 2.2236547470092773, Total loss : 884.8732299804688\n",
      "learning rate A :  tf.Tensor(9.918572e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 756 is 0.0745 sec\n",
      "train AE loss : 8.608694076538086, train ANN loss : 2.5282039642333984\n",
      "AE loss : 8.589853286743164, ANN loss : 2.2239270210266113, Total loss : 861.2092895507812\n",
      "learning rate A :  tf.Tensor(9.918364e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 757 is 0.0750 sec\n",
      "train AE loss : 8.378661155700684, train ANN loss : 2.5388412475585938\n",
      "AE loss : 8.364312171936035, ANN loss : 2.224289894104004, Total loss : 838.655517578125\n",
      "learning rate A :  tf.Tensor(9.918155e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 758 is 0.0760 sec\n",
      "train AE loss : 8.159394264221191, train ANN loss : 2.5218560695648193\n",
      "AE loss : 8.149062156677246, ANN loss : 2.22472882270813, Total loss : 817.1309204101562\n",
      "learning rate A :  tf.Tensor(9.917946e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 759 is 0.0754 sec\n",
      "train AE loss : 7.950138092041016, train ANN loss : 2.533910036087036\n",
      "AE loss : 8.35873794555664, ANN loss : 2.2233328819274902, Total loss : 838.0971069335938\n",
      "learning rate A :  tf.Tensor(9.917946e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 760 is 0.0769 sec\n",
      "train AE loss : 8.154263496398926, train ANN loss : 2.5291860103607178\n",
      "AE loss : 8.143354415893555, ANN loss : 2.2237772941589355, Total loss : 816.5592041015625\n",
      "learning rate A :  tf.Tensor(9.917737e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 761 is 0.0752 sec\n",
      "train AE loss : 7.944882392883301, train ANN loss : 2.5420541763305664\n",
      "AE loss : 8.391936302185059, ANN loss : 2.2232441902160645, Total loss : 841.4168090820312\n",
      "learning rate A :  tf.Tensor(9.917737e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 762 is 0.0775 sec\n",
      "train AE loss : 8.18712043762207, train ANN loss : 2.5350348949432373\n",
      "AE loss : 8.174662590026855, ANN loss : 2.2235965728759766, Total loss : 819.6898193359375\n",
      "learning rate A :  tf.Tensor(9.9175275e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 763 is 0.0770 sec\n",
      "train AE loss : 7.975876808166504, train ANN loss : 2.53605318069458\n",
      "AE loss : 7.967213153839111, ANN loss : 2.2240209579467773, Total loss : 798.9453125\n",
      "learning rate A :  tf.Tensor(9.9173194e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 764 is 0.0759 sec\n",
      "train AE loss : 7.774209499359131, train ANN loss : 2.535123586654663\n",
      "AE loss : 8.250511169433594, ANN loss : 2.224287271499634, Total loss : 827.2754516601562\n",
      "learning rate A :  tf.Tensor(9.9173194e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 765 is 0.0770 sec\n",
      "train AE loss : 8.050458908081055, train ANN loss : 2.5288164615631104\n",
      "AE loss : 8.553771018981934, ANN loss : 2.225309371948242, Total loss : 857.6023559570312\n",
      "learning rate A :  tf.Tensor(9.9173194e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 766 is 0.0769 sec\n",
      "train AE loss : 8.34622573852539, train ANN loss : 2.5302388668060303\n",
      "AE loss : 8.82961368560791, ANN loss : 2.224055051803589, Total loss : 885.1854248046875\n",
      "learning rate A :  tf.Tensor(9.9173194e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 767 is 0.0770 sec\n",
      "train AE loss : 8.614802360534668, train ANN loss : 2.532076597213745\n",
      "AE loss : 9.018030166625977, ANN loss : 2.2172634601593018, Total loss : 904.0203247070312\n",
      "learning rate A :  tf.Tensor(9.9173194e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 768 is 0.0768 sec\n",
      "train AE loss : 8.797825813293457, train ANN loss : 2.514244318008423\n",
      "AE loss : 8.768726348876953, ANN loss : 2.2169883251190186, Total loss : 879.089599609375\n",
      "learning rate A :  tf.Tensor(9.91711e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 769 is 0.0751 sec\n",
      "train AE loss : 8.555510520935059, train ANN loss : 2.523517608642578\n",
      "AE loss : 8.531436920166016, ANN loss : 2.216822624206543, Total loss : 855.3605346679688\n",
      "learning rate A :  tf.Tensor(9.916901e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 770 is 0.0755 sec\n",
      "train AE loss : 8.324840545654297, train ANN loss : 2.52657151222229\n",
      "AE loss : 8.675801277160645, ANN loss : 2.2103071212768555, Total loss : 869.7904663085938\n",
      "learning rate A :  tf.Tensor(9.916901e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 771 is 0.0771 sec\n",
      "train AE loss : 8.464701652526855, train ANN loss : 2.517759084701538\n",
      "AE loss : 8.442625999450684, ANN loss : 2.2103841304779053, Total loss : 846.4729614257812\n",
      "learning rate A :  tf.Tensor(9.916692e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 772 is 0.0756 sec\n",
      "train AE loss : 8.237996101379395, train ANN loss : 2.5105223655700684\n",
      "AE loss : 8.220358848571777, ANN loss : 2.2105538845062256, Total loss : 824.2464599609375\n",
      "learning rate A :  tf.Tensor(9.916483e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 773 is 0.0760 sec\n",
      "train AE loss : 8.02192211151123, train ANN loss : 2.5238964557647705\n",
      "AE loss : 8.395779609680176, ANN loss : 2.2072465419769287, Total loss : 841.78515625\n",
      "learning rate A :  tf.Tensor(9.916483e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 774 is 0.0769 sec\n",
      "train AE loss : 8.192028045654297, train ANN loss : 2.50830340385437\n",
      "AE loss : 8.600598335266113, ANN loss : 2.2046737670898438, Total loss : 862.2645263671875\n",
      "learning rate A :  tf.Tensor(9.916483e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 775 is 0.0778 sec\n",
      "train AE loss : 8.39077377319336, train ANN loss : 2.512753486633301\n",
      "AE loss : 8.839302062988281, ANN loss : 2.2026357650756836, Total loss : 886.1328125\n",
      "learning rate A :  tf.Tensor(9.916483e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 776 is 0.0771 sec\n",
      "train AE loss : 8.62270450592041, train ANN loss : 2.5141537189483643\n",
      "AE loss : 9.09273624420166, ANN loss : 2.2022340297698975, Total loss : 911.4757690429688\n",
      "learning rate A :  tf.Tensor(9.916483e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 777 is 0.0784 sec\n",
      "train AE loss : 8.869263648986816, train ANN loss : 2.5089409351348877\n",
      "AE loss : 9.335054397583008, ANN loss : 2.202160120010376, Total loss : 935.7075805664062\n",
      "learning rate A :  tf.Tensor(9.916483e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 778 is 0.0761 sec\n",
      "train AE loss : 9.105034828186035, train ANN loss : 2.510188102722168\n",
      "AE loss : 9.56082534790039, ANN loss : 2.199991226196289, Total loss : 958.2825317382812\n",
      "learning rate A :  tf.Tensor(9.916483e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 779 is 0.0757 sec\n",
      "train AE loss : 9.324552536010742, train ANN loss : 2.5108869075775146\n",
      "AE loss : 9.2823486328125, ANN loss : 2.199915647506714, Total loss : 930.434814453125\n",
      "learning rate A :  tf.Tensor(9.9162746e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 780 is 0.0738 sec\n",
      "train AE loss : 9.054009437561035, train ANN loss : 2.500828742980957\n",
      "AE loss : 9.017932891845703, ANN loss : 2.1999526023864746, Total loss : 903.9932250976562\n",
      "learning rate A :  tf.Tensor(9.916065e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 781 is 0.0733 sec\n",
      "train AE loss : 8.79708480834961, train ANN loss : 2.515589714050293\n",
      "AE loss : 8.766570091247559, ANN loss : 2.2001044750213623, Total loss : 878.8570556640625\n",
      "learning rate A :  tf.Tensor(9.915856e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 782 is 0.0751 sec\n",
      "train AE loss : 8.5528564453125, train ANN loss : 2.5183956623077393\n",
      "AE loss : 8.527358055114746, ANN loss : 2.200364828109741, Total loss : 854.9361572265625\n",
      "learning rate A :  tf.Tensor(9.9156474e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 783 is 0.0738 sec\n",
      "train AE loss : 8.320398330688477, train ANN loss : 2.5067152976989746\n",
      "AE loss : 8.299494743347168, ANN loss : 2.200709819793701, Total loss : 832.1502075195312\n",
      "learning rate A :  tf.Tensor(9.9154386e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 784 is 0.0738 sec\n",
      "train AE loss : 8.098932266235352, train ANN loss : 2.5091116428375244\n",
      "AE loss : 8.082242012023926, ANN loss : 2.2011477947235107, Total loss : 810.4253540039062\n",
      "learning rate A :  tf.Tensor(9.91523e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 785 is 0.0740 sec\n",
      "train AE loss : 7.8877692222595215, train ANN loss : 2.5027027130126953\n",
      "AE loss : 8.345633506774902, ANN loss : 2.1983938217163086, Total loss : 836.76171875\n",
      "learning rate A :  tf.Tensor(9.91523e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 786 is 0.0752 sec\n",
      "train AE loss : 8.144197463989258, train ANN loss : 2.5050559043884277\n",
      "AE loss : 8.125940322875977, ANN loss : 2.198664426803589, Total loss : 814.7926635742188\n",
      "learning rate A :  tf.Tensor(9.915021e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 787 is 0.0729 sec\n",
      "train AE loss : 7.930657863616943, train ANN loss : 2.504645824432373\n",
      "AE loss : 8.412381172180176, ANN loss : 2.196065664291382, Total loss : 843.4342041015625\n",
      "learning rate A :  tf.Tensor(9.915021e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 788 is 0.0761 sec\n",
      "train AE loss : 8.20945930480957, train ANN loss : 2.4945626258850098\n",
      "AE loss : 8.6903715133667, ANN loss : 2.1930840015411377, Total loss : 871.2302856445312\n",
      "learning rate A :  tf.Tensor(9.915021e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 789 is 0.0759 sec\n",
      "train AE loss : 8.479684829711914, train ANN loss : 2.503934860229492\n",
      "AE loss : 8.453393936157227, ANN loss : 2.192830801010132, Total loss : 847.5322265625\n",
      "learning rate A :  tf.Tensor(9.9148114e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 790 is 0.0741 sec\n",
      "train AE loss : 8.249398231506348, train ANN loss : 2.506037950515747\n",
      "AE loss : 8.71498966217041, ANN loss : 2.1900391578674316, Total loss : 873.6890258789062\n",
      "learning rate A :  tf.Tensor(9.9148114e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 791 is 0.0767 sec\n",
      "train AE loss : 8.50368881225586, train ANN loss : 2.507305860519409\n",
      "AE loss : 8.476420402526855, ANN loss : 2.1897385120391846, Total loss : 849.831787109375\n",
      "learning rate A :  tf.Tensor(9.914603e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 792 is 0.0743 sec\n",
      "train AE loss : 8.271851539611816, train ANN loss : 2.4927642345428467\n",
      "AE loss : 8.249176979064941, ANN loss : 2.1895434856414795, Total loss : 827.1072387695312\n",
      "learning rate A :  tf.Tensor(9.914394e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 793 is 0.0750 sec\n",
      "train AE loss : 8.050996780395508, train ANN loss : 2.4934353828430176\n",
      "AE loss : 8.484931945800781, ANN loss : 2.1870124340057373, Total loss : 850.68017578125\n",
      "learning rate A :  tf.Tensor(9.914394e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 794 is 0.0761 sec\n",
      "train AE loss : 8.280170440673828, train ANN loss : 2.4993155002593994\n",
      "AE loss : 8.256969451904297, ANN loss : 2.1868534088134766, Total loss : 827.8838500976562\n",
      "learning rate A :  tf.Tensor(9.914185e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 795 is 0.0745 sec\n",
      "train AE loss : 8.058643341064453, train ANN loss : 2.4955995082855225\n",
      "AE loss : 8.039679527282715, ANN loss : 2.186800956726074, Total loss : 806.15478515625\n",
      "learning rate A :  tf.Tensor(9.913976e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 796 is 0.0751 sec\n",
      "train AE loss : 7.847438812255859, train ANN loss : 2.50321102142334\n",
      "AE loss : 8.280436515808105, ANN loss : 2.1848111152648926, Total loss : 830.2284545898438\n",
      "learning rate A :  tf.Tensor(9.913976e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 797 is 0.0762 sec\n",
      "train AE loss : 8.081635475158691, train ANN loss : 2.4895026683807373\n",
      "AE loss : 8.506281852722168, ANN loss : 2.1821377277374268, Total loss : 852.810302734375\n",
      "learning rate A :  tf.Tensor(9.913976e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 798 is 0.0834 sec\n",
      "train AE loss : 8.301203727722168, train ANN loss : 2.4885799884796143\n",
      "AE loss : 8.276719093322754, ANN loss : 2.182060718536377, Total loss : 829.85400390625\n",
      "learning rate A :  tf.Tensor(9.913767e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 799 is 0.0894 sec\n",
      "train AE loss : 8.078136444091797, train ANN loss : 2.490793466567993\n",
      "AE loss : 8.500688552856445, ANN loss : 2.180119276046753, Total loss : 852.2490234375\n",
      "learning rate A :  tf.Tensor(9.913767e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 800 is 0.0776 sec\n",
      "train AE loss : 8.295784950256348, train ANN loss : 2.490652084350586\n",
      "AE loss : 8.726086616516113, ANN loss : 2.17824649810791, Total loss : 874.786865234375\n",
      "learning rate A :  tf.Tensor(9.913767e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 801 is 0.0762 sec\n",
      "train AE loss : 8.514803886413574, train ANN loss : 2.475599527359009\n",
      "AE loss : 8.485586166381836, ANN loss : 2.178189992904663, Total loss : 850.73681640625\n",
      "learning rate A :  tf.Tensor(9.9135585e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 802 is 0.0770 sec\n",
      "train AE loss : 8.281115531921387, train ANN loss : 2.4987170696258545\n",
      "AE loss : 8.708996772766113, ANN loss : 2.177074432373047, Total loss : 873.0767211914062\n",
      "learning rate A :  tf.Tensor(9.9135585e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 803 is 0.0769 sec\n",
      "train AE loss : 8.498403549194336, train ANN loss : 2.4887382984161377\n",
      "AE loss : 8.94188117980957, ANN loss : 2.176677703857422, Total loss : 896.3648071289062\n",
      "learning rate A :  tf.Tensor(9.9135585e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 804 is 0.0766 sec\n",
      "train AE loss : 8.724896430969238, train ANN loss : 2.4891908168792725\n",
      "AE loss : 8.690751075744629, ANN loss : 2.176581859588623, Total loss : 871.251708984375\n",
      "learning rate A :  tf.Tensor(9.91335e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 805 is 0.0758 sec\n",
      "train AE loss : 8.48090648651123, train ANN loss : 2.4755632877349854\n",
      "AE loss : 8.93034553527832, ANN loss : 2.176555633544922, Total loss : 895.2111206054688\n",
      "learning rate A :  tf.Tensor(9.91335e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 806 is 0.0760 sec\n",
      "train AE loss : 8.71395206451416, train ANN loss : 2.4855754375457764\n",
      "AE loss : 8.679737091064453, ANN loss : 2.1764678955078125, Total loss : 870.1502075195312\n",
      "learning rate A :  tf.Tensor(9.913141e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 807 is 0.0748 sec\n",
      "train AE loss : 8.470459938049316, train ANN loss : 2.485609292984009\n",
      "AE loss : 8.441330909729004, ANN loss : 2.176503896713257, Total loss : 846.3096313476562\n",
      "learning rate A :  tf.Tensor(9.912932e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 808 is 0.0764 sec\n",
      "train AE loss : 8.238805770874023, train ANN loss : 2.4821503162384033\n",
      "AE loss : 8.214254379272461, ANN loss : 2.1766531467437744, Total loss : 823.60205078125\n",
      "learning rate A :  tf.Tensor(9.912723e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 809 is 0.0748 sec\n",
      "train AE loss : 8.01806926727295, train ANN loss : 2.477358818054199\n",
      "AE loss : 8.463665008544922, ANN loss : 2.1748080253601074, Total loss : 848.5413208007812\n",
      "learning rate A :  tf.Tensor(9.912723e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 810 is 0.0771 sec\n",
      "train AE loss : 8.260767936706543, train ANN loss : 2.4906692504882812\n",
      "AE loss : 8.730262756347656, ANN loss : 2.1732559204101562, Total loss : 875.1995239257812\n",
      "learning rate A :  tf.Tensor(9.912723e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 811 is 0.0781 sec\n",
      "train AE loss : 8.520102500915527, train ANN loss : 2.478924512863159\n",
      "AE loss : 8.488699913024902, ANN loss : 2.173067808151245, Total loss : 851.0430908203125\n",
      "learning rate A :  tf.Tensor(9.9125136e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 812 is 0.0769 sec\n",
      "train AE loss : 8.28535270690918, train ANN loss : 2.475998878479004\n",
      "AE loss : 8.258744239807129, ANN loss : 2.173001527786255, Total loss : 828.0474853515625\n",
      "learning rate A :  tf.Tensor(9.9123055e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 813 is 0.0771 sec\n",
      "train AE loss : 8.061863899230957, train ANN loss : 2.4821724891662598\n",
      "AE loss : 8.03963565826416, ANN loss : 2.1730470657348633, Total loss : 806.1365966796875\n",
      "learning rate A :  tf.Tensor(9.912096e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 814 is 0.0768 sec\n",
      "train AE loss : 7.848855972290039, train ANN loss : 2.480562448501587\n",
      "AE loss : 8.304945945739746, ANN loss : 2.171196937561035, Total loss : 832.665771484375\n",
      "learning rate A :  tf.Tensor(9.912096e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 815 is 0.0778 sec\n",
      "train AE loss : 8.107095718383789, train ANN loss : 2.4760355949401855\n",
      "AE loss : 8.569841384887695, ANN loss : 2.169595718383789, Total loss : 859.1537475585938\n",
      "learning rate A :  tf.Tensor(9.912096e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 816 is 0.0773 sec\n",
      "train AE loss : 8.364843368530273, train ANN loss : 2.4801082611083984\n",
      "AE loss : 8.792081832885742, ANN loss : 2.1657869815826416, Total loss : 881.3739624023438\n",
      "learning rate A :  tf.Tensor(9.912096e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 817 is 0.0781 sec\n",
      "train AE loss : 8.58072566986084, train ANN loss : 2.4729607105255127\n",
      "AE loss : 8.975171089172363, ANN loss : 2.1612789630889893, Total loss : 899.6784057617188\n",
      "learning rate A :  tf.Tensor(9.912096e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 818 is 0.0771 sec\n",
      "train AE loss : 8.75839614868164, train ANN loss : 2.471984386444092\n",
      "AE loss : 8.719833374023438, ANN loss : 2.1608645915985107, Total loss : 874.1441650390625\n",
      "learning rate A :  tf.Tensor(9.911887e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 819 is 0.0749 sec\n",
      "train AE loss : 8.510213851928711, train ANN loss : 2.4692513942718506\n",
      "AE loss : 8.89470386505127, ANN loss : 2.1575353145599365, Total loss : 891.6279907226562\n",
      "learning rate A :  tf.Tensor(9.911887e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 820 is 0.0777 sec\n",
      "train AE loss : 8.679847717285156, train ANN loss : 2.45910906791687\n",
      "AE loss : 8.643258094787598, ANN loss : 2.157357931137085, Total loss : 866.483154296875\n",
      "learning rate A :  tf.Tensor(9.911679e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 821 is 0.0745 sec\n",
      "train AE loss : 8.435497283935547, train ANN loss : 2.462265729904175\n",
      "AE loss : 8.404108047485352, ANN loss : 2.157299518585205, Total loss : 842.568115234375\n",
      "learning rate A :  tf.Tensor(9.9114695e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 822 is 0.0746 sec\n",
      "train AE loss : 8.20305347442627, train ANN loss : 2.4679501056671143\n",
      "AE loss : 8.176457405090332, ANN loss : 2.1573455333709717, Total loss : 819.8030395507812\n",
      "learning rate A :  tf.Tensor(9.911261e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 823 is 0.0758 sec\n",
      "train AE loss : 7.981747150421143, train ANN loss : 2.4685885906219482\n",
      "AE loss : 7.959449768066406, ANN loss : 2.1574809551239014, Total loss : 798.1024780273438\n",
      "learning rate A :  tf.Tensor(9.911051e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 824 is 0.0762 sec\n",
      "train AE loss : 7.770737648010254, train ANN loss : 2.478511333465576\n",
      "AE loss : 8.183990478515625, ANN loss : 2.1551437377929688, Total loss : 820.55419921875\n",
      "learning rate A :  tf.Tensor(9.911051e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 825 is 0.0763 sec\n",
      "train AE loss : 7.989128589630127, train ANN loss : 2.468210220336914\n",
      "AE loss : 8.450169563293457, ANN loss : 2.154874086380005, Total loss : 847.1717529296875\n",
      "learning rate A :  tf.Tensor(9.911051e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 826 is 0.0787 sec\n",
      "train AE loss : 8.248072624206543, train ANN loss : 2.4671292304992676\n",
      "AE loss : 8.728412628173828, ANN loss : 2.155487298965454, Total loss : 874.9967651367188\n",
      "learning rate A :  tf.Tensor(9.911051e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 827 is 0.0781 sec\n",
      "train AE loss : 8.518598556518555, train ANN loss : 2.4616310596466064\n",
      "AE loss : 8.998175621032715, ANN loss : 2.1564605236053467, Total loss : 901.9739990234375\n",
      "learning rate A :  tf.Tensor(9.911051e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 828 is 0.0767 sec\n",
      "train AE loss : 8.780938148498535, train ANN loss : 2.4557836055755615\n",
      "AE loss : 8.738412857055664, ANN loss : 2.155790090560913, Total loss : 875.9971313476562\n",
      "learning rate A :  tf.Tensor(9.910842e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 829 is 0.0764 sec\n",
      "train AE loss : 8.528542518615723, train ANN loss : 2.4523773193359375\n",
      "AE loss : 8.953204154968262, ANN loss : 2.1541388034820557, Total loss : 897.474609375\n",
      "learning rate A :  tf.Tensor(9.910842e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 830 is 0.0875 sec\n",
      "train AE loss : 8.7373628616333, train ANN loss : 2.4638943672180176\n",
      "AE loss : 9.122918128967285, ANN loss : 2.1520886421203613, Total loss : 914.4439086914062\n",
      "learning rate A :  tf.Tensor(9.910842e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 831 is 0.0886 sec\n",
      "train AE loss : 8.902249336242676, train ANN loss : 2.4502596855163574\n",
      "AE loss : 9.285886764526367, ANN loss : 2.1511101722717285, Total loss : 930.7398071289062\n",
      "learning rate A :  tf.Tensor(9.910842e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 832 is 0.0772 sec\n",
      "train AE loss : 9.060389518737793, train ANN loss : 2.4615492820739746\n",
      "AE loss : 9.011324882507324, ANN loss : 2.150738477706909, Total loss : 903.2832641601562\n",
      "learning rate A :  tf.Tensor(9.910634e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 833 is 0.0851 sec\n",
      "train AE loss : 8.793642044067383, train ANN loss : 2.448596239089966\n",
      "AE loss : 9.189194679260254, ANN loss : 2.147947072982788, Total loss : 921.0674438476562\n",
      "learning rate A :  tf.Tensor(9.910634e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 834 is 0.0792 sec\n",
      "train AE loss : 8.966029167175293, train ANN loss : 2.450242042541504\n",
      "AE loss : 9.38837718963623, ANN loss : 2.1453211307525635, Total loss : 940.9829711914062\n",
      "learning rate A :  tf.Tensor(9.910634e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 835 is 0.0765 sec\n",
      "train AE loss : 9.15917682647705, train ANN loss : 2.4563677310943604\n",
      "AE loss : 9.602710723876953, ANN loss : 2.141704797744751, Total loss : 962.4127807617188\n",
      "learning rate A :  tf.Tensor(9.910634e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 836 is 0.0758 sec\n",
      "train AE loss : 9.367473602294922, train ANN loss : 2.449761390686035\n",
      "AE loss : 9.310759544372559, ANN loss : 2.141427516937256, Total loss : 933.2173461914062\n",
      "learning rate A :  tf.Tensor(9.910425e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 837 is 0.0762 sec\n",
      "train AE loss : 9.083867073059082, train ANN loss : 2.4567408561706543\n",
      "AE loss : 9.538260459899902, ANN loss : 2.138228178024292, Total loss : 955.9642333984375\n",
      "learning rate A :  tf.Tensor(9.910425e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 838 is 0.0773 sec\n",
      "train AE loss : 9.305144309997559, train ANN loss : 2.4540462493896484\n",
      "AE loss : 9.249302864074707, ANN loss : 2.1379244327545166, Total loss : 927.0681762695312\n",
      "learning rate A :  tf.Tensor(9.910216e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 839 is 0.0738 sec\n",
      "train AE loss : 9.024459838867188, train ANN loss : 2.457629919052124\n",
      "AE loss : 8.975375175476074, ANN loss : 2.1377816200256348, Total loss : 899.67529296875\n",
      "learning rate A :  tf.Tensor(9.910008e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 840 is 0.0759 sec\n",
      "train AE loss : 8.758331298828125, train ANN loss : 2.4410550594329834\n",
      "AE loss : 8.715333938598633, ANN loss : 2.137779474258423, Total loss : 873.6712036132812\n",
      "learning rate A :  tf.Tensor(9.909798e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 841 is 0.0746 sec\n",
      "train AE loss : 8.50565242767334, train ANN loss : 2.454517126083374\n",
      "AE loss : 8.468220710754395, ANN loss : 2.1379058361053467, Total loss : 848.9599609375\n",
      "learning rate A :  tf.Tensor(9.9095894e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 842 is 0.0770 sec\n",
      "train AE loss : 8.265497207641602, train ANN loss : 2.454900026321411\n",
      "AE loss : 8.740330696105957, ANN loss : 2.1352343559265137, Total loss : 876.1683349609375\n",
      "learning rate A :  tf.Tensor(9.9095894e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 843 is 0.0766 sec\n",
      "train AE loss : 8.530715942382812, train ANN loss : 2.4508228302001953\n",
      "AE loss : 9.045062065124512, ANN loss : 2.135141134262085, Total loss : 906.6412963867188\n",
      "learning rate A :  tf.Tensor(9.9095894e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 844 is 0.0749 sec\n",
      "train AE loss : 8.827493667602539, train ANN loss : 2.4561219215393066\n",
      "AE loss : 8.779970169067383, ANN loss : 2.1345150470733643, Total loss : 880.1315307617188\n",
      "learning rate A :  tf.Tensor(9.909381e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 845 is 0.0734 sec\n",
      "train AE loss : 8.569975852966309, train ANN loss : 2.4400153160095215\n",
      "AE loss : 8.528197288513184, ANN loss : 2.1340434551239014, Total loss : 854.9537963867188\n",
      "learning rate A :  tf.Tensor(9.909172e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 846 is 0.0741 sec\n",
      "train AE loss : 8.325420379638672, train ANN loss : 2.4472317695617676\n",
      "AE loss : 8.288872718811035, ANN loss : 2.133720636367798, Total loss : 831.02099609375\n",
      "learning rate A :  tf.Tensor(9.908963e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 847 is 0.0738 sec\n",
      "train AE loss : 8.092897415161133, train ANN loss : 2.4303271770477295\n",
      "AE loss : 8.061120986938477, ANN loss : 2.1335361003875732, Total loss : 808.2456665039062\n",
      "learning rate A :  tf.Tensor(9.908755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 848 is 0.0740 sec\n",
      "train AE loss : 7.87158203125, train ANN loss : 2.4384939670562744\n",
      "AE loss : 8.373787879943848, ANN loss : 2.134934186935425, Total loss : 839.513671875\n",
      "learning rate A :  tf.Tensor(9.908755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 849 is 0.0775 sec\n",
      "train AE loss : 8.176321983337402, train ANN loss : 2.4482645988464355\n",
      "AE loss : 8.660408973693848, ANN loss : 2.1368930339813232, Total loss : 868.1777954101562\n",
      "learning rate A :  tf.Tensor(9.908755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 850 is 0.0747 sec\n",
      "train AE loss : 8.455238342285156, train ANN loss : 2.4401473999023438\n",
      "AE loss : 8.867439270019531, ANN loss : 2.1353726387023926, Total loss : 888.8792114257812\n",
      "learning rate A :  tf.Tensor(9.908755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 851 is 0.0758 sec\n",
      "train AE loss : 8.656336784362793, train ANN loss : 2.4356513023376465\n",
      "AE loss : 8.609254837036133, ANN loss : 2.1343472003936768, Total loss : 863.059814453125\n",
      "learning rate A :  tf.Tensor(9.908545e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 852 is 0.0954 sec\n",
      "train AE loss : 8.405533790588379, train ANN loss : 2.435162305831909\n",
      "AE loss : 8.363869667053223, ANN loss : 2.1334800720214844, Total loss : 838.5204467773438\n",
      "learning rate A :  tf.Tensor(9.9083365e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 853 is 0.0730 sec\n",
      "train AE loss : 8.167237281799316, train ANN loss : 2.4536025524139404\n",
      "AE loss : 8.530946731567383, ANN loss : 2.1298139095306396, Total loss : 855.2244262695312\n",
      "learning rate A :  tf.Tensor(9.9083365e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 854 is 0.0752 sec\n",
      "train AE loss : 8.329275131225586, train ANN loss : 2.4390242099761963\n",
      "AE loss : 8.2892427444458, ANN loss : 2.12919282913208, Total loss : 831.053466796875\n",
      "learning rate A :  tf.Tensor(9.9081284e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 855 is 0.0741 sec\n",
      "train AE loss : 8.094558715820312, train ANN loss : 2.453688383102417\n",
      "AE loss : 8.438271522521973, ANN loss : 2.1241328716278076, Total loss : 845.9512939453125\n",
      "learning rate A :  tf.Tensor(9.9081284e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 856 is 0.0755 sec\n",
      "train AE loss : 8.23906421661377, train ANN loss : 2.430180549621582\n",
      "AE loss : 8.605831146240234, ANN loss : 2.118957996368408, Total loss : 862.7021484375\n",
      "learning rate A :  tf.Tensor(9.9081284e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 857 is 0.0761 sec\n",
      "train AE loss : 8.401735305786133, train ANN loss : 2.4252774715423584\n",
      "AE loss : 8.80925464630127, ANN loss : 2.1162092685699463, Total loss : 883.0416870117188\n",
      "learning rate A :  tf.Tensor(9.9081284e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 858 is 0.0769 sec\n",
      "train AE loss : 8.599396705627441, train ANN loss : 2.421588182449341\n",
      "AE loss : 9.030922889709473, ANN loss : 2.1152470111846924, Total loss : 905.2075805664062\n",
      "learning rate A :  tf.Tensor(9.9081284e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 859 is 0.0749 sec\n",
      "train AE loss : 8.814949989318848, train ANN loss : 2.422589063644409\n",
      "AE loss : 8.762938499450684, ANN loss : 2.114917516708374, Total loss : 878.4087524414062\n",
      "learning rate A :  tf.Tensor(9.9079196e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 860 is 0.0965 sec\n",
      "train AE loss : 8.55473804473877, train ANN loss : 2.4289052486419678\n",
      "AE loss : 9.010173797607422, ANN loss : 2.1148812770843506, Total loss : 903.1322021484375\n",
      "learning rate A :  tf.Tensor(9.9079196e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 861 is 0.0789 sec\n",
      "train AE loss : 8.795348167419434, train ANN loss : 2.424689292907715\n",
      "AE loss : 8.742618560791016, ANN loss : 2.114490032196045, Total loss : 876.3763427734375\n",
      "learning rate A :  tf.Tensor(9.90771e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 862 is 0.0748 sec\n",
      "train AE loss : 8.535543441772461, train ANN loss : 2.425285816192627\n",
      "AE loss : 8.9946928024292, ANN loss : 2.1158411502838135, Total loss : 901.5851440429688\n",
      "learning rate A :  tf.Tensor(9.90771e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 863 is 0.0782 sec\n",
      "train AE loss : 8.780801773071289, train ANN loss : 2.4206786155700684\n",
      "AE loss : 9.243648529052734, ANN loss : 2.116579294204712, Total loss : 926.4814453125\n",
      "learning rate A :  tf.Tensor(9.90771e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 864 is 0.0766 sec\n",
      "train AE loss : 9.022941589355469, train ANN loss : 2.427971601486206\n",
      "AE loss : 9.463960647583008, ANN loss : 2.1152219772338867, Total loss : 948.5112915039062\n",
      "learning rate A :  tf.Tensor(9.90771e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 865 is 0.0769 sec\n",
      "train AE loss : 9.237183570861816, train ANN loss : 2.424893617630005\n",
      "AE loss : 9.666389465332031, ANN loss : 2.112131118774414, Total loss : 968.7509765625\n",
      "learning rate A :  tf.Tensor(9.90771e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 866 is 0.0787 sec\n",
      "train AE loss : 9.434085845947266, train ANN loss : 2.4249184131622314\n",
      "AE loss : 9.814922332763672, ANN loss : 2.1083014011383057, Total loss : 983.6005249023438\n",
      "learning rate A :  tf.Tensor(9.90771e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 867 is 0.0780 sec\n",
      "train AE loss : 9.578396797180176, train ANN loss : 2.407831907272339\n",
      "AE loss : 9.50244140625, ANN loss : 2.1075127124786377, Total loss : 952.3516235351562\n",
      "learning rate A :  tf.Tensor(9.907502e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 868 is 0.0938 sec\n",
      "train AE loss : 9.274944305419922, train ANN loss : 2.419342041015625\n",
      "AE loss : 9.632665634155273, ANN loss : 2.1038341522216797, Total loss : 965.370361328125\n",
      "learning rate A :  tf.Tensor(9.907502e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 869 is 0.1343 sec\n",
      "train AE loss : 9.401185989379883, train ANN loss : 2.42002534866333\n",
      "AE loss : 9.329957962036133, ANN loss : 2.103435754776001, Total loss : 935.0992431640625\n",
      "learning rate A :  tf.Tensor(9.907293e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 870 is 0.0936 sec\n",
      "train AE loss : 9.107237815856934, train ANN loss : 2.420606851577759\n",
      "AE loss : 9.043437957763672, ANN loss : 2.1032235622406006, Total loss : 906.4469604492188\n",
      "learning rate A :  tf.Tensor(9.907084e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 871 is 0.0747 sec\n",
      "train AE loss : 8.8289213180542, train ANN loss : 2.4151666164398193\n",
      "AE loss : 9.223819732666016, ANN loss : 2.102107048034668, Total loss : 924.4840698242188\n",
      "learning rate A :  tf.Tensor(9.907084e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 872 is 0.0757 sec\n",
      "train AE loss : 9.004144668579102, train ANN loss : 2.4110350608825684\n",
      "AE loss : 8.942452430725098, ANN loss : 2.1020374298095703, Total loss : 896.3472290039062\n",
      "learning rate A :  tf.Tensor(9.9068755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 873 is 0.0756 sec\n",
      "train AE loss : 8.73076057434082, train ANN loss : 2.407956838607788\n",
      "AE loss : 8.675756454467773, ANN loss : 2.102123975753784, Total loss : 869.677734375\n",
      "learning rate A :  tf.Tensor(9.906667e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 874 is 0.0753 sec\n",
      "train AE loss : 8.471622467041016, train ANN loss : 2.4053854942321777\n",
      "AE loss : 8.42262077331543, ANN loss : 2.1023497581481934, Total loss : 844.3644409179688\n",
      "learning rate A :  tf.Tensor(9.906458e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 875 is 0.0748 sec\n",
      "train AE loss : 8.225665092468262, train ANN loss : 2.4280877113342285\n",
      "AE loss : 8.182083129882812, ANN loss : 2.1026980876922607, Total loss : 820.3109741210938\n",
      "learning rate A :  tf.Tensor(9.906249e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 876 is 0.0761 sec\n",
      "train AE loss : 7.991945743560791, train ANN loss : 2.4115335941314697\n",
      "AE loss : 8.45357608795166, ANN loss : 2.103808879852295, Total loss : 847.4613647460938\n",
      "learning rate A :  tf.Tensor(9.906249e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 877 is 0.0781 sec\n",
      "train AE loss : 8.256295204162598, train ANN loss : 2.4086697101593018\n",
      "AE loss : 8.775409698486328, ANN loss : 2.106703519821167, Total loss : 879.647705078125\n",
      "learning rate A :  tf.Tensor(9.906249e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 878 is 0.0793 sec\n",
      "train AE loss : 8.569893836975098, train ANN loss : 2.4111130237579346\n",
      "AE loss : 9.09389877319336, ANN loss : 2.1083438396453857, Total loss : 911.4982299804688\n",
      "learning rate A :  tf.Tensor(9.906249e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 879 is 0.0791 sec\n",
      "train AE loss : 8.879988670349121, train ANN loss : 2.4196865558624268\n",
      "AE loss : 9.331517219543457, ANN loss : 2.10687255859375, Total loss : 935.2586059570312\n",
      "learning rate A :  tf.Tensor(9.906249e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 880 is 0.0892 sec\n",
      "train AE loss : 9.111099243164062, train ANN loss : 2.4069602489471436\n",
      "AE loss : 9.457398414611816, ANN loss : 2.1003615856170654, Total loss : 947.8402099609375\n",
      "learning rate A :  tf.Tensor(9.906249e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 881 is 0.0791 sec\n",
      "train AE loss : 9.233399391174316, train ANN loss : 2.4043822288513184\n",
      "AE loss : 9.158638954162598, ANN loss : 2.0990586280822754, Total loss : 917.9629516601562\n",
      "learning rate A :  tf.Tensor(9.906041e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 882 is 0.0771 sec\n",
      "train AE loss : 8.943167686462402, train ANN loss : 2.417198896408081\n",
      "AE loss : 8.875823020935059, ANN loss : 2.097944736480713, Total loss : 889.6802368164062\n",
      "learning rate A :  tf.Tensor(9.905832e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 883 is 0.0753 sec\n",
      "train AE loss : 8.668376922607422, train ANN loss : 2.4143049716949463\n",
      "AE loss : 8.96414852142334, ANN loss : 2.090954303741455, Total loss : 898.5057983398438\n",
      "learning rate A :  tf.Tensor(9.905832e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 884 is 0.0799 sec\n",
      "train AE loss : 8.753923416137695, train ANN loss : 2.4044740200042725\n",
      "AE loss : 9.072614669799805, ANN loss : 2.0857672691345215, Total loss : 909.3472290039062\n",
      "learning rate A :  tf.Tensor(9.905832e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 885 is 0.0784 sec\n",
      "train AE loss : 8.859025955200195, train ANN loss : 2.403909683227539\n",
      "AE loss : 9.222697257995605, ANN loss : 2.0848042964935303, Total loss : 924.3545532226562\n",
      "learning rate A :  tf.Tensor(9.905832e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 886 is 0.0780 sec\n",
      "train AE loss : 9.004941940307617, train ANN loss : 2.4044039249420166\n",
      "AE loss : 8.935757637023926, ANN loss : 2.084578275680542, Total loss : 895.6603393554688\n",
      "learning rate A :  tf.Tensor(9.905623e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 887 is 0.0864 sec\n",
      "train AE loss : 8.726085662841797, train ANN loss : 2.4046642780303955\n",
      "AE loss : 9.154651641845703, ANN loss : 2.086308717727661, Total loss : 917.5514526367188\n",
      "learning rate A :  tf.Tensor(9.905623e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 888 is 0.0781 sec\n",
      "train AE loss : 8.93967342376709, train ANN loss : 2.3948304653167725\n",
      "AE loss : 8.870779991149902, ANN loss : 2.0860612392425537, Total loss : 889.1640625\n",
      "learning rate A :  tf.Tensor(9.9054145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 889 is 0.0764 sec\n",
      "train AE loss : 8.66380500793457, train ANN loss : 2.3852367401123047\n",
      "AE loss : 9.141905784606934, ANN loss : 2.0897910594940186, Total loss : 916.2803344726562\n",
      "learning rate A :  tf.Tensor(9.9054145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 890 is 0.0791 sec\n",
      "train AE loss : 8.928441047668457, train ANN loss : 2.38814377784729\n",
      "AE loss : 9.437628746032715, ANN loss : 2.0960335731506348, Total loss : 945.85888671875\n",
      "learning rate A :  tf.Tensor(9.9054145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 891 is 0.0778 sec\n",
      "train AE loss : 9.216793060302734, train ANN loss : 2.3904049396514893\n",
      "AE loss : 9.708555221557617, ANN loss : 2.0982844829559326, Total loss : 972.953857421875\n",
      "learning rate A :  tf.Tensor(9.9054145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 892 is 0.0781 sec\n",
      "train AE loss : 9.480491638183594, train ANN loss : 2.3819308280944824\n",
      "AE loss : 9.906964302062988, ANN loss : 2.0952579975128174, Total loss : 992.7916259765625\n",
      "learning rate A :  tf.Tensor(9.9054145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 893 is 0.0784 sec\n",
      "train AE loss : 9.673200607299805, train ANN loss : 2.3948333263397217\n",
      "AE loss : 10.034917831420898, ANN loss : 2.0873594284057617, Total loss : 1005.5792236328125\n",
      "learning rate A :  tf.Tensor(9.9054145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 894 is 0.0783 sec\n",
      "train AE loss : 9.796765327453613, train ANN loss : 2.393817901611328\n",
      "AE loss : 10.132390975952148, ANN loss : 2.0781915187835693, Total loss : 1015.3172607421875\n",
      "learning rate A :  tf.Tensor(9.9054145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 895 is 0.0777 sec\n",
      "train AE loss : 9.89039421081543, train ANN loss : 2.3962738513946533\n",
      "AE loss : 9.791106224060059, ANN loss : 2.077338218688965, Total loss : 981.1879272460938\n",
      "learning rate A :  tf.Tensor(9.905206e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 896 is 0.0759 sec\n",
      "train AE loss : 9.55894660949707, train ANN loss : 2.3856232166290283\n",
      "AE loss : 9.908517837524414, ANN loss : 2.0705745220184326, Total loss : 992.9224243164062\n",
      "learning rate A :  tf.Tensor(9.905206e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 897 is 0.0778 sec\n",
      "train AE loss : 9.672343254089355, train ANN loss : 2.3861148357391357\n",
      "AE loss : 9.579628944396973, ANN loss : 2.070208787918091, Total loss : 960.0331420898438\n",
      "learning rate A :  tf.Tensor(9.904997e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 898 is 0.0758 sec\n",
      "train AE loss : 9.352883338928223, train ANN loss : 2.3885815143585205\n",
      "AE loss : 9.749580383300781, ANN loss : 2.068331718444824, Total loss : 977.0263061523438\n",
      "learning rate A :  tf.Tensor(9.904997e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 899 is 0.0785 sec\n",
      "train AE loss : 9.517965316772461, train ANN loss : 2.382558584213257\n",
      "AE loss : 9.961525917053223, ANN loss : 2.070202112197876, Total loss : 998.222900390625\n",
      "learning rate A :  tf.Tensor(9.904997e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 900 is 0.0780 sec\n",
      "train AE loss : 9.724251747131348, train ANN loss : 2.3900811672210693\n",
      "AE loss : 9.628664016723633, ANN loss : 2.06982159614563, Total loss : 964.9361572265625\n",
      "learning rate A :  tf.Tensor(9.904789e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 901 is 0.0757 sec\n",
      "train AE loss : 9.400955200195312, train ANN loss : 2.382049560546875\n",
      "AE loss : 9.903182983398438, ANN loss : 2.07289457321167, Total loss : 992.3912353515625\n",
      "learning rate A :  tf.Tensor(9.904789e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 902 is 0.0798 sec\n",
      "train AE loss : 9.668447494506836, train ANN loss : 2.3937528133392334\n",
      "AE loss : 10.169605255126953, ANN loss : 2.072263240814209, Total loss : 1019.0328369140625\n",
      "learning rate A :  tf.Tensor(9.904789e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 903 is 0.0782 sec\n",
      "train AE loss : 9.927701950073242, train ANN loss : 2.376527786254883\n",
      "AE loss : 10.388534545898438, ANN loss : 2.071460247039795, Total loss : 1040.925048828125\n",
      "learning rate A :  tf.Tensor(9.904789e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 904 is 0.0787 sec\n",
      "train AE loss : 10.140661239624023, train ANN loss : 2.3748810291290283\n",
      "AE loss : 10.53607177734375, ANN loss : 2.0676960945129395, Total loss : 1055.6748046875\n",
      "learning rate A :  tf.Tensor(9.904789e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 905 is 0.0788 sec\n",
      "train AE loss : 10.283995628356934, train ANN loss : 2.369776487350464\n",
      "AE loss : 10.632515907287598, ANN loss : 2.061985492706299, Total loss : 1065.3135986328125\n",
      "learning rate A :  tf.Tensor(9.904789e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 906 is 0.0787 sec\n",
      "train AE loss : 10.377372741699219, train ANN loss : 2.374680995941162\n",
      "AE loss : 10.255791664123535, ANN loss : 2.0609130859375, Total loss : 1027.6400146484375\n",
      "learning rate A :  tf.Tensor(9.90458e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 907 is 0.0741 sec\n",
      "train AE loss : 10.01159954071045, train ANN loss : 2.378877639770508\n",
      "AE loss : 10.366765975952148, ANN loss : 2.0574846267700195, Total loss : 1038.734130859375\n",
      "learning rate A :  tf.Tensor(9.90458e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 908 is 0.0819 sec\n",
      "train AE loss : 10.119089126586914, train ANN loss : 2.383599281311035\n",
      "AE loss : 10.509176254272461, ANN loss : 2.0551140308380127, Total loss : 1052.9727783203125\n",
      "learning rate A :  tf.Tensor(9.90458e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 909 is 0.0779 sec\n",
      "train AE loss : 10.257529258728027, train ANN loss : 2.369041681289673\n",
      "AE loss : 10.698062896728516, ANN loss : 2.051637649536133, Total loss : 1071.85791015625\n",
      "learning rate A :  tf.Tensor(9.90458e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 910 is 0.0762 sec\n",
      "train AE loss : 10.441291809082031, train ANN loss : 2.375791549682617\n",
      "AE loss : 10.925335884094238, ANN loss : 2.049664258956909, Total loss : 1094.583251953125\n",
      "learning rate A :  tf.Tensor(9.90458e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 911 is 0.0766 sec\n",
      "train AE loss : 10.662506103515625, train ANN loss : 2.3713040351867676\n",
      "AE loss : 10.529147148132324, ANN loss : 2.0489559173583984, Total loss : 1054.963623046875\n",
      "learning rate A :  tf.Tensor(9.904371e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 912 is 0.0741 sec\n",
      "train AE loss : 10.277787208557129, train ANN loss : 2.358940362930298\n",
      "AE loss : 10.787429809570312, ANN loss : 2.050191640853882, Total loss : 1080.793212890625\n",
      "learning rate A :  tf.Tensor(9.904371e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 913 is 0.0757 sec\n",
      "train AE loss : 10.529264450073242, train ANN loss : 2.372015953063965\n",
      "AE loss : 11.03621768951416, ANN loss : 2.054126024246216, Total loss : 1105.6759033203125\n",
      "learning rate A :  tf.Tensor(9.904371e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 914 is 0.0756 sec\n",
      "train AE loss : 10.771320343017578, train ANN loss : 2.3591291904449463\n",
      "AE loss : 11.251811981201172, ANN loss : 2.056637763977051, Total loss : 1127.23779296875\n",
      "learning rate A :  tf.Tensor(9.904371e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 915 is 0.0757 sec\n",
      "train AE loss : 10.98050308227539, train ANN loss : 2.3551101684570312\n",
      "AE loss : 11.43792724609375, ANN loss : 2.0547754764556885, Total loss : 1145.847412109375\n",
      "learning rate A :  tf.Tensor(9.904371e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 916 is 0.0753 sec\n",
      "train AE loss : 11.160504341125488, train ANN loss : 2.3605053424835205\n",
      "AE loss : 11.005902290344238, ANN loss : 2.053323268890381, Total loss : 1102.6434326171875\n",
      "learning rate A :  tf.Tensor(9.904162e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 917 is 0.0742 sec\n",
      "train AE loss : 10.741029739379883, train ANN loss : 2.3580856323242188\n",
      "AE loss : 10.601168632507324, ANN loss : 2.052175521850586, Total loss : 1062.1690673828125\n",
      "learning rate A :  tf.Tensor(9.9039535e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 918 is 0.0740 sec\n",
      "train AE loss : 10.348047256469727, train ANN loss : 2.3582940101623535\n",
      "AE loss : 10.76459789276123, ANN loss : 2.0454564094543457, Total loss : 1078.50537109375\n",
      "learning rate A :  tf.Tensor(9.9039535e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 919 is 0.0755 sec\n",
      "train AE loss : 10.506155014038086, train ANN loss : 2.353429079055786\n",
      "AE loss : 10.956949234008789, ANN loss : 2.039462089538574, Total loss : 1097.734375\n",
      "learning rate A :  tf.Tensor(9.9039535e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 920 is 0.0768 sec\n",
      "train AE loss : 10.69249439239502, train ANN loss : 2.351405382156372\n",
      "AE loss : 10.553605079650879, ANN loss : 2.0384950637817383, Total loss : 1057.39892578125\n",
      "learning rate A :  tf.Tensor(9.903745e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 921 is 0.0741 sec\n",
      "train AE loss : 10.30080509185791, train ANN loss : 2.3613600730895996\n",
      "AE loss : 10.175368309020996, ANN loss : 2.0378313064575195, Total loss : 1019.5746459960938\n",
      "learning rate A :  tf.Tensor(9.903536e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 922 is 0.0732 sec\n",
      "train AE loss : 9.933429718017578, train ANN loss : 2.3639960289001465\n",
      "AE loss : 9.820085525512695, ANN loss : 2.0374653339385986, Total loss : 984.0459594726562\n",
      "learning rate A :  tf.Tensor(9.903328e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 923 is 0.0753 sec\n",
      "train AE loss : 9.588371276855469, train ANN loss : 2.36826491355896\n",
      "AE loss : 10.047311782836914, ANN loss : 2.0357797145843506, Total loss : 1006.7669677734375\n",
      "learning rate A :  tf.Tensor(9.903328e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 924 is 0.0767 sec\n",
      "train AE loss : 9.809555053710938, train ANN loss : 2.3607089519500732\n",
      "AE loss : 9.698756217956543, ANN loss : 2.0352816581726074, Total loss : 971.910888671875\n",
      "learning rate A :  tf.Tensor(9.903119e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 925 is 0.0734 sec\n",
      "train AE loss : 9.471022605895996, train ANN loss : 2.363140821456909\n",
      "AE loss : 9.977967262268066, ANN loss : 2.0382609367370605, Total loss : 999.8349609375\n",
      "learning rate A :  tf.Tensor(9.903119e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 926 is 0.0770 sec\n",
      "train AE loss : 9.743361473083496, train ANN loss : 2.363809823989868\n",
      "AE loss : 10.24620246887207, ANN loss : 2.040479898452759, Total loss : 1026.66064453125\n",
      "learning rate A :  tf.Tensor(9.903119e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 927 is 0.0753 sec\n",
      "train AE loss : 10.004993438720703, train ANN loss : 2.3542048931121826\n",
      "AE loss : 9.883782386779785, ANN loss : 2.0390164852142334, Total loss : 990.417236328125\n",
      "learning rate A :  tf.Tensor(9.90291e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 928 is 0.0746 sec\n",
      "train AE loss : 9.652863502502441, train ANN loss : 2.3549129962921143\n",
      "AE loss : 10.094691276550293, ANN loss : 2.037661552429199, Total loss : 1011.5067138671875\n",
      "learning rate A :  tf.Tensor(9.90291e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 929 is 0.0764 sec\n",
      "train AE loss : 9.858222961425781, train ANN loss : 2.3631317615509033\n",
      "AE loss : 10.250916481018066, ANN loss : 2.035447835922241, Total loss : 1027.1270751953125\n",
      "learning rate A :  tf.Tensor(9.90291e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 930 is 0.0762 sec\n",
      "train AE loss : 10.01003360748291, train ANN loss : 2.347607374191284\n",
      "AE loss : 10.3662691116333, ANN loss : 2.0298335552215576, Total loss : 1038.65673828125\n",
      "learning rate A :  tf.Tensor(9.90291e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 931 is 0.0764 sec\n",
      "train AE loss : 10.122010231018066, train ANN loss : 2.3533151149749756\n",
      "AE loss : 9.995352745056152, ANN loss : 2.0286591053009033, Total loss : 1001.5638427734375\n",
      "learning rate A :  tf.Tensor(9.902702e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 932 is 0.0751 sec\n",
      "train AE loss : 9.761631965637207, train ANN loss : 2.353700876235962\n",
      "AE loss : 10.12696647644043, ANN loss : 2.024268388748169, Total loss : 1014.7208862304688\n",
      "learning rate A :  tf.Tensor(9.902702e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 933 is 0.0759 sec\n",
      "train AE loss : 9.889498710632324, train ANN loss : 2.3576362133026123\n",
      "AE loss : 10.30574893951416, ANN loss : 2.0237529277801514, Total loss : 1032.5987548828125\n",
      "learning rate A :  tf.Tensor(9.902702e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 934 is 0.0757 sec\n",
      "train AE loss : 10.063950538635254, train ANN loss : 2.3524749279022217\n",
      "AE loss : 10.523681640625, ANN loss : 2.026088237762451, Total loss : 1054.394287109375\n",
      "learning rate A :  tf.Tensor(9.902702e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 935 is 0.0769 sec\n",
      "train AE loss : 10.276798248291016, train ANN loss : 2.3458821773529053\n",
      "AE loss : 10.72044849395752, ANN loss : 2.0274505615234375, Total loss : 1074.072265625\n",
      "learning rate A :  tf.Tensor(9.902702e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 936 is 0.0756 sec\n",
      "train AE loss : 10.468876838684082, train ANN loss : 2.349038600921631\n",
      "AE loss : 10.8973388671875, ANN loss : 2.0284032821655273, Total loss : 1091.76220703125\n",
      "learning rate A :  tf.Tensor(9.902702e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 937 is 0.0766 sec\n",
      "train AE loss : 10.641254425048828, train ANN loss : 2.339986562728882\n",
      "AE loss : 10.490488052368164, ANN loss : 2.0273566246032715, Total loss : 1051.0762939453125\n",
      "learning rate A :  tf.Tensor(9.902493e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 938 is 0.0764 sec\n",
      "train AE loss : 10.24605941772461, train ANN loss : 2.3409030437469482\n",
      "AE loss : 10.697822570800781, ANN loss : 2.0268852710723877, Total loss : 1071.8092041015625\n",
      "learning rate A :  tf.Tensor(9.902493e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 939 is 0.0772 sec\n",
      "train AE loss : 10.447870254516602, train ANN loss : 2.3382184505462646\n",
      "AE loss : 10.929454803466797, ANN loss : 2.0258915424346924, Total loss : 1094.9713134765625\n",
      "learning rate A :  tf.Tensor(9.902493e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 940 is 0.0771 sec\n",
      "train AE loss : 10.67325496673584, train ANN loss : 2.3275198936462402\n",
      "AE loss : 11.120025634765625, ANN loss : 2.022006034851074, Total loss : 1114.0245361328125\n",
      "learning rate A :  tf.Tensor(9.902493e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 941 is 0.0788 sec\n",
      "train AE loss : 10.858272552490234, train ANN loss : 2.348332643508911\n",
      "AE loss : 10.696488380432129, ANN loss : 2.02060866355896, Total loss : 1071.66943359375\n",
      "learning rate A :  tf.Tensor(9.9022844e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 942 is 0.0746 sec\n",
      "train AE loss : 10.446816444396973, train ANN loss : 2.3347628116607666\n",
      "AE loss : 10.891256332397461, ANN loss : 2.015103816986084, Total loss : 1091.1407470703125\n",
      "learning rate A :  tf.Tensor(9.9022844e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 943 is 0.0777 sec\n",
      "train AE loss : 10.63588809967041, train ANN loss : 2.3329787254333496\n",
      "AE loss : 11.082120895385742, ANN loss : 2.0113444328308105, Total loss : 1110.223388671875\n",
      "learning rate A :  tf.Tensor(9.9022844e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 944 is 0.0777 sec\n",
      "train AE loss : 10.821258544921875, train ANN loss : 2.3386898040771484\n",
      "AE loss : 11.251546859741211, ANN loss : 2.0086777210235596, Total loss : 1127.163330078125\n",
      "learning rate A :  tf.Tensor(9.9022844e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 945 is 0.0777 sec\n",
      "train AE loss : 10.985759735107422, train ANN loss : 2.3448739051818848\n",
      "AE loss : 10.817712783813477, ANN loss : 2.0073680877685547, Total loss : 1083.778564453125\n",
      "learning rate A :  tf.Tensor(9.9020755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 946 is 0.0750 sec\n",
      "train AE loss : 10.564298629760742, train ANN loss : 2.3348677158355713\n",
      "AE loss : 11.010783195495605, ANN loss : 2.006809949874878, Total loss : 1103.0850830078125\n",
      "learning rate A :  tf.Tensor(9.9020755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 947 is 0.0782 sec\n",
      "train AE loss : 10.75223445892334, train ANN loss : 2.3310580253601074\n",
      "AE loss : 10.591938018798828, ANN loss : 2.005704879760742, Total loss : 1061.1995849609375\n",
      "learning rate A :  tf.Tensor(9.9018675e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 948 is 0.0756 sec\n",
      "train AE loss : 10.345330238342285, train ANN loss : 2.325416326522827\n",
      "AE loss : 10.200067520141602, ANN loss : 2.0049567222595215, Total loss : 1022.0117797851562\n",
      "learning rate A :  tf.Tensor(9.9016586e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 949 is 0.0766 sec\n",
      "train AE loss : 9.964532852172852, train ANN loss : 2.3440005779266357\n",
      "AE loss : 9.832651138305664, ANN loss : 2.004533290863037, Total loss : 985.2696533203125\n",
      "learning rate A :  tf.Tensor(9.90145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 950 is 0.0758 sec\n",
      "train AE loss : 9.607444763183594, train ANN loss : 2.335055351257324\n",
      "AE loss : 10.075800895690918, ANN loss : 2.0059220790863037, Total loss : 1009.5859375\n",
      "learning rate A :  tf.Tensor(9.90145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 951 is 0.0773 sec\n",
      "train AE loss : 9.844843864440918, train ANN loss : 2.340109348297119\n",
      "AE loss : 10.368311882019043, ANN loss : 2.012547731399536, Total loss : 1038.8436279296875\n",
      "learning rate A :  tf.Tensor(9.90145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 952 is 0.0766 sec\n",
      "train AE loss : 10.130794525146484, train ANN loss : 2.3354790210723877\n",
      "AE loss : 10.625126838684082, ANN loss : 2.016897439956665, Total loss : 1064.5296630859375\n",
      "learning rate A :  tf.Tensor(9.90145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 953 is 0.0783 sec\n",
      "train AE loss : 10.381710052490234, train ANN loss : 2.331564426422119\n",
      "AE loss : 10.228240966796875, ANN loss : 2.015080690383911, Total loss : 1024.8392333984375\n",
      "learning rate A :  tf.Tensor(9.901242e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 954 is 0.0752 sec\n",
      "train AE loss : 9.995959281921387, train ANN loss : 2.330678939819336\n",
      "AE loss : 10.423361778259277, ANN loss : 2.0149331092834473, Total loss : 1044.35107421875\n",
      "learning rate A :  tf.Tensor(9.901242e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 955 is 0.0780 sec\n",
      "train AE loss : 10.186079978942871, train ANN loss : 2.3139235973358154\n",
      "AE loss : 10.03858757019043, ANN loss : 2.013258218765259, Total loss : 1005.8720092773438\n",
      "learning rate A :  tf.Tensor(9.901033e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 956 is 0.0766 sec\n",
      "train AE loss : 9.812113761901855, train ANN loss : 2.3223583698272705\n",
      "AE loss : 10.218908309936523, ANN loss : 2.0119686126708984, Total loss : 1023.9027099609375\n",
      "learning rate A :  tf.Tensor(9.901033e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 957 is 0.0832 sec\n",
      "train AE loss : 9.987292289733887, train ANN loss : 2.3408191204071045\n",
      "AE loss : 10.363601684570312, ANN loss : 2.006601572036743, Total loss : 1038.36669921875\n",
      "learning rate A :  tf.Tensor(9.901033e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 958 is 0.0787 sec\n",
      "train AE loss : 10.127115249633789, train ANN loss : 2.325840950012207\n",
      "AE loss : 10.489640235900879, ANN loss : 1.997381329536438, Total loss : 1050.9613037109375\n",
      "learning rate A :  tf.Tensor(9.901033e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 959 is 0.0888 sec\n",
      "train AE loss : 10.248452186584473, train ANN loss : 2.3357203006744385\n",
      "AE loss : 10.614930152893066, ANN loss : 1.9911726713180542, Total loss : 1063.484130859375\n",
      "learning rate A :  tf.Tensor(9.901033e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 960 is 0.0778 sec\n",
      "train AE loss : 10.369118690490723, train ANN loss : 2.337599039077759\n",
      "AE loss : 10.215757369995117, ANN loss : 1.9902101755142212, Total loss : 1023.5659790039062\n",
      "learning rate A :  tf.Tensor(9.900824e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 961 is 0.0756 sec\n",
      "train AE loss : 9.981313705444336, train ANN loss : 2.331435203552246\n",
      "AE loss : 9.842037200927734, ANN loss : 1.9896141290664673, Total loss : 986.193359375\n",
      "learning rate A :  tf.Tensor(9.900615e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 962 is 0.0770 sec\n",
      "train AE loss : 9.618081092834473, train ANN loss : 2.314573287963867\n",
      "AE loss : 10.033279418945312, ANN loss : 1.990508794784546, Total loss : 1005.3184204101562\n",
      "learning rate A :  tf.Tensor(9.900615e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 963 is 0.0782 sec\n",
      "train AE loss : 9.803871154785156, train ANN loss : 2.3359858989715576\n",
      "AE loss : 9.670698165893555, ANN loss : 1.9900453090667725, Total loss : 969.0598754882812\n",
      "learning rate A :  tf.Tensor(9.900407e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 964 is 0.0757 sec\n",
      "train AE loss : 9.451462745666504, train ANN loss : 2.3364059925079346\n",
      "AE loss : 9.923068046569824, ANN loss : 1.9950519800186157, Total loss : 994.3018798828125\n",
      "learning rate A :  tf.Tensor(9.900407e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 965 is 0.0791 sec\n",
      "train AE loss : 9.697583198547363, train ANN loss : 2.314561128616333\n",
      "AE loss : 10.188048362731934, ANN loss : 1.9999200105667114, Total loss : 1020.8047485351562\n",
      "learning rate A :  tf.Tensor(9.900407e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 966 is 0.0773 sec\n",
      "train AE loss : 9.956356048583984, train ANN loss : 2.3148884773254395\n",
      "AE loss : 9.811004638671875, ANN loss : 1.9985357522964478, Total loss : 983.0989990234375\n",
      "learning rate A :  tf.Tensor(9.900197e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 967 is 0.0757 sec\n",
      "train AE loss : 9.589862823486328, train ANN loss : 2.3308308124542236\n",
      "AE loss : 9.456963539123535, ANN loss : 1.9974616765975952, Total loss : 947.69384765625\n",
      "learning rate A :  tf.Tensor(9.899989e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 968 is 0.0762 sec\n",
      "train AE loss : 9.245649337768555, train ANN loss : 2.314136505126953\n",
      "AE loss : 9.739447593688965, ANN loss : 2.001338005065918, Total loss : 975.946044921875\n",
      "learning rate A :  tf.Tensor(9.899989e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 969 is 0.0779 sec\n",
      "train AE loss : 9.521784782409668, train ANN loss : 2.310643196105957\n",
      "AE loss : 9.976057052612305, ANN loss : 2.0011794567108154, Total loss : 999.6068725585938\n",
      "learning rate A :  tf.Tensor(9.899989e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 970 is 0.0787 sec\n",
      "train AE loss : 9.75244426727295, train ANN loss : 2.3124778270721436\n",
      "AE loss : 9.609496116638184, ANN loss : 1.9993109703063965, Total loss : 962.9488525390625\n",
      "learning rate A :  tf.Tensor(9.89978e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 971 is 0.0780 sec\n",
      "train AE loss : 9.396147727966309, train ANN loss : 2.309011697769165\n",
      "AE loss : 9.265473365783691, ANN loss : 1.997746229171753, Total loss : 928.5451049804688\n",
      "learning rate A :  tf.Tensor(9.899571e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 972 is 0.0744 sec\n",
      "train AE loss : 9.061654090881348, train ANN loss : 2.3022353649139404\n",
      "AE loss : 9.49063777923584, ANN loss : 1.9976799488067627, Total loss : 951.0614624023438\n",
      "learning rate A :  tf.Tensor(9.899571e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 973 is 0.0767 sec\n",
      "train AE loss : 9.281052589416504, train ANN loss : 2.3188273906707764\n",
      "AE loss : 9.152390480041504, ANN loss : 1.9960579872131348, Total loss : 917.235107421875\n",
      "learning rate A :  tf.Tensor(9.899362e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 974 is 0.0750 sec\n",
      "train AE loss : 8.952149391174316, train ANN loss : 2.310346841812134\n",
      "AE loss : 9.37307357788086, ANN loss : 1.9960997104644775, Total loss : 939.303466796875\n",
      "learning rate A :  tf.Tensor(9.899362e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 975 is 0.0769 sec\n",
      "train AE loss : 9.166863441467285, train ANN loss : 2.3202147483825684\n",
      "AE loss : 9.040331840515137, ANN loss : 1.9945088624954224, Total loss : 906.0277709960938\n",
      "learning rate A :  tf.Tensor(9.899155e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 976 is 0.0743 sec\n",
      "train AE loss : 8.84326171875, train ANN loss : 2.318061590194702\n",
      "AE loss : 8.727264404296875, ANN loss : 1.993227481842041, Total loss : 874.7197265625\n",
      "learning rate A :  tf.Tensor(9.898946e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 977 is 0.0743 sec\n",
      "train AE loss : 8.538753509521484, train ANN loss : 2.315650224685669\n",
      "AE loss : 8.432469367980957, ANN loss : 1.9922336339950562, Total loss : 845.2391967773438\n",
      "learning rate A :  tf.Tensor(9.898737e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 978 is 0.0740 sec\n",
      "train AE loss : 8.2518949508667, train ANN loss : 2.318715810775757\n",
      "AE loss : 8.154500961303711, ANN loss : 1.9915058612823486, Total loss : 817.4415283203125\n",
      "learning rate A :  tf.Tensor(9.8985285e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 979 is 0.0737 sec\n",
      "train AE loss : 7.9813008308410645, train ANN loss : 2.3173372745513916\n",
      "AE loss : 8.39206314086914, ANN loss : 1.9929643869400024, Total loss : 841.1992797851562\n",
      "learning rate A :  tf.Tensor(9.8985285e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 980 is 0.0775 sec\n",
      "train AE loss : 8.212824821472168, train ANN loss : 2.3071112632751465\n",
      "AE loss : 8.645674705505371, ANN loss : 1.9954476356506348, Total loss : 866.5629272460938\n",
      "learning rate A :  tf.Tensor(9.8985285e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 981 is 0.0759 sec\n",
      "train AE loss : 8.460147857666016, train ANN loss : 2.308746099472046\n",
      "AE loss : 8.875386238098145, ANN loss : 1.9939806461334229, Total loss : 889.5326538085938\n",
      "learning rate A :  tf.Tensor(9.8985285e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 982 is 0.0766 sec\n",
      "train AE loss : 8.683867454528809, train ANN loss : 2.304060697555542\n",
      "AE loss : 9.045805931091309, ANN loss : 1.9889310598373413, Total loss : 906.5694580078125\n",
      "learning rate A :  tf.Tensor(9.8985285e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 983 is 0.0879 sec\n",
      "train AE loss : 8.84956169128418, train ANN loss : 2.304401159286499\n",
      "AE loss : 8.72698974609375, ANN loss : 1.9871453046798706, Total loss : 874.6861572265625\n",
      "learning rate A :  tf.Tensor(9.8983204e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 984 is 0.0746 sec\n",
      "train AE loss : 8.539432525634766, train ANN loss : 2.308062791824341\n",
      "AE loss : 8.426931381225586, ANN loss : 1.9856494665145874, Total loss : 844.6787719726562\n",
      "learning rate A :  tf.Tensor(9.8981116e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 985 is 0.0756 sec\n",
      "train AE loss : 8.247490882873535, train ANN loss : 2.304348945617676\n",
      "AE loss : 8.573833465576172, ANN loss : 1.9806163311004639, Total loss : 859.3639526367188\n",
      "learning rate A :  tf.Tensor(9.8981116e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 986 is 0.0882 sec\n",
      "train AE loss : 8.390076637268066, train ANN loss : 2.30926251411438\n",
      "AE loss : 8.731585502624512, ANN loss : 1.9773638248443604, Total loss : 875.1358642578125\n",
      "learning rate A :  tf.Tensor(9.8981116e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 987 is 0.0859 sec\n",
      "train AE loss : 8.543774604797363, train ANN loss : 2.3169288635253906\n",
      "AE loss : 8.429814338684082, ANN loss : 1.9760568141937256, Total loss : 844.95751953125\n",
      "learning rate A :  tf.Tensor(9.897903e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 988 is 0.0787 sec\n",
      "train AE loss : 8.250171661376953, train ANN loss : 2.3060059547424316\n",
      "AE loss : 8.592522621154785, ANN loss : 1.9764070510864258, Total loss : 861.2286987304688\n",
      "learning rate A :  tf.Tensor(9.897903e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 989 is 0.0798 sec\n",
      "train AE loss : 8.409344673156738, train ANN loss : 2.304454803466797\n",
      "AE loss : 8.297791481018066, ANN loss : 1.9750984907150269, Total loss : 831.7542724609375\n",
      "learning rate A :  tf.Tensor(9.897695e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 990 is 0.0759 sec\n",
      "train AE loss : 8.122512817382812, train ANN loss : 2.3047285079956055\n",
      "AE loss : 8.020038604736328, ANN loss : 1.9740736484527588, Total loss : 803.9779052734375\n",
      "learning rate A :  tf.Tensor(9.897486e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 991 is 0.0781 sec\n",
      "train AE loss : 7.852101802825928, train ANN loss : 2.2931792736053467\n",
      "AE loss : 7.757991313934326, ANN loss : 1.973296880722046, Total loss : 777.7724609375\n",
      "learning rate A :  tf.Tensor(9.897277e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 992 is 0.0785 sec\n",
      "train AE loss : 7.597005367279053, train ANN loss : 2.3031349182128906\n",
      "AE loss : 7.9570183753967285, ANN loss : 1.9794517755508423, Total loss : 797.6813354492188\n",
      "learning rate A :  tf.Tensor(9.897277e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 993 is 0.0785 sec\n",
      "train AE loss : 7.792293548583984, train ANN loss : 2.3011796474456787\n",
      "AE loss : 8.166410446166992, ANN loss : 1.9821585416793823, Total loss : 818.6232299804688\n",
      "learning rate A :  tf.Tensor(9.897277e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 994 is 0.0804 sec\n",
      "train AE loss : 7.997703552246094, train ANN loss : 2.2921524047851562\n",
      "AE loss : 8.342358589172363, ANN loss : 1.978763222694397, Total loss : 836.2146606445312\n",
      "learning rate A :  tf.Tensor(9.897277e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 995 is 0.0787 sec\n",
      "train AE loss : 8.16966438293457, train ANN loss : 2.289250612258911\n",
      "AE loss : 8.48304557800293, ANN loss : 1.971771240234375, Total loss : 850.2763061523438\n",
      "learning rate A :  tf.Tensor(9.897277e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 996 is 0.0797 sec\n",
      "train AE loss : 8.307019233703613, train ANN loss : 2.2961795330047607\n",
      "AE loss : 8.569428443908691, ANN loss : 1.9649758338928223, Total loss : 858.9077758789062\n",
      "learning rate A :  tf.Tensor(9.897277e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 997 is 0.0801 sec\n",
      "train AE loss : 8.390643119812012, train ANN loss : 2.291795015335083\n",
      "AE loss : 8.625544548034668, ANN loss : 1.9627200365066528, Total loss : 864.5171508789062\n",
      "learning rate A :  tf.Tensor(9.897277e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 998 is 0.0808 sec\n",
      "train AE loss : 8.44532585144043, train ANN loss : 2.290111780166626\n",
      "AE loss : 8.717581748962402, ANN loss : 1.9654642343521118, Total loss : 873.7236328125\n",
      "learning rate A :  tf.Tensor(9.897277e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 999 is 0.0796 sec\n",
      "train AE loss : 8.535650253295898, train ANN loss : 2.283881425857544\n",
      "AE loss : 8.411367416381836, ANN loss : 1.9641855955123901, Total loss : 843.1008911132812\n",
      "learning rate A :  tf.Tensor(9.897068e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1000 is 0.0787 sec\n",
      "train AE loss : 8.237418174743652, train ANN loss : 2.293818712234497\n",
      "AE loss : 8.540931701660156, ANN loss : 1.9642161130905151, Total loss : 856.057373046875\n",
      "learning rate A :  tf.Tensor(9.897068e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1001 is 0.0799 sec\n",
      "train AE loss : 8.365133285522461, train ANN loss : 2.295208692550659\n",
      "AE loss : 8.713661193847656, ANN loss : 1.9646090269088745, Total loss : 873.3306884765625\n",
      "learning rate A :  tf.Tensor(9.897068e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1002 is 0.0813 sec\n",
      "train AE loss : 8.535313606262207, train ANN loss : 2.2835540771484375\n",
      "AE loss : 8.88093090057373, ANN loss : 1.96465003490448, Total loss : 890.0577392578125\n",
      "learning rate A :  tf.Tensor(9.897068e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1003 is 0.0818 sec\n",
      "train AE loss : 8.699400901794434, train ANN loss : 2.2842605113983154\n",
      "AE loss : 8.561211585998535, ANN loss : 1.96292245388031, Total loss : 858.0841064453125\n",
      "learning rate A :  tf.Tensor(9.89686e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1004 is 0.0802 sec\n",
      "train AE loss : 8.387979507446289, train ANN loss : 2.2901647090911865\n",
      "AE loss : 8.754998207092285, ANN loss : 1.964102864265442, Total loss : 877.4639282226562\n",
      "learning rate A :  tf.Tensor(9.89686e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1005 is 0.0811 sec\n",
      "train AE loss : 8.57730484008789, train ANN loss : 2.285085678100586\n",
      "AE loss : 8.942139625549316, ANN loss : 1.9667290449142456, Total loss : 896.1807250976562\n",
      "learning rate A :  tf.Tensor(9.89686e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1006 is 0.0817 sec\n",
      "train AE loss : 8.75925064086914, train ANN loss : 2.2876198291778564\n",
      "AE loss : 9.095990180969238, ANN loss : 1.9659136533737183, Total loss : 911.56494140625\n",
      "learning rate A :  tf.Tensor(9.89686e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1007 is 0.0805 sec\n",
      "train AE loss : 8.90819263458252, train ANN loss : 2.2855324745178223\n",
      "AE loss : 8.761953353881836, ANN loss : 1.964086890220642, Total loss : 878.1593627929688\n",
      "learning rate A :  tf.Tensor(9.896652e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1008 is 0.0786 sec\n",
      "train AE loss : 8.582820892333984, train ANN loss : 2.2928061485290527\n",
      "AE loss : 8.912283897399902, ANN loss : 1.9589875936508179, Total loss : 893.1873779296875\n",
      "learning rate A :  tf.Tensor(9.896652e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1009 is 0.0822 sec\n",
      "train AE loss : 8.72868537902832, train ANN loss : 2.2833449840545654\n",
      "AE loss : 9.070576667785645, ANN loss : 1.9550038576126099, Total loss : 909.0126953125\n",
      "learning rate A :  tf.Tensor(9.896652e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1010 is 0.0815 sec\n",
      "train AE loss : 8.883082389831543, train ANN loss : 2.279501438140869\n",
      "AE loss : 9.221848487854004, ANN loss : 1.9523732662200928, Total loss : 924.1373291015625\n",
      "learning rate A :  tf.Tensor(9.896652e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1011 is 0.0806 sec\n",
      "train AE loss : 9.03149700164795, train ANN loss : 2.270307779312134\n",
      "AE loss : 9.336556434631348, ANN loss : 1.9519540071487427, Total loss : 935.6076049804688\n",
      "learning rate A :  tf.Tensor(9.896652e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1012 is 0.0811 sec\n",
      "train AE loss : 9.144329071044922, train ANN loss : 2.285407066345215\n",
      "AE loss : 8.98266315460205, ANN loss : 1.9498846530914307, Total loss : 900.2162475585938\n",
      "learning rate A :  tf.Tensor(9.896443e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1013 is 0.0782 sec\n",
      "train AE loss : 8.79965591430664, train ANN loss : 2.278275728225708\n",
      "AE loss : 9.0933198928833, ANN loss : 1.9518239498138428, Total loss : 911.2838134765625\n",
      "learning rate A :  tf.Tensor(9.896443e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1014 is 0.0808 sec\n",
      "train AE loss : 8.908954620361328, train ANN loss : 2.2753398418426514\n",
      "AE loss : 9.206846237182617, ANN loss : 1.9527182579040527, Total loss : 922.6373901367188\n",
      "learning rate A :  tf.Tensor(9.896443e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1015 is 0.0819 sec\n",
      "train AE loss : 9.020845413208008, train ANN loss : 2.2793190479278564\n",
      "AE loss : 9.316007614135742, ANN loss : 1.9499377012252808, Total loss : 933.5506591796875\n",
      "learning rate A :  tf.Tensor(9.896443e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1016 is 0.0796 sec\n",
      "train AE loss : 9.127910614013672, train ANN loss : 2.2712080478668213\n",
      "AE loss : 8.959349632263184, ANN loss : 1.948022484779358, Total loss : 897.8829345703125\n",
      "learning rate A :  tf.Tensor(9.8962344e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1017 is 0.0781 sec\n",
      "train AE loss : 8.780548095703125, train ANN loss : 2.269529342651367\n",
      "AE loss : 9.073444366455078, ANN loss : 1.9460721015930176, Total loss : 909.2904663085938\n",
      "learning rate A :  tf.Tensor(9.8962344e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1018 is 0.0810 sec\n",
      "train AE loss : 8.892325401306152, train ANN loss : 2.275128126144409\n",
      "AE loss : 8.732099533081055, ANN loss : 1.944502830505371, Total loss : 875.1544189453125\n",
      "learning rate A :  tf.Tensor(9.896026e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1019 is 0.0794 sec\n",
      "train AE loss : 8.559718132019043, train ANN loss : 2.2753970623016357\n",
      "AE loss : 8.412174224853516, ANN loss : 1.9432653188705444, Total loss : 843.1607055664062\n",
      "learning rate A :  tf.Tensor(9.895818e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1020 is 0.0797 sec\n",
      "train AE loss : 8.247993469238281, train ANN loss : 2.2671055793762207\n",
      "AE loss : 8.58647346496582, ANN loss : 1.943411946296692, Total loss : 860.5907592773438\n",
      "learning rate A :  tf.Tensor(9.895818e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1021 is 0.0821 sec\n",
      "train AE loss : 8.418697357177734, train ANN loss : 2.271784782409668\n",
      "AE loss : 8.275053024291992, ANN loss : 1.9421409368515015, Total loss : 829.4474487304688\n",
      "learning rate A :  tf.Tensor(9.8956094e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1022 is 0.0792 sec\n",
      "train AE loss : 8.115232467651367, train ANN loss : 2.2621898651123047\n",
      "AE loss : 8.501138687133789, ANN loss : 1.946081280708313, Total loss : 852.0599975585938\n",
      "learning rate A :  tf.Tensor(9.8956094e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1023 is 0.0894 sec\n",
      "train AE loss : 8.33665657043457, train ANN loss : 2.2730712890625\n",
      "AE loss : 8.19471549987793, ANN loss : 1.9445464611053467, Total loss : 821.4161376953125\n",
      "learning rate A :  tf.Tensor(9.8954006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1024 is 0.0793 sec\n",
      "train AE loss : 8.037985801696777, train ANN loss : 2.2752790451049805\n",
      "AE loss : 7.906987190246582, ANN loss : 1.9433571100234985, Total loss : 792.6420288085938\n",
      "learning rate A :  tf.Tensor(9.8951925e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1025 is 0.0783 sec\n",
      "train AE loss : 7.757484436035156, train ANN loss : 2.269817352294922\n",
      "AE loss : 8.153237342834473, ANN loss : 1.9484072923660278, Total loss : 817.2721557617188\n",
      "learning rate A :  tf.Tensor(9.8951925e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1026 is 0.0822 sec\n",
      "train AE loss : 7.9989447593688965, train ANN loss : 2.26572847366333\n",
      "AE loss : 8.379825592041016, ANN loss : 1.9500887393951416, Total loss : 839.9325561523438\n",
      "learning rate A :  tf.Tensor(9.8951925e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1027 is 0.0810 sec\n",
      "train AE loss : 8.221086502075195, train ANN loss : 2.2718141078948975\n",
      "AE loss : 8.079439163208008, ANN loss : 1.9478263854980469, Total loss : 809.8917236328125\n",
      "learning rate A :  tf.Tensor(9.894984e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1028 is 0.0789 sec\n",
      "train AE loss : 7.928075313568115, train ANN loss : 2.2761623859405518\n",
      "AE loss : 7.79713773727417, ANN loss : 1.945879578590393, Total loss : 781.6596069335938\n",
      "learning rate A :  tf.Tensor(9.894775e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1029 is 0.0797 sec\n",
      "train AE loss : 7.652750492095947, train ANN loss : 2.2657864093780518\n",
      "AE loss : 7.531655788421631, ANN loss : 1.944248080253601, Total loss : 755.10986328125\n",
      "learning rate A :  tf.Tensor(9.894567e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1030 is 0.0784 sec\n",
      "train AE loss : 7.393774509429932, train ANN loss : 2.268402576446533\n",
      "AE loss : 7.745049476623535, ANN loss : 1.941763162612915, Total loss : 776.4467163085938\n",
      "learning rate A :  tf.Tensor(9.894567e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1031 is 0.0805 sec\n",
      "train AE loss : 7.603138446807861, train ANN loss : 2.2676315307617188\n",
      "AE loss : 7.920129776000977, ANN loss : 1.9383379220962524, Total loss : 793.9513549804688\n",
      "learning rate A :  tf.Tensor(9.894567e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1032 is 0.0819 sec\n",
      "train AE loss : 7.774799346923828, train ANN loss : 2.2656188011169434\n",
      "AE loss : 7.6441330909729, ANN loss : 1.9359217882156372, Total loss : 766.3492431640625\n",
      "learning rate A :  tf.Tensor(9.894358e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1033 is 0.0794 sec\n",
      "train AE loss : 7.505509853363037, train ANN loss : 2.262807607650757\n",
      "AE loss : 7.384435176849365, ANN loss : 1.9338397979736328, Total loss : 740.3773803710938\n",
      "learning rate A :  tf.Tensor(9.89415e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1034 is 0.0805 sec\n",
      "train AE loss : 7.252131462097168, train ANN loss : 2.2565815448760986\n",
      "AE loss : 7.519547462463379, ANN loss : 1.9324198961257935, Total loss : 753.8871459960938\n",
      "learning rate A :  tf.Tensor(9.89415e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1035 is 0.0808 sec\n",
      "train AE loss : 7.384453296661377, train ANN loss : 2.257519483566284\n",
      "AE loss : 7.634189605712891, ANN loss : 1.9308462142944336, Total loss : 765.3497924804688\n",
      "learning rate A :  tf.Tensor(9.89415e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1036 is 0.0794 sec\n",
      "train AE loss : 7.496345043182373, train ANN loss : 2.259202718734741\n",
      "AE loss : 7.75465726852417, ANN loss : 1.9288445711135864, Total loss : 777.3945922851562\n",
      "learning rate A :  tf.Tensor(9.89415e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1037 is 0.0808 sec\n",
      "train AE loss : 7.613720893859863, train ANN loss : 2.2733798027038574\n",
      "AE loss : 7.887454986572266, ANN loss : 1.9286267757415771, Total loss : 790.6741333007812\n",
      "learning rate A :  tf.Tensor(9.89415e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1038 is 0.0821 sec\n",
      "train AE loss : 7.743714332580566, train ANN loss : 2.273206949234009\n",
      "AE loss : 7.610246658325195, ANN loss : 1.9270814657211304, Total loss : 762.9517211914062\n",
      "learning rate A :  tf.Tensor(9.893941e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1039 is 0.0790 sec\n",
      "train AE loss : 7.473344326019287, train ANN loss : 2.2716071605682373\n",
      "AE loss : 7.349592685699463, ANN loss : 1.925835371017456, Total loss : 736.8851318359375\n",
      "learning rate A :  tf.Tensor(9.893733e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1040 is 0.0783 sec\n",
      "train AE loss : 7.21906042098999, train ANN loss : 2.266860008239746\n",
      "AE loss : 7.104149341583252, ANN loss : 1.9248632192611694, Total loss : 712.3397827148438\n",
      "learning rate A :  tf.Tensor(9.893524e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1041 is 0.0787 sec\n",
      "train AE loss : 6.979587554931641, train ANN loss : 2.2585718631744385\n",
      "AE loss : 6.872625827789307, ANN loss : 1.9241398572921753, Total loss : 689.1867065429688\n",
      "learning rate A :  tf.Tensor(9.893316e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1042 is 0.0777 sec\n",
      "train AE loss : 6.753697872161865, train ANN loss : 2.2690634727478027\n",
      "AE loss : 6.653796672821045, ANN loss : 1.9236369132995605, Total loss : 667.3032836914062\n",
      "learning rate A :  tf.Tensor(9.893107e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1043 is 0.0777 sec\n",
      "train AE loss : 6.540220260620117, train ANN loss : 2.258728265762329\n",
      "AE loss : 6.8776116371154785, ANN loss : 1.926243543624878, Total loss : 689.6875\n",
      "learning rate A :  tf.Tensor(9.893107e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1044 is 0.0815 sec\n",
      "train AE loss : 6.760221481323242, train ANN loss : 2.249013900756836\n",
      "AE loss : 6.658074378967285, ANN loss : 1.9253473281860352, Total loss : 667.7328491210938\n",
      "learning rate A :  tf.Tensor(9.892899e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1045 is 0.0772 sec\n",
      "train AE loss : 6.545957088470459, train ANN loss : 2.265212059020996\n",
      "AE loss : 6.450246810913086, ANN loss : 1.9246670007705688, Total loss : 646.9493408203125\n",
      "learning rate A :  tf.Tensor(9.89269e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1046 is 0.0784 sec\n",
      "train AE loss : 6.3431077003479, train ANN loss : 2.258267641067505\n",
      "AE loss : 6.25308084487915, ANN loss : 1.9241844415664673, Total loss : 627.2322998046875\n",
      "learning rate A :  tf.Tensor(9.892482e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1047 is 0.0788 sec\n",
      "train AE loss : 6.150618076324463, train ANN loss : 2.2722694873809814\n",
      "AE loss : 6.065940856933594, ANN loss : 1.9238733053207397, Total loss : 608.5179443359375\n",
      "learning rate A :  tf.Tensor(9.8922734e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1048 is 0.0789 sec\n",
      "train AE loss : 5.967906475067139, train ANN loss : 2.276484727859497\n",
      "AE loss : 5.888179302215576, ANN loss : 1.9237338304519653, Total loss : 590.74169921875\n",
      "learning rate A :  tf.Tensor(9.892065e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1049 is 0.0775 sec\n",
      "train AE loss : 5.794343948364258, train ANN loss : 2.2747952938079834\n",
      "AE loss : 5.7191243171691895, ANN loss : 1.923734426498413, Total loss : 573.8361206054688\n",
      "learning rate A :  tf.Tensor(9.8918565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1050 is 0.0776 sec\n",
      "train AE loss : 5.629311561584473, train ANN loss : 2.2600600719451904\n",
      "AE loss : 6.008935451507568, ANN loss : 1.9314439296722412, Total loss : 602.8250122070312\n",
      "learning rate A :  tf.Tensor(9.8918565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1051 is 0.0785 sec\n",
      "train AE loss : 5.914872169494629, train ANN loss : 2.264451265335083\n",
      "AE loss : 6.313318252563477, ANN loss : 1.943864107131958, Total loss : 633.2756958007812\n",
      "learning rate A :  tf.Tensor(9.8918565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1052 is 0.0787 sec\n",
      "train AE loss : 6.215104579925537, train ANN loss : 2.2582509517669678\n",
      "AE loss : 6.121878623962402, ANN loss : 1.9416534900665283, Total loss : 614.1295166015625\n",
      "learning rate A :  tf.Tensor(9.8916484e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1053 is 0.0781 sec\n",
      "train AE loss : 6.027933120727539, train ANN loss : 2.2651519775390625\n",
      "AE loss : 6.359966278076172, ANN loss : 1.9482883214950562, Total loss : 637.9449462890625\n",
      "learning rate A :  tf.Tensor(9.8916484e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1054 is 0.0788 sec\n",
      "train AE loss : 6.262224197387695, train ANN loss : 2.282111644744873\n",
      "AE loss : 6.165121555328369, ANN loss : 1.9454457759857178, Total loss : 618.4576416015625\n",
      "learning rate A :  tf.Tensor(9.89144e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1055 is 0.0774 sec\n",
      "train AE loss : 6.071685314178467, train ANN loss : 2.265394926071167\n",
      "AE loss : 5.980344295501709, ANN loss : 1.94285249710083, Total loss : 599.977294921875\n",
      "learning rate A :  tf.Tensor(9.8912315e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1056 is 0.0783 sec\n",
      "train AE loss : 5.890914440155029, train ANN loss : 2.265237808227539\n",
      "AE loss : 5.80485200881958, ANN loss : 1.9405120611190796, Total loss : 582.4257202148438\n",
      "learning rate A :  tf.Tensor(9.891023e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1057 is 0.0778 sec\n",
      "train AE loss : 5.719274520874023, train ANN loss : 2.2507917881011963\n",
      "AE loss : 5.958749771118164, ANN loss : 1.9378015995025635, Total loss : 597.8128051757812\n",
      "learning rate A :  tf.Tensor(9.891023e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1058 is 0.0784 sec\n",
      "train AE loss : 5.869672775268555, train ANN loss : 2.2656800746917725\n",
      "AE loss : 5.783329010009766, ANN loss : 1.9353296756744385, Total loss : 580.2681884765625\n",
      "learning rate A :  tf.Tensor(9.8908145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1059 is 0.0781 sec\n",
      "train AE loss : 5.698110103607178, train ANN loss : 2.240196466445923\n",
      "AE loss : 5.616709232330322, ANN loss : 1.9331157207489014, Total loss : 563.60400390625\n",
      "learning rate A :  tf.Tensor(9.8906065e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1060 is 0.0793 sec\n",
      "train AE loss : 5.53515625, train ANN loss : 2.2549731731414795\n",
      "AE loss : 5.704548358917236, ANN loss : 1.9286319017410278, Total loss : 572.3834838867188\n",
      "learning rate A :  tf.Tensor(9.8906065e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1061 is 0.0820 sec\n",
      "train AE loss : 5.619855880737305, train ANN loss : 2.264021873474121\n",
      "AE loss : 5.540708541870117, ANN loss : 1.9266998767852783, Total loss : 555.99755859375\n",
      "learning rate A :  tf.Tensor(9.8903976e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1062 is 0.0788 sec\n",
      "train AE loss : 5.45976448059082, train ANN loss : 2.2437334060668945\n",
      "AE loss : 5.384710311889648, ANN loss : 1.9249924421310425, Total loss : 540.39599609375\n",
      "learning rate A :  tf.Tensor(9.8901895e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1063 is 0.0775 sec\n",
      "train AE loss : 5.307435989379883, train ANN loss : 2.2514591217041016\n",
      "AE loss : 5.460999965667725, ANN loss : 1.9187626838684082, Total loss : 548.0187377929688\n",
      "learning rate A :  tf.Tensor(9.8901895e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1064 is 0.0795 sec\n",
      "train AE loss : 5.381046772003174, train ANN loss : 2.256808280944824\n",
      "AE loss : 5.527963161468506, ANN loss : 1.9095168113708496, Total loss : 554.7058715820312\n",
      "learning rate A :  tf.Tensor(9.8901895e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1065 is 0.0826 sec\n",
      "train AE loss : 5.446193695068359, train ANN loss : 2.250330686569214\n",
      "AE loss : 5.370964050292969, ANN loss : 1.9083033800125122, Total loss : 539.0047607421875\n",
      "learning rate A :  tf.Tensor(9.889981e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1066 is 0.0986 sec\n",
      "train AE loss : 5.2930803298950195, train ANN loss : 2.254668951034546\n",
      "AE loss : 5.45735502243042, ANN loss : 1.9076814651489258, Total loss : 547.6431274414062\n",
      "learning rate A :  tf.Tensor(9.889981e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1067 is 0.0975 sec\n",
      "train AE loss : 5.377944469451904, train ANN loss : 2.2418389320373535\n",
      "AE loss : 5.303194046020508, ANN loss : 1.9066332578659058, Total loss : 532.2260131835938\n",
      "learning rate A :  tf.Tensor(9.8897726e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1068 is 0.0785 sec\n",
      "train AE loss : 5.22759485244751, train ANN loss : 2.245776891708374\n",
      "AE loss : 5.4191083908081055, ANN loss : 1.9082053899765015, Total loss : 543.819091796875\n",
      "learning rate A :  tf.Tensor(9.8897726e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1069 is 0.0818 sec\n",
      "train AE loss : 5.34205436706543, train ANN loss : 2.248718500137329\n",
      "AE loss : 5.266404628753662, ANN loss : 1.9071177244186401, Total loss : 528.5475463867188\n",
      "learning rate A :  tf.Tensor(9.8895645e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1070 is 0.0794 sec\n",
      "train AE loss : 5.193063259124756, train ANN loss : 2.2437326908111572\n",
      "AE loss : 5.121111869812012, ANN loss : 1.9061895608901978, Total loss : 514.0173950195312\n",
      "learning rate A :  tf.Tensor(9.889355e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1071 is 0.0791 sec\n",
      "train AE loss : 5.051271915435791, train ANN loss : 2.2424325942993164\n",
      "AE loss : 4.982766151428223, ANN loss : 1.9054173231124878, Total loss : 500.18206787109375\n",
      "learning rate A :  tf.Tensor(9.889146e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1072 is 0.0793 sec\n",
      "train AE loss : 4.916235446929932, train ANN loss : 2.2478256225585938\n",
      "AE loss : 5.143755912780762, ANN loss : 1.9142946004867554, Total loss : 516.2899169921875\n",
      "learning rate A :  tf.Tensor(9.889146e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1073 is 0.0810 sec\n",
      "train AE loss : 5.075351715087891, train ANN loss : 2.249772787094116\n",
      "AE loss : 5.32645845413208, ANN loss : 1.9254639148712158, Total loss : 534.5712890625\n",
      "learning rate A :  tf.Tensor(9.889146e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1074 is 0.0832 sec\n",
      "train AE loss : 5.255509853363037, train ANN loss : 2.2576334476470947\n",
      "AE loss : 5.177912712097168, ANN loss : 1.923760175704956, Total loss : 519.7149658203125\n",
      "learning rate A :  tf.Tensor(9.888938e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1075 is 0.0810 sec\n",
      "train AE loss : 5.110409259796143, train ANN loss : 2.2360029220581055\n",
      "AE loss : 5.337080001831055, ANN loss : 1.9271149635314941, Total loss : 535.6351318359375\n",
      "learning rate A :  tf.Tensor(9.888938e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1076 is 0.0819 sec\n",
      "train AE loss : 5.266943454742432, train ANN loss : 2.2427637577056885\n",
      "AE loss : 5.187750816345215, ANN loss : 1.9251664876937866, Total loss : 520.7002563476562\n",
      "learning rate A :  tf.Tensor(9.88873e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1077 is 0.0793 sec\n",
      "train AE loss : 5.121001720428467, train ANN loss : 2.2530882358551025\n",
      "AE loss : 5.309542179107666, ANN loss : 1.9223328828811646, Total loss : 532.8765869140625\n",
      "learning rate A :  tf.Tensor(9.88873e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1078 is 0.0816 sec\n",
      "train AE loss : 5.240302085876465, train ANN loss : 2.2368383407592773\n",
      "AE loss : 5.161075115203857, ANN loss : 1.9203541278839111, Total loss : 518.0278930664062\n",
      "learning rate A :  tf.Tensor(9.888522e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1079 is 0.0792 sec\n",
      "train AE loss : 5.0952348709106445, train ANN loss : 2.247019052505493\n",
      "AE loss : 5.254674434661865, ANN loss : 1.9114439487457275, Total loss : 527.3788452148438\n",
      "learning rate A :  tf.Tensor(9.888522e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1080 is 0.0795 sec\n",
      "train AE loss : 5.186378479003906, train ANN loss : 2.2378673553466797\n",
      "AE loss : 5.108372211456299, ANN loss : 1.9096159934997559, Total loss : 512.7468872070312\n",
      "learning rate A :  tf.Tensor(9.888313e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1081 is 0.0787 sec\n",
      "train AE loss : 5.043517589569092, train ANN loss : 2.237661838531494\n",
      "AE loss : 4.969010829925537, ANN loss : 1.9079887866973877, Total loss : 498.80908203125\n",
      "learning rate A :  tf.Tensor(9.888105e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1082 is 0.0789 sec\n",
      "train AE loss : 4.9074225425720215, train ANN loss : 2.2331507205963135\n",
      "AE loss : 4.83610200881958, ANN loss : 1.9065433740615845, Total loss : 485.5167236328125\n",
      "learning rate A :  tf.Tensor(9.887897e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1083 is 0.0799 sec\n",
      "train AE loss : 4.777591228485107, train ANN loss : 2.241849899291992\n",
      "AE loss : 4.709446430206299, ANN loss : 1.9052534103393555, Total loss : 472.8498840332031\n",
      "learning rate A :  tf.Tensor(9.887689e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1084 is 0.0799 sec\n",
      "train AE loss : 4.653830528259277, train ANN loss : 2.229429006576538\n",
      "AE loss : 4.588638782501221, ANN loss : 1.904106855392456, Total loss : 460.76800537109375\n",
      "learning rate A :  tf.Tensor(9.88748e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1085 is 0.0779 sec\n",
      "train AE loss : 4.535801410675049, train ANN loss : 2.2425787448883057\n",
      "AE loss : 4.688875675201416, ANN loss : 1.9007447957992554, Total loss : 470.7882995605469\n",
      "learning rate A :  tf.Tensor(9.88748e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1086 is 0.0814 sec\n",
      "train AE loss : 4.633818626403809, train ANN loss : 2.2356152534484863\n",
      "AE loss : 4.805468559265137, ANN loss : 1.8988184928894043, Total loss : 482.4456481933594\n",
      "learning rate A :  tf.Tensor(9.88748e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1087 is 0.0834 sec\n",
      "train AE loss : 4.747947692871094, train ANN loss : 2.258760452270508\n",
      "AE loss : 4.922649383544922, ANN loss : 1.8983442783355713, Total loss : 494.1632995605469\n",
      "learning rate A :  tf.Tensor(9.88748e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1088 is 0.0806 sec\n",
      "train AE loss : 4.862629413604736, train ANN loss : 2.251967191696167\n",
      "AE loss : 5.03415060043335, ANN loss : 1.8974261283874512, Total loss : 505.3125\n",
      "learning rate A :  tf.Tensor(9.88748e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1089 is 0.0820 sec\n",
      "train AE loss : 4.9718241691589355, train ANN loss : 2.238826274871826\n",
      "AE loss : 5.143124580383301, ANN loss : 1.8963109254837036, Total loss : 516.208740234375\n",
      "learning rate A :  tf.Tensor(9.88748e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1090 is 0.0827 sec\n",
      "train AE loss : 5.078345775604248, train ANN loss : 2.2432539463043213\n",
      "AE loss : 5.243430137634277, ANN loss : 1.898209810256958, Total loss : 526.2412109375\n",
      "learning rate A :  tf.Tensor(9.88748e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1091 is 0.0828 sec\n",
      "train AE loss : 5.176388263702393, train ANN loss : 2.226168632507324\n",
      "AE loss : 5.0948028564453125, ANN loss : 1.8965154886245728, Total loss : 511.3768005371094\n",
      "learning rate A :  tf.Tensor(9.887271e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1092 is 0.0952 sec\n",
      "train AE loss : 5.031327247619629, train ANN loss : 2.227086305618286\n",
      "AE loss : 4.953516483306885, ANN loss : 1.8950122594833374, Total loss : 497.24664306640625\n",
      "learning rate A :  tf.Tensor(9.887063e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1093 is 0.0853 sec\n",
      "train AE loss : 4.893399238586426, train ANN loss : 2.235058546066284\n",
      "AE loss : 5.053709983825684, ANN loss : 1.8973267078399658, Total loss : 507.26837158203125\n",
      "learning rate A :  tf.Tensor(9.887063e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1094 is 0.0872 sec\n",
      "train AE loss : 4.99153470993042, train ANN loss : 2.2344796657562256\n",
      "AE loss : 5.165165424346924, ANN loss : 1.897810935974121, Total loss : 518.4143676757812\n",
      "learning rate A :  tf.Tensor(9.887063e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1095 is 0.0770 sec\n",
      "train AE loss : 5.100809097290039, train ANN loss : 2.2359392642974854\n",
      "AE loss : 5.27435302734375, ANN loss : 1.8973913192749023, Total loss : 529.3327026367188\n",
      "learning rate A :  tf.Tensor(9.887063e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1096 is 0.0886 sec\n",
      "train AE loss : 5.20790958404541, train ANN loss : 2.23746657371521\n",
      "AE loss : 5.122555732727051, ANN loss : 1.8955661058425903, Total loss : 514.151123046875\n",
      "learning rate A :  tf.Tensor(9.886855e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1097 is 0.0762 sec\n",
      "train AE loss : 5.059780120849609, train ANN loss : 2.2368295192718506\n",
      "AE loss : 4.978336811065674, ANN loss : 1.893952488899231, Total loss : 499.7276306152344\n",
      "learning rate A :  tf.Tensor(9.886647e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1098 is 0.0738 sec\n",
      "train AE loss : 4.9190168380737305, train ANN loss : 2.2259533405303955\n",
      "AE loss : 5.0879950523376465, ANN loss : 1.8913888931274414, Total loss : 510.69091796875\n",
      "learning rate A :  tf.Tensor(9.886647e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1099 is 0.0759 sec\n",
      "train AE loss : 5.026546001434326, train ANN loss : 2.23860764503479\n",
      "AE loss : 4.944847106933594, ANN loss : 1.8897368907928467, Total loss : 496.37445068359375\n",
      "learning rate A :  tf.Tensor(9.886438e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1100 is 0.0755 sec\n",
      "train AE loss : 4.886838436126709, train ANN loss : 2.238840103149414\n",
      "AE loss : 5.083550930023193, ANN loss : 1.8889646530151367, Total loss : 510.2440490722656\n",
      "learning rate A :  tf.Tensor(9.886438e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1101 is 0.0851 sec\n",
      "train AE loss : 5.022578239440918, train ANN loss : 2.218231201171875\n",
      "AE loss : 5.209908485412598, ANN loss : 1.8869671821594238, Total loss : 522.8778076171875\n",
      "learning rate A :  tf.Tensor(9.886438e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1102 is 0.0758 sec\n",
      "train AE loss : 5.146172523498535, train ANN loss : 2.2263400554656982\n",
      "AE loss : 5.306920051574707, ANN loss : 1.8831268548965454, Total loss : 532.5751342773438\n",
      "learning rate A :  tf.Tensor(9.886438e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1103 is 0.0766 sec\n",
      "train AE loss : 5.240893840789795, train ANN loss : 2.230576276779175\n",
      "AE loss : 5.1519856452941895, ANN loss : 1.8809890747070312, Total loss : 517.07958984375\n",
      "learning rate A :  tf.Tensor(9.88623e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1104 is 0.0740 sec\n",
      "train AE loss : 5.089694023132324, train ANN loss : 2.2348921298980713\n",
      "AE loss : 5.004885196685791, ANN loss : 1.879090666770935, Total loss : 502.3675842285156\n",
      "learning rate A :  tf.Tensor(9.886021e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1105 is 0.0745 sec\n",
      "train AE loss : 4.946125030517578, train ANN loss : 2.2345659732818604\n",
      "AE loss : 4.865104675292969, ANN loss : 1.8774222135543823, Total loss : 488.3879089355469\n",
      "learning rate A :  tf.Tensor(9.885813e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1106 is 0.0745 sec\n",
      "train AE loss : 4.80966854095459, train ANN loss : 2.2243757247924805\n",
      "AE loss : 4.732203960418701, ANN loss : 1.8759446144104004, Total loss : 475.0963439941406\n",
      "learning rate A :  tf.Tensor(9.885606e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1107 is 0.0742 sec\n",
      "train AE loss : 4.679922580718994, train ANN loss : 2.2300615310668945\n",
      "AE loss : 4.605740070343018, ANN loss : 1.8746337890625, Total loss : 462.4486389160156\n",
      "learning rate A :  tf.Tensor(9.885397e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1108 is 0.0737 sec\n",
      "train AE loss : 4.556474685668945, train ANN loss : 2.2300796508789062\n",
      "AE loss : 4.485330581665039, ANN loss : 1.8734798431396484, Total loss : 450.40655517578125\n",
      "learning rate A :  tf.Tensor(9.885189e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1109 is 0.0748 sec\n",
      "train AE loss : 4.438919544219971, train ANN loss : 2.2226531505584717\n",
      "AE loss : 4.370655536651611, ANN loss : 1.8724616765975952, Total loss : 438.9380187988281\n",
      "learning rate A :  tf.Tensor(9.88498e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1110 is 0.0753 sec\n",
      "train AE loss : 4.326900959014893, train ANN loss : 2.22689151763916\n",
      "AE loss : 4.261324882507324, ANN loss : 1.8715732097625732, Total loss : 428.0040588378906\n",
      "learning rate A :  tf.Tensor(9.884772e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1111 is 0.0746 sec\n",
      "train AE loss : 4.220065593719482, train ANN loss : 2.2194807529449463\n",
      "AE loss : 4.15700626373291, ANN loss : 1.8708029985427856, Total loss : 417.5714416503906\n",
      "learning rate A :  tf.Tensor(9.884564e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1112 is 0.0746 sec\n",
      "train AE loss : 4.11813497543335, train ANN loss : 2.2361831665039062\n",
      "AE loss : 4.057401657104492, ANN loss : 1.8701461553573608, Total loss : 407.6103210449219\n",
      "learning rate A :  tf.Tensor(9.884356e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1113 is 0.0738 sec\n",
      "train AE loss : 4.020797252655029, train ANN loss : 2.245891809463501\n",
      "AE loss : 4.185904502868652, ANN loss : 1.875608205795288, Total loss : 420.4660949707031\n",
      "learning rate A :  tf.Tensor(9.884356e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1114 is 0.0767 sec\n",
      "train AE loss : 4.148090839385986, train ANN loss : 2.224090337753296\n",
      "AE loss : 4.084738731384277, ANN loss : 1.8746346235275269, Total loss : 410.3485107421875\n",
      "learning rate A :  tf.Tensor(9.884147e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1115 is 0.0763 sec\n",
      "train AE loss : 4.049177169799805, train ANN loss : 2.227029800415039\n",
      "AE loss : 3.9881064891815186, ANN loss : 1.873782753944397, Total loss : 400.6844177246094\n",
      "learning rate A :  tf.Tensor(9.883939e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1116 is 0.0759 sec\n",
      "train AE loss : 3.9546945095062256, train ANN loss : 2.225450277328491\n",
      "AE loss : 3.895742893218994, ANN loss : 1.8730372190475464, Total loss : 391.44732666015625\n",
      "learning rate A :  tf.Tensor(9.883731e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1117 is 0.0749 sec\n",
      "train AE loss : 3.8643882274627686, train ANN loss : 2.2395131587982178\n",
      "AE loss : 4.069818496704102, ANN loss : 1.8858397006988525, Total loss : 408.8676452636719\n",
      "learning rate A :  tf.Tensor(9.883731e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1118 is 0.0761 sec\n",
      "train AE loss : 4.037353038787842, train ANN loss : 2.2338247299194336\n",
      "AE loss : 3.9734890460968018, ANN loss : 1.8844166994094849, Total loss : 399.23333740234375\n",
      "learning rate A :  tf.Tensor(9.883522e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1119 is 0.0743 sec\n",
      "train AE loss : 3.943112373352051, train ANN loss : 2.2281336784362793\n",
      "AE loss : 4.149840831756592, ANN loss : 1.9012857675552368, Total loss : 416.8853454589844\n",
      "learning rate A :  tf.Tensor(9.883522e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1120 is 0.0757 sec\n",
      "train AE loss : 4.1184515953063965, train ANN loss : 2.2346384525299072\n",
      "AE loss : 4.049546718597412, ANN loss : 1.8991485834121704, Total loss : 406.85382080078125\n",
      "learning rate A :  tf.Tensor(9.883314e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1121 is 0.0753 sec\n",
      "train AE loss : 4.020290374755859, train ANN loss : 2.2199783325195312\n",
      "AE loss : 3.9537277221679688, ANN loss : 1.8971785306930542, Total loss : 397.26995849609375\n",
      "learning rate A :  tf.Tensor(9.8831064e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1122 is 0.0734 sec\n",
      "train AE loss : 3.9265100955963135, train ANN loss : 2.2343368530273438\n",
      "AE loss : 4.093143939971924, ANN loss : 1.9049737453460693, Total loss : 411.2193603515625\n",
      "learning rate A :  tf.Tensor(9.8831064e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1123 is 0.0753 sec\n",
      "train AE loss : 4.064572811126709, train ANN loss : 2.2210428714752197\n",
      "AE loss : 3.994966506958008, ANN loss : 1.902625322341919, Total loss : 401.3992919921875\n",
      "learning rate A :  tf.Tensor(9.8828976e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1124 is 0.0747 sec\n",
      "train AE loss : 3.968435525894165, train ANN loss : 2.224165201187134\n",
      "AE loss : 3.9011459350585938, ANN loss : 1.9004592895507812, Total loss : 392.0150451660156\n",
      "learning rate A :  tf.Tensor(9.8826895e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1125 is 0.0739 sec\n",
      "train AE loss : 3.8765671253204346, train ANN loss : 2.213296890258789\n",
      "AE loss : 3.811436891555786, ANN loss : 1.898449420928955, Total loss : 383.0421142578125\n",
      "learning rate A :  tf.Tensor(9.882481e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1126 is 0.0739 sec\n",
      "train AE loss : 3.7887163162231445, train ANN loss : 2.2219667434692383\n",
      "AE loss : 3.7255125045776367, ANN loss : 1.8965883255004883, Total loss : 374.44781494140625\n",
      "learning rate A :  tf.Tensor(9.8822726e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1127 is 0.0762 sec\n",
      "train AE loss : 3.704554557800293, train ANN loss : 2.2171366214752197\n",
      "AE loss : 3.838796377182007, ANN loss : 1.897231101989746, Total loss : 385.77685546875\n",
      "learning rate A :  tf.Tensor(9.8822726e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1128 is 0.0766 sec\n",
      "train AE loss : 3.8162736892700195, train ANN loss : 2.227821111679077\n",
      "AE loss : 3.751248836517334, ANN loss : 1.895268201828003, Total loss : 377.0201416015625\n",
      "learning rate A :  tf.Tensor(9.8820645e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1129 is 0.0749 sec\n",
      "train AE loss : 3.7305145263671875, train ANN loss : 2.2304067611694336\n",
      "AE loss : 3.840679407119751, ANN loss : 1.892930030822754, Total loss : 385.96087646484375\n",
      "learning rate A :  tf.Tensor(9.8820645e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1130 is 0.0776 sec\n",
      "train AE loss : 3.818178653717041, train ANN loss : 2.208364963531494\n",
      "AE loss : 3.7526724338531494, ANN loss : 1.8910983800888062, Total loss : 377.1583251953125\n",
      "learning rate A :  tf.Tensor(9.8818564e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1131 is 0.0755 sec\n",
      "train AE loss : 3.731982707977295, train ANN loss : 2.209867238998413\n",
      "AE loss : 3.6684391498565674, ANN loss : 1.8893988132476807, Total loss : 368.7333068847656\n",
      "learning rate A :  tf.Tensor(9.881648e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1132 is 0.0756 sec\n",
      "train AE loss : 3.649467706680298, train ANN loss : 2.2132534980773926\n",
      "AE loss : 3.5876755714416504, ANN loss : 1.8878203630447388, Total loss : 360.6553649902344\n",
      "learning rate A :  tf.Tensor(9.88144e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1133 is 0.0772 sec\n",
      "train AE loss : 3.5703463554382324, train ANN loss : 2.226628541946411\n",
      "AE loss : 3.655243396759033, ANN loss : 1.8809491395950317, Total loss : 367.4053039550781\n",
      "learning rate A :  tf.Tensor(9.88144e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1134 is 0.0819 sec\n",
      "train AE loss : 3.636413097381592, train ANN loss : 2.226571559906006\n",
      "AE loss : 3.717888593673706, ANN loss : 1.8751606941223145, Total loss : 373.6640319824219\n",
      "learning rate A :  tf.Tensor(9.88144e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1135 is 0.0792 sec\n",
      "train AE loss : 3.69769549369812, train ANN loss : 2.2153029441833496\n",
      "AE loss : 3.7887682914733887, ANN loss : 1.8695690631866455, Total loss : 380.74639892578125\n",
      "learning rate A :  tf.Tensor(9.88144e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1136 is 0.0791 sec\n",
      "train AE loss : 3.767460584640503, train ANN loss : 2.2121994495391846\n",
      "AE loss : 3.7016091346740723, ANN loss : 1.8682806491851807, Total loss : 372.0292053222656\n",
      "learning rate A :  tf.Tensor(9.8812314e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1137 is 0.0761 sec\n",
      "train AE loss : 3.682176351547241, train ANN loss : 2.234121799468994\n",
      "AE loss : 3.6182570457458496, ANN loss : 1.8671211004257202, Total loss : 363.69287109375\n",
      "learning rate A :  tf.Tensor(9.881023e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1138 is 0.0856 sec\n",
      "train AE loss : 3.600599527359009, train ANN loss : 2.2124879360198975\n",
      "AE loss : 3.5385048389434814, ANN loss : 1.8660714626312256, Total loss : 355.716552734375\n",
      "learning rate A :  tf.Tensor(9.880815e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1139 is 0.0761 sec\n",
      "train AE loss : 3.5225350856781006, train ANN loss : 2.221958875656128\n",
      "AE loss : 3.633904457092285, ANN loss : 1.8636361360549927, Total loss : 365.2540588378906\n",
      "learning rate A :  tf.Tensor(9.880815e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1140 is 0.0770 sec\n",
      "train AE loss : 3.6165401935577393, train ANN loss : 2.2135329246520996\n",
      "AE loss : 3.7504725456237793, ANN loss : 1.865523099899292, Total loss : 376.91278076171875\n",
      "learning rate A :  tf.Tensor(9.880815e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1141 is 0.0771 sec\n",
      "train AE loss : 3.7309563159942627, train ANN loss : 2.2126176357269287\n",
      "AE loss : 3.664581298828125, ANN loss : 1.8640309572219849, Total loss : 368.3221740722656\n",
      "learning rate A :  tf.Tensor(9.880608e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1142 is 0.0763 sec\n",
      "train AE loss : 3.6469075679779053, train ANN loss : 2.236298084259033\n",
      "AE loss : 3.787972927093506, ANN loss : 1.8671702146530151, Total loss : 380.6644592285156\n",
      "learning rate A :  tf.Tensor(9.880608e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1143 is 0.0772 sec\n",
      "train AE loss : 3.767965316772461, train ANN loss : 2.2060606479644775\n",
      "AE loss : 3.8885021209716797, ANN loss : 1.865521788597107, Total loss : 390.71575927734375\n",
      "learning rate A :  tf.Tensor(9.880608e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1144 is 0.0769 sec\n",
      "train AE loss : 3.8665964603424072, train ANN loss : 2.2109479904174805\n",
      "AE loss : 3.9522783756256104, ANN loss : 1.8632400035858154, Total loss : 397.0910949707031\n",
      "learning rate A :  tf.Tensor(9.880608e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1145 is 0.0783 sec\n",
      "train AE loss : 3.9289350509643555, train ANN loss : 2.2069549560546875\n",
      "AE loss : 3.9828336238861084, ANN loss : 1.859336495399475, Total loss : 400.1426696777344\n",
      "learning rate A :  tf.Tensor(9.880608e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1146 is 0.0779 sec\n",
      "train AE loss : 3.9586055278778076, train ANN loss : 2.2125935554504395\n",
      "AE loss : 4.012444496154785, ANN loss : 1.8549178838729858, Total loss : 403.099365234375\n",
      "learning rate A :  tf.Tensor(9.880608e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1147 is 0.0771 sec\n",
      "train AE loss : 3.987133026123047, train ANN loss : 2.202942132949829\n",
      "AE loss : 4.060142993927002, ANN loss : 1.855194330215454, Total loss : 407.8694763183594\n",
      "learning rate A :  tf.Tensor(9.880608e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1148 is 0.0776 sec\n",
      "train AE loss : 4.033573627471924, train ANN loss : 2.2045629024505615\n",
      "AE loss : 4.121256351470947, ANN loss : 1.8589825630187988, Total loss : 413.984619140625\n",
      "learning rate A :  tf.Tensor(9.880608e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1149 is 0.0858 sec\n",
      "train AE loss : 4.09345817565918, train ANN loss : 2.2087221145629883\n",
      "AE loss : 4.1984992027282715, ANN loss : 1.863385796546936, Total loss : 421.7132873535156\n",
      "learning rate A :  tf.Tensor(9.880608e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1150 is 0.0770 sec\n",
      "train AE loss : 4.16937255859375, train ANN loss : 2.201934337615967\n",
      "AE loss : 4.091177463531494, ANN loss : 1.8617362976074219, Total loss : 410.9794616699219\n",
      "learning rate A :  tf.Tensor(9.880399e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1151 is 0.0752 sec\n",
      "train AE loss : 4.064422607421875, train ANN loss : 2.204564332962036\n",
      "AE loss : 4.170215606689453, ANN loss : 1.8609555959701538, Total loss : 418.88250732421875\n",
      "learning rate A :  tf.Tensor(9.880399e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1152 is 0.0771 sec\n",
      "train AE loss : 4.142433166503906, train ANN loss : 2.1998589038848877\n",
      "AE loss : 4.063898086547852, ANN loss : 1.8593060970306396, Total loss : 408.2491149902344\n",
      "learning rate A :  tf.Tensor(9.880191e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1153 is 0.0756 sec\n",
      "train AE loss : 4.038447856903076, train ANN loss : 2.2013094425201416\n",
      "AE loss : 4.152639865875244, ANN loss : 1.8594406843185425, Total loss : 417.1234130859375\n",
      "learning rate A :  tf.Tensor(9.880191e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1154 is 0.0781 sec\n",
      "train AE loss : 4.12598180770874, train ANN loss : 2.2092883586883545\n",
      "AE loss : 4.046607494354248, ANN loss : 1.8576780557632446, Total loss : 406.5184326171875\n",
      "learning rate A :  tf.Tensor(9.879983e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1155 is 0.1773 sec\n",
      "train AE loss : 4.022258758544922, train ANN loss : 2.213482618331909\n",
      "AE loss : 3.945596933364868, ANN loss : 1.856091022491455, Total loss : 396.415771484375\n",
      "learning rate A :  tf.Tensor(9.879775e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1156 is 0.0753 sec\n",
      "train AE loss : 3.923436403274536, train ANN loss : 2.193657159805298\n",
      "AE loss : 4.046011924743652, ANN loss : 1.8625280857086182, Total loss : 406.4637145996094\n",
      "learning rate A :  tf.Tensor(9.879775e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1157 is 0.0764 sec\n",
      "train AE loss : 4.022458076477051, train ANN loss : 2.206226348876953\n",
      "AE loss : 4.13623046875, ANN loss : 1.863916277885437, Total loss : 415.4869689941406\n",
      "learning rate A :  tf.Tensor(9.879775e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1158 is 0.0781 sec\n",
      "train AE loss : 4.111366271972656, train ANN loss : 2.202554702758789\n",
      "AE loss : 4.212774276733398, ANN loss : 1.8578085899353027, Total loss : 423.13525390625\n",
      "learning rate A :  tf.Tensor(9.879775e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1159 is 0.0766 sec\n",
      "train AE loss : 4.186705112457275, train ANN loss : 2.213300943374634\n",
      "AE loss : 4.102589130401611, ANN loss : 1.855588674545288, Total loss : 412.1145324707031\n",
      "learning rate A :  tf.Tensor(9.879566e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1160 is 0.0761 sec\n",
      "train AE loss : 4.078910827636719, train ANN loss : 2.2078466415405273\n",
      "AE loss : 4.173897743225098, ANN loss : 1.8498830795288086, Total loss : 419.2396545410156\n",
      "learning rate A :  tf.Tensor(9.879566e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1161 is 0.0778 sec\n",
      "train AE loss : 4.148936748504639, train ANN loss : 2.2037477493286133\n",
      "AE loss : 4.228846549987793, ANN loss : 1.8468097448349, Total loss : 424.7314758300781\n",
      "learning rate A :  tf.Tensor(9.879566e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1162 is 0.0753 sec\n",
      "train AE loss : 4.202764511108398, train ANN loss : 2.2252771854400635\n",
      "AE loss : 4.117183685302734, ANN loss : 1.8447694778442383, Total loss : 413.56317138671875\n",
      "learning rate A :  tf.Tensor(9.879358e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1163 is 0.0727 sec\n",
      "train AE loss : 4.0935282707214355, train ANN loss : 2.196667194366455\n",
      "AE loss : 4.167919635772705, ANN loss : 1.8422253131866455, Total loss : 418.6341857910156\n",
      "learning rate A :  tf.Tensor(9.879358e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1164 is 0.0770 sec\n",
      "train AE loss : 4.143608570098877, train ANN loss : 2.1930062770843506\n",
      "AE loss : 4.223625659942627, ANN loss : 1.8391919136047363, Total loss : 424.2017822265625\n",
      "learning rate A :  tf.Tensor(9.879358e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1165 is 0.0750 sec\n",
      "train AE loss : 4.198607444763184, train ANN loss : 2.2048680782318115\n",
      "AE loss : 4.11130952835083, ANN loss : 1.8373628854751587, Total loss : 412.96832275390625\n",
      "learning rate A :  tf.Tensor(9.8791505e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1166 is 0.0729 sec\n",
      "train AE loss : 4.088716506958008, train ANN loss : 2.196284532546997\n",
      "AE loss : 4.00450325012207, ANN loss : 1.8357332944869995, Total loss : 402.28607177734375\n",
      "learning rate A :  tf.Tensor(9.8789424e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1167 is 0.0743 sec\n",
      "train AE loss : 3.984196186065674, train ANN loss : 2.2007367610931396\n",
      "AE loss : 3.9028944969177246, ANN loss : 1.8342896699905396, Total loss : 392.12371826171875\n",
      "learning rate A :  tf.Tensor(9.8787335e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1168 is 0.0727 sec\n",
      "train AE loss : 3.8847556114196777, train ANN loss : 2.2052507400512695\n",
      "AE loss : 3.9916484355926514, ANN loss : 1.837243676185608, Total loss : 401.0021057128906\n",
      "learning rate A :  tf.Tensor(9.8787335e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1169 is 0.0768 sec\n",
      "train AE loss : 3.9722721576690674, train ANN loss : 2.1947712898254395\n",
      "AE loss : 3.8903002738952637, ANN loss : 1.8357077836990356, Total loss : 390.8657531738281\n",
      "learning rate A :  tf.Tensor(9.8785255e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1170 is 0.0768 sec\n",
      "train AE loss : 3.8730897903442383, train ANN loss : 2.207956314086914\n",
      "AE loss : 3.7936594486236572, ANN loss : 1.8343393802642822, Total loss : 381.2002868652344\n",
      "learning rate A :  tf.Tensor(9.8783166e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1171 is 0.0854 sec\n",
      "train AE loss : 3.7785093784332275, train ANN loss : 2.20356822013855\n",
      "AE loss : 3.7016260623931885, ANN loss : 1.8331273794174194, Total loss : 371.9957275390625\n",
      "learning rate A :  tf.Tensor(9.8781085e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1172 is 0.0844 sec\n",
      "train AE loss : 3.688422679901123, train ANN loss : 2.202054023742676\n",
      "AE loss : 3.823213577270508, ANN loss : 1.841172456741333, Total loss : 384.1625061035156\n",
      "learning rate A :  tf.Tensor(9.8781085e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1173 is 0.0811 sec\n",
      "train AE loss : 3.8084607124328613, train ANN loss : 2.18894100189209\n",
      "AE loss : 3.7295563220977783, ANN loss : 1.8395696878433228, Total loss : 374.7951965332031\n",
      "learning rate A :  tf.Tensor(9.8779004e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1174 is 0.0768 sec\n",
      "train AE loss : 3.716761350631714, train ANN loss : 2.1859474182128906\n",
      "AE loss : 3.858832359313965, ANN loss : 1.8507661819458008, Total loss : 387.7340087890625\n",
      "learning rate A :  tf.Tensor(9.8779004e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1175 is 0.0780 sec\n",
      "train AE loss : 3.8445611000061035, train ANN loss : 2.198972463607788\n",
      "AE loss : 3.9660027027130127, ANN loss : 1.8547004461288452, Total loss : 398.4549865722656\n",
      "learning rate A :  tf.Tensor(9.8779004e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1176 is 0.0754 sec\n",
      "train AE loss : 3.9504141807556152, train ANN loss : 2.205070734024048\n",
      "AE loss : 4.030871868133545, ANN loss : 1.8508710861206055, Total loss : 404.93804931640625\n",
      "learning rate A :  tf.Tensor(9.8779004e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1177 is 0.0760 sec\n",
      "train AE loss : 4.014116287231445, train ANN loss : 2.193002700805664\n",
      "AE loss : 3.9270823001861572, ANN loss : 1.848279595375061, Total loss : 394.5564880371094\n",
      "learning rate A :  tf.Tensor(9.877692e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1178 is 0.0760 sec\n",
      "train AE loss : 3.912505865097046, train ANN loss : 2.1922051906585693\n",
      "AE loss : 3.964966058731079, ANN loss : 1.8416882753372192, Total loss : 398.33831787109375\n",
      "learning rate A :  tf.Tensor(9.877692e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1179 is 0.0763 sec\n",
      "train AE loss : 3.948866128921509, train ANN loss : 2.2116987705230713\n",
      "AE loss : 3.9793126583099365, ANN loss : 1.8299829959869385, Total loss : 399.76123046875\n",
      "learning rate A :  tf.Tensor(9.877692e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1180 is 0.0755 sec\n",
      "train AE loss : 3.9615936279296875, train ANN loss : 2.1867618560791016\n",
      "AE loss : 3.877943277359009, ANN loss : 1.8282650709152222, Total loss : 389.62261962890625\n",
      "learning rate A :  tf.Tensor(9.877484e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1181 is 0.0751 sec\n",
      "train AE loss : 3.8623950481414795, train ANN loss : 2.203761577606201\n",
      "AE loss : 3.904123067855835, ANN loss : 1.8211232423782349, Total loss : 392.2333984375\n",
      "learning rate A :  tf.Tensor(9.877484e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1182 is 0.0746 sec\n",
      "train AE loss : 3.8871946334838867, train ANN loss : 2.184798240661621\n",
      "AE loss : 3.806025981903076, ANN loss : 1.819870948791504, Total loss : 382.4224853515625\n",
      "learning rate A :  tf.Tensor(9.877276e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1183 is 0.0738 sec\n",
      "train AE loss : 3.791259527206421, train ANN loss : 2.191392183303833\n",
      "AE loss : 3.7126119136810303, ANN loss : 1.8187658786773682, Total loss : 373.0799560546875\n",
      "learning rate A :  tf.Tensor(9.877067e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1184 is 0.0759 sec\n",
      "train AE loss : 3.6999287605285645, train ANN loss : 2.1903088092803955\n",
      "AE loss : 3.780472755432129, ANN loss : 1.8222023248672485, Total loss : 379.8694763183594\n",
      "learning rate A :  tf.Tensor(9.877067e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1185 is 0.0763 sec\n",
      "train AE loss : 3.767256736755371, train ANN loss : 2.204097032546997\n",
      "AE loss : 3.6878082752227783, ANN loss : 1.821055293083191, Total loss : 370.6018981933594\n",
      "learning rate A :  tf.Tensor(9.876859e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1186 is 0.0736 sec\n",
      "train AE loss : 3.676630973815918, train ANN loss : 2.202173948287964\n",
      "AE loss : 3.7877817153930664, ANN loss : 1.8291481733322144, Total loss : 380.6073303222656\n",
      "learning rate A :  tf.Tensor(9.876859e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1187 is 0.0768 sec\n",
      "train AE loss : 3.776387929916382, train ANN loss : 2.188627243041992\n",
      "AE loss : 3.694247007369995, ANN loss : 1.8276309967041016, Total loss : 371.2523193359375\n",
      "learning rate A :  tf.Tensor(9.876651e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1188 is 0.0747 sec\n",
      "train AE loss : 3.6848292350769043, train ANN loss : 2.1839663982391357\n",
      "AE loss : 3.8050284385681152, ANN loss : 1.8385026454925537, Total loss : 382.34130859375\n",
      "learning rate A :  tf.Tensor(9.876651e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1189 is 0.0767 sec\n",
      "train AE loss : 3.795332193374634, train ANN loss : 2.1880455017089844\n",
      "AE loss : 3.9003708362579346, ANN loss : 1.8433669805526733, Total loss : 391.8804626464844\n",
      "learning rate A :  tf.Tensor(9.876651e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1190 is 0.0767 sec\n",
      "train AE loss : 3.8901491165161133, train ANN loss : 2.191377878189087\n",
      "AE loss : 3.800705909729004, ANN loss : 1.8409279584884644, Total loss : 381.9114990234375\n",
      "learning rate A :  tf.Tensor(9.876444e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1191 is 0.0747 sec\n",
      "train AE loss : 3.7925097942352295, train ANN loss : 2.197432518005371\n",
      "AE loss : 3.8691508769989014, ANN loss : 1.843306541442871, Total loss : 388.7584228515625\n",
      "learning rate A :  tf.Tensor(9.876444e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1192 is 0.0764 sec\n",
      "train AE loss : 3.8604624271392822, train ANN loss : 2.1817545890808105\n",
      "AE loss : 3.9161410331726074, ANN loss : 1.8431955575942993, Total loss : 393.457275390625\n",
      "learning rate A :  tf.Tensor(9.876444e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1193 is 0.0778 sec\n",
      "train AE loss : 3.906233310699463, train ANN loss : 2.1884288787841797\n",
      "AE loss : 3.8154475688934326, ANN loss : 1.8407620191574097, Total loss : 383.3855285644531\n",
      "learning rate A :  tf.Tensor(9.876236e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1194 is 0.0745 sec\n",
      "train AE loss : 3.807591199874878, train ANN loss : 2.1786081790924072\n",
      "AE loss : 3.719740152359009, ANN loss : 1.838518738746643, Total loss : 373.8125305175781\n",
      "learning rate A :  tf.Tensor(9.8760276e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1195 is 0.0758 sec\n",
      "train AE loss : 3.7138359546661377, train ANN loss : 2.19974684715271\n",
      "AE loss : 3.6287248134613037, ANN loss : 1.8364559412002563, Total loss : 364.70892333984375\n",
      "learning rate A :  tf.Tensor(9.8758195e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1196 is 0.0765 sec\n",
      "train AE loss : 3.6246652603149414, train ANN loss : 2.1985270977020264\n",
      "AE loss : 3.5420966148376465, ANN loss : 1.8345608711242676, Total loss : 356.0442199707031\n",
      "learning rate A :  tf.Tensor(9.8756114e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1197 is 0.0747 sec\n",
      "train AE loss : 3.5398168563842773, train ANN loss : 2.1788458824157715\n",
      "AE loss : 3.590531587600708, ANN loss : 1.8323429822921753, Total loss : 360.885498046875\n",
      "learning rate A :  tf.Tensor(9.8756114e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1198 is 0.0773 sec\n",
      "train AE loss : 3.587099075317383, train ANN loss : 2.1932032108306885\n",
      "AE loss : 3.6286301612854004, ANN loss : 1.8236984014511108, Total loss : 364.68670654296875\n",
      "learning rate A :  tf.Tensor(9.8756114e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1199 is 0.0787 sec\n",
      "train AE loss : 3.6245357990264893, train ANN loss : 2.1862645149230957\n",
      "AE loss : 3.6730799674987793, ANN loss : 1.8159221410751343, Total loss : 369.1239013671875\n",
      "learning rate A :  tf.Tensor(9.8756114e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1200 is 0.0769 sec\n",
      "train AE loss : 3.6683754920959473, train ANN loss : 2.17914080619812\n",
      "AE loss : 3.5838825702667236, ANN loss : 1.8142896890640259, Total loss : 360.2025451660156\n",
      "learning rate A :  tf.Tensor(9.8754026e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1201 is 0.0756 sec\n",
      "train AE loss : 3.581073522567749, train ANN loss : 2.1833600997924805\n",
      "AE loss : 3.6550137996673584, ANN loss : 1.8193447589874268, Total loss : 367.3207092285156\n",
      "learning rate A :  tf.Tensor(9.8754026e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1202 is 0.0785 sec\n",
      "train AE loss : 3.6511809825897217, train ANN loss : 2.1887717247009277\n",
      "AE loss : 3.566664218902588, ANN loss : 1.8176264762878418, Total loss : 358.48406982421875\n",
      "learning rate A :  tf.Tensor(9.8751945e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1203 is 0.0751 sec\n",
      "train AE loss : 3.5647106170654297, train ANN loss : 2.1774697303771973\n",
      "AE loss : 3.6497156620025635, ANN loss : 1.8229237794876099, Total loss : 366.7944641113281\n",
      "learning rate A :  tf.Tensor(9.8751945e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1204 is 0.0768 sec\n",
      "train AE loss : 3.646542549133301, train ANN loss : 2.1705727577209473\n",
      "AE loss : 3.561649799346924, ANN loss : 1.821025013923645, Total loss : 357.98602294921875\n",
      "learning rate A :  tf.Tensor(9.8749864e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1205 is 0.0765 sec\n",
      "train AE loss : 3.560326099395752, train ANN loss : 2.178385019302368\n",
      "AE loss : 3.477851629257202, ANN loss : 1.8192908763885498, Total loss : 349.6044616699219\n",
      "learning rate A :  tf.Tensor(9.874779e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1206 is 0.0757 sec\n",
      "train AE loss : 3.478288412094116, train ANN loss : 2.17390775680542\n",
      "AE loss : 3.573852062225342, ANN loss : 1.8283559083938599, Total loss : 359.21356201171875\n",
      "learning rate A :  tf.Tensor(9.874779e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1207 is 0.0777 sec\n",
      "train AE loss : 3.5731489658355713, train ANN loss : 2.1722476482391357\n",
      "AE loss : 3.645339250564575, ANN loss : 1.8321168422698975, Total loss : 366.3660583496094\n",
      "learning rate A :  tf.Tensor(9.874779e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1208 is 0.0791 sec\n",
      "train AE loss : 3.643862247467041, train ANN loss : 2.1712019443511963\n",
      "AE loss : 3.6884500980377197, ANN loss : 1.8237414360046387, Total loss : 370.6687316894531\n",
      "learning rate A :  tf.Tensor(9.874779e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1209 is 0.0771 sec\n",
      "train AE loss : 3.68648362159729, train ANN loss : 2.179382085800171\n",
      "AE loss : 3.7268831729888916, ANN loss : 1.8173744678497314, Total loss : 374.5057373046875\n",
      "learning rate A :  tf.Tensor(9.874779e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1210 is 0.0768 sec\n",
      "train AE loss : 3.7240428924560547, train ANN loss : 2.1879146099090576\n",
      "AE loss : 3.755467414855957, ANN loss : 1.8127319812774658, Total loss : 377.3594665527344\n",
      "learning rate A :  tf.Tensor(9.874779e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1211 is 0.0777 sec\n",
      "train AE loss : 3.7515299320220947, train ANN loss : 2.171785354614258\n",
      "AE loss : 3.6604952812194824, ANN loss : 1.8107306957244873, Total loss : 367.8602600097656\n",
      "learning rate A :  tf.Tensor(9.874571e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1212 is 0.0752 sec\n",
      "train AE loss : 3.658534526824951, train ANN loss : 2.1786224842071533\n",
      "AE loss : 3.5702743530273438, ANN loss : 1.808907151222229, Total loss : 358.83636474609375\n",
      "learning rate A :  tf.Tensor(9.874363e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1213 is 0.0756 sec\n",
      "train AE loss : 3.570209503173828, train ANN loss : 2.1810319423675537\n",
      "AE loss : 3.609884262084961, ANN loss : 1.8091583251953125, Total loss : 362.7975769042969\n",
      "learning rate A :  tf.Tensor(9.874363e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1214 is 0.0783 sec\n",
      "train AE loss : 3.6087920665740967, train ANN loss : 2.162778615951538\n",
      "AE loss : 3.653729200363159, ANN loss : 1.8106580972671509, Total loss : 367.18359375\n",
      "learning rate A :  tf.Tensor(9.874363e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1215 is 0.0768 sec\n",
      "train AE loss : 3.652150869369507, train ANN loss : 2.1744027137756348\n",
      "AE loss : 3.698904037475586, ANN loss : 1.8029441833496094, Total loss : 371.6933288574219\n",
      "learning rate A :  tf.Tensor(9.874363e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1216 is 0.0769 sec\n",
      "train AE loss : 3.6973354816436768, train ANN loss : 2.168492078781128\n",
      "AE loss : 3.605821132659912, ANN loss : 1.8011245727539062, Total loss : 362.38323974609375\n",
      "learning rate A :  tf.Tensor(9.874155e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1217 is 0.0761 sec\n",
      "train AE loss : 3.60617995262146, train ANN loss : 2.1733648777008057\n",
      "AE loss : 3.5173799991607666, ANN loss : 1.7994747161865234, Total loss : 353.5374755859375\n",
      "learning rate A :  tf.Tensor(9.873947e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1218 is 0.0747 sec\n",
      "train AE loss : 3.5196051597595215, train ANN loss : 2.1584408283233643\n",
      "AE loss : 3.4333133697509766, ANN loss : 1.7979832887649536, Total loss : 345.12933349609375\n",
      "learning rate A :  tf.Tensor(9.8737386e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1219 is 0.0756 sec\n",
      "train AE loss : 3.4373083114624023, train ANN loss : 2.1755661964416504\n",
      "AE loss : 3.505028247833252, ANN loss : 1.801467776298523, Total loss : 352.3043212890625\n",
      "learning rate A :  tf.Tensor(9.8737386e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1220 is 0.0782 sec\n",
      "train AE loss : 3.5088846683502197, train ANN loss : 2.1863722801208496\n",
      "AE loss : 3.593149185180664, ANN loss : 1.8127379417419434, Total loss : 361.1276550292969\n",
      "learning rate A :  tf.Tensor(9.8737386e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1221 is 0.0838 sec\n",
      "train AE loss : 3.596439838409424, train ANN loss : 2.1668622493743896\n",
      "AE loss : 3.504730701446533, ANN loss : 1.8104662895202637, Total loss : 352.2835388183594\n",
      "learning rate A :  tf.Tensor(9.8735305e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1222 is 0.0827 sec\n",
      "train AE loss : 3.509801149368286, train ANN loss : 2.165419340133667\n",
      "AE loss : 3.420668125152588, ANN loss : 1.808384656906128, Total loss : 343.87518310546875\n",
      "learning rate A :  tf.Tensor(9.8733224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1223 is 0.0824 sec\n",
      "train AE loss : 3.427462339401245, train ANN loss : 2.162402391433716\n",
      "AE loss : 3.503523349761963, ANN loss : 1.8156063556671143, Total loss : 352.1679382324219\n",
      "learning rate A :  tf.Tensor(9.8733224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1224 is 0.0810 sec\n",
      "train AE loss : 3.509636640548706, train ANN loss : 2.169015645980835\n",
      "AE loss : 3.559412717819214, ANN loss : 1.815292239189148, Total loss : 357.756591796875\n",
      "learning rate A :  tf.Tensor(9.8733224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1225 is 0.0893 sec\n",
      "train AE loss : 3.5648651123046875, train ANN loss : 2.1745574474334717\n",
      "AE loss : 3.472425699234009, ANN loss : 1.812862515449524, Total loss : 349.055419921875\n",
      "learning rate A :  tf.Tensor(9.873114e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1226 is 0.0770 sec\n",
      "train AE loss : 3.4796180725097656, train ANN loss : 2.1751906871795654\n",
      "AE loss : 3.389672040939331, ANN loss : 1.8106188774108887, Total loss : 340.7778015136719\n",
      "learning rate A :  tf.Tensor(9.872906e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1227 is 0.0740 sec\n",
      "train AE loss : 3.3985328674316406, train ANN loss : 2.178541898727417\n",
      "AE loss : 3.3109190464019775, ANN loss : 1.8085510730743408, Total loss : 332.9004821777344\n",
      "learning rate A :  tf.Tensor(9.872699e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1228 is 0.0749 sec\n",
      "train AE loss : 3.3213753700256348, train ANN loss : 2.1755332946777344\n",
      "AE loss : 3.2358222007751465, ANN loss : 1.80663001537323, Total loss : 325.38885498046875\n",
      "learning rate A :  tf.Tensor(9.872491e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1229 is 0.0738 sec\n",
      "train AE loss : 3.2477712631225586, train ANN loss : 2.168933868408203\n",
      "AE loss : 3.16416335105896, ANN loss : 1.8048555850982666, Total loss : 318.22119140625\n",
      "learning rate A :  tf.Tensor(9.872283e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1230 is 0.0736 sec\n",
      "train AE loss : 3.177515983581543, train ANN loss : 2.155648708343506\n",
      "AE loss : 3.2182722091674805, ANN loss : 1.8057878017425537, Total loss : 323.63299560546875\n",
      "learning rate A :  tf.Tensor(9.872283e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1231 is 0.0769 sec\n",
      "train AE loss : 3.2312376499176025, train ANN loss : 2.1665170192718506\n",
      "AE loss : 3.2672863006591797, ANN loss : 1.8062845468521118, Total loss : 328.5348815917969\n",
      "learning rate A :  tf.Tensor(9.872283e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1232 is 0.0817 sec\n",
      "train AE loss : 3.27993106842041, train ANN loss : 2.1655502319335938\n",
      "AE loss : 3.2999866008758545, ANN loss : 1.8003244400024414, Total loss : 331.7989807128906\n",
      "learning rate A :  tf.Tensor(9.872283e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1233 is 0.0763 sec\n",
      "train AE loss : 3.3125698566436768, train ANN loss : 2.1599314212799072\n",
      "AE loss : 3.2252659797668457, ANN loss : 1.7984404563903809, Total loss : 324.3250427246094\n",
      "learning rate A :  tf.Tensor(9.8720746e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1234 is 0.0745 sec\n",
      "train AE loss : 3.2392783164978027, train ANN loss : 2.167630672454834\n",
      "AE loss : 3.25882625579834, ANN loss : 1.795594334602356, Total loss : 327.67822265625\n",
      "learning rate A :  tf.Tensor(9.8720746e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1235 is 0.0760 sec\n",
      "train AE loss : 3.272707223892212, train ANN loss : 2.1726222038269043\n",
      "AE loss : 3.3118698596954346, ANN loss : 1.7992042303085327, Total loss : 332.9861755371094\n",
      "learning rate A :  tf.Tensor(9.8720746e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1236 is 0.0765 sec\n",
      "train AE loss : 3.3250527381896973, train ANN loss : 2.1619908809661865\n",
      "AE loss : 3.354844093322754, ANN loss : 1.793239712715149, Total loss : 337.2776184082031\n",
      "learning rate A :  tf.Tensor(9.8720746e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1237 is 0.0776 sec\n",
      "train AE loss : 3.3673436641693115, train ANN loss : 2.159872531890869\n",
      "AE loss : 3.391202449798584, ANN loss : 1.7887324094772339, Total loss : 340.9089660644531\n",
      "learning rate A :  tf.Tensor(9.8720746e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1238 is 0.0756 sec\n",
      "train AE loss : 3.403205633163452, train ANN loss : 2.1517934799194336\n",
      "AE loss : 3.3110227584838867, ANN loss : 1.7868950366973877, Total loss : 332.8891296386719\n",
      "learning rate A :  tf.Tensor(9.8718665e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1239 is 0.0758 sec\n",
      "train AE loss : 3.324598789215088, train ANN loss : 2.1488196849823\n",
      "AE loss : 3.3453972339630127, ANN loss : 1.78606116771698, Total loss : 336.3258056640625\n",
      "learning rate A :  tf.Tensor(9.8718665e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1240 is 0.0768 sec\n",
      "train AE loss : 3.358829975128174, train ANN loss : 2.1690785884857178\n",
      "AE loss : 3.2671821117401123, ANN loss : 1.784278154373169, Total loss : 328.50250244140625\n",
      "learning rate A :  tf.Tensor(9.8716584e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1241 is 0.0742 sec\n",
      "train AE loss : 3.282146692276001, train ANN loss : 2.1636624336242676\n",
      "AE loss : 3.3161556720733643, ANN loss : 1.788473129272461, Total loss : 333.4040832519531\n",
      "learning rate A :  tf.Tensor(9.8716584e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1242 is 0.0770 sec\n",
      "train AE loss : 3.3309054374694824, train ANN loss : 2.1485652923583984\n",
      "AE loss : 3.3603148460388184, ANN loss : 1.7951685190200806, Total loss : 337.8266906738281\n",
      "learning rate A :  tf.Tensor(9.8716584e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1243 is 0.0769 sec\n",
      "train AE loss : 3.3749475479125977, train ANN loss : 2.1672091484069824\n",
      "AE loss : 3.410616159439087, ANN loss : 1.8002654314041138, Total loss : 342.86187744140625\n",
      "learning rate A :  tf.Tensor(9.8716584e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1244 is 0.0759 sec\n",
      "train AE loss : 3.4245662689208984, train ANN loss : 2.1652324199676514\n",
      "AE loss : 3.4555583000183105, ANN loss : 1.8007209300994873, Total loss : 347.3565368652344\n",
      "learning rate A :  tf.Tensor(9.8716584e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1245 is 0.0762 sec\n",
      "train AE loss : 3.468735933303833, train ANN loss : 2.1625583171844482\n",
      "AE loss : 3.371628522872925, ANN loss : 1.7985097169876099, Total loss : 338.9613342285156\n",
      "learning rate A :  tf.Tensor(9.87145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1246 is 0.0748 sec\n",
      "train AE loss : 3.3863894939422607, train ANN loss : 2.1698880195617676\n",
      "AE loss : 3.4038407802581787, ANN loss : 1.7940384149551392, Total loss : 342.1781005859375\n",
      "learning rate A :  tf.Tensor(9.87145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1247 is 0.0763 sec\n",
      "train AE loss : 3.4184305667877197, train ANN loss : 2.1474480628967285\n",
      "AE loss : 3.4397037029266357, ANN loss : 1.7903040647506714, Total loss : 345.76068115234375\n",
      "learning rate A :  tf.Tensor(9.87145e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1248 is 0.0764 sec\n",
      "train AE loss : 3.45439076423645, train ANN loss : 2.1601619720458984\n",
      "AE loss : 3.355983018875122, ANN loss : 1.7882397174835205, Total loss : 337.38653564453125\n",
      "learning rate A :  tf.Tensor(9.871242e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1249 is 0.0750 sec\n",
      "train AE loss : 3.372244358062744, train ANN loss : 2.1563777923583984\n",
      "AE loss : 3.2763023376464844, ANN loss : 1.7863513231277466, Total loss : 329.4165954589844\n",
      "learning rate A :  tf.Tensor(9.871034e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1250 is 0.0740 sec\n",
      "train AE loss : 3.2940845489501953, train ANN loss : 2.155017137527466\n",
      "AE loss : 3.3191466331481934, ANN loss : 1.7874877452850342, Total loss : 333.7021484375\n",
      "learning rate A :  tf.Tensor(9.871034e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1251 is 0.0761 sec\n",
      "train AE loss : 3.336843490600586, train ANN loss : 2.1500165462493896\n",
      "AE loss : 3.366781234741211, ANN loss : 1.789049744606018, Total loss : 338.4671630859375\n",
      "learning rate A :  tf.Tensor(9.871034e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1252 is 0.0771 sec\n",
      "train AE loss : 3.384002685546875, train ANN loss : 2.158545732498169\n",
      "AE loss : 3.2860586643218994, ANN loss : 1.787087082862854, Total loss : 330.3929443359375\n",
      "learning rate A :  tf.Tensor(9.870826e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1253 is 0.0741 sec\n",
      "train AE loss : 3.3048131465911865, train ANN loss : 2.146806478500366\n",
      "AE loss : 3.209285259246826, ANN loss : 1.7852853536605835, Total loss : 322.71380615234375\n",
      "learning rate A :  tf.Tensor(9.870619e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1254 is 0.0741 sec\n",
      "train AE loss : 3.2294557094573975, train ANN loss : 2.1564009189605713\n",
      "AE loss : 3.2599728107452393, ANN loss : 1.7829891443252563, Total loss : 327.7802734375\n",
      "learning rate A :  tf.Tensor(9.870619e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1255 is 0.0765 sec\n",
      "train AE loss : 3.279653549194336, train ANN loss : 2.1589059829711914\n",
      "AE loss : 3.184424877166748, ANN loss : 1.7812594175338745, Total loss : 320.2237243652344\n",
      "learning rate A :  tf.Tensor(9.8704106e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1256 is 0.0751 sec\n",
      "train AE loss : 3.205471992492676, train ANN loss : 2.149158239364624\n",
      "AE loss : 3.112631320953369, ANN loss : 1.779667615890503, Total loss : 313.04278564453125\n",
      "learning rate A :  tf.Tensor(9.8702025e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1257 is 0.0746 sec\n",
      "train AE loss : 3.134944200515747, train ANN loss : 2.158923864364624\n",
      "AE loss : 3.0443813800811768, ANN loss : 1.7782038450241089, Total loss : 306.2163391113281\n",
      "learning rate A :  tf.Tensor(9.8699944e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1258 is 0.0765 sec\n",
      "train AE loss : 3.067856550216675, train ANN loss : 2.158585548400879\n",
      "AE loss : 3.1120054721832275, ANN loss : 1.781647801399231, Total loss : 312.98223876953125\n",
      "learning rate A :  tf.Tensor(9.8699944e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1259 is 0.0769 sec\n",
      "train AE loss : 3.1355385780334473, train ANN loss : 2.1658010482788086\n",
      "AE loss : 3.043668508529663, ANN loss : 1.7800604104995728, Total loss : 306.1469421386719\n",
      "learning rate A :  tf.Tensor(9.869786e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1260 is 0.0752 sec\n",
      "train AE loss : 3.068359136581421, train ANN loss : 2.1662514209747314\n",
      "AE loss : 2.9786598682403564, ANN loss : 1.7785911560058594, Total loss : 299.6445617675781\n",
      "learning rate A :  tf.Tensor(9.869578e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1261 is 0.0755 sec\n",
      "train AE loss : 3.0044291019439697, train ANN loss : 2.1545968055725098\n",
      "AE loss : 3.0657730102539062, ANN loss : 1.7796121835708618, Total loss : 308.35693359375\n",
      "learning rate A :  tf.Tensor(9.869578e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1262 is 0.0775 sec\n",
      "train AE loss : 3.0917181968688965, train ANN loss : 2.1623010635375977\n",
      "AE loss : 2.9995334148406982, ANN loss : 1.7778092622756958, Total loss : 301.73114013671875\n",
      "learning rate A :  tf.Tensor(9.869371e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1263 is 0.0748 sec\n",
      "train AE loss : 3.0265703201293945, train ANN loss : 2.1586062908172607\n",
      "AE loss : 2.9364888668060303, ANN loss : 1.7761467695236206, Total loss : 295.4250183105469\n",
      "learning rate A :  tf.Tensor(9.869163e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1264 is 0.0763 sec\n",
      "train AE loss : 2.964526891708374, train ANN loss : 2.154240846633911\n",
      "AE loss : 3.029832601547241, ANN loss : 1.785223364830017, Total loss : 304.7684631347656\n",
      "learning rate A :  tf.Tensor(9.869163e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1265 is 0.0769 sec\n",
      "train AE loss : 3.0577664375305176, train ANN loss : 2.1688990592956543\n",
      "AE loss : 2.9651896953582764, ANN loss : 1.7831683158874512, Total loss : 298.3021545410156\n",
      "learning rate A :  tf.Tensor(9.868955e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1266 is 0.0759 sec\n",
      "train AE loss : 2.9941506385803223, train ANN loss : 2.165670156478882\n",
      "AE loss : 2.9036552906036377, ANN loss : 1.7812659740447998, Total loss : 292.14678955078125\n",
      "learning rate A :  tf.Tensor(9.8687466e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1267 is 0.0765 sec\n",
      "train AE loss : 2.933568000793457, train ANN loss : 2.162475109100342\n",
      "AE loss : 2.9816839694976807, ANN loss : 1.7913657426834106, Total loss : 299.95977783203125\n",
      "learning rate A :  tf.Tensor(9.8687466e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1268 is 0.0774 sec\n",
      "train AE loss : 3.0114328861236572, train ANN loss : 2.160991907119751\n",
      "AE loss : 2.9193320274353027, ANN loss : 1.7892264127731323, Total loss : 293.7224426269531\n",
      "learning rate A :  tf.Tensor(9.8685385e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1269 is 0.0745 sec\n",
      "train AE loss : 2.950035333633423, train ANN loss : 2.163127899169922\n",
      "AE loss : 2.8599817752838135, ANN loss : 1.7872347831726074, Total loss : 287.785400390625\n",
      "learning rate A :  tf.Tensor(9.8683304e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1270 is 0.0770 sec\n",
      "train AE loss : 2.891570806503296, train ANN loss : 2.147003173828125\n",
      "AE loss : 2.8034579753875732, ANN loss : 1.785386562347412, Total loss : 282.13116455078125\n",
      "learning rate A :  tf.Tensor(9.868123e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1271 is 0.0755 sec\n",
      "train AE loss : 2.835847854614258, train ANN loss : 2.151707649230957\n",
      "AE loss : 2.867690086364746, ANN loss : 1.7886234521865845, Total loss : 288.55767822265625\n",
      "learning rate A :  tf.Tensor(9.868123e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1272 is 0.0769 sec\n",
      "train AE loss : 2.9000957012176514, train ANN loss : 2.158186197280884\n",
      "AE loss : 2.8107495307922363, ANN loss : 1.7866934537887573, Total loss : 282.86163330078125\n",
      "learning rate A :  tf.Tensor(9.867915e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1273 is 0.0761 sec\n",
      "train AE loss : 2.843952178955078, train ANN loss : 2.151919364929199\n",
      "AE loss : 2.7564432621002197, ANN loss : 1.7848999500274658, Total loss : 277.4292297363281\n",
      "learning rate A :  tf.Tensor(9.8677076e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1274 is 0.0763 sec\n",
      "train AE loss : 2.7903666496276855, train ANN loss : 2.15046763420105\n",
      "AE loss : 2.8107638359069824, ANN loss : 1.7803460359573364, Total loss : 282.8567199707031\n",
      "learning rate A :  tf.Tensor(9.8677076e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1275 is 0.0786 sec\n",
      "train AE loss : 2.844280242919922, train ANN loss : 2.141847848892212\n",
      "AE loss : 2.84004282951355, ANN loss : 1.7781070470809937, Total loss : 285.7823791503906\n",
      "learning rate A :  tf.Tensor(9.8677076e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1276 is 0.0782 sec\n",
      "train AE loss : 2.873142719268799, train ANN loss : 2.1494131088256836\n",
      "AE loss : 2.86491060256958, ANN loss : 1.7748141288757324, Total loss : 288.265869140625\n",
      "learning rate A :  tf.Tensor(9.8677076e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1277 is 0.0770 sec\n",
      "train AE loss : 2.8976805210113525, train ANN loss : 2.1508522033691406\n",
      "AE loss : 2.890721559524536, ANN loss : 1.7689656019210815, Total loss : 290.84112548828125\n",
      "learning rate A :  tf.Tensor(9.8677076e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1278 is 0.0770 sec\n",
      "train AE loss : 2.9232194423675537, train ANN loss : 2.1495676040649414\n",
      "AE loss : 2.832742214202881, ANN loss : 1.7675228118896484, Total loss : 285.041748046875\n",
      "learning rate A :  tf.Tensor(9.8674995e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1279 is 0.0762 sec\n",
      "train AE loss : 2.8660519123077393, train ANN loss : 2.1481950283050537\n",
      "AE loss : 2.777514934539795, ANN loss : 1.7661809921264648, Total loss : 279.5176696777344\n",
      "learning rate A :  tf.Tensor(9.867291e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1280 is 0.0753 sec\n",
      "train AE loss : 2.8115651607513428, train ANN loss : 2.1418094635009766\n",
      "AE loss : 2.724886417388916, ANN loss : 1.764937400817871, Total loss : 274.25360107421875\n",
      "learning rate A :  tf.Tensor(9.8670826e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1281 is 0.0763 sec\n",
      "train AE loss : 2.7596116065979004, train ANN loss : 2.1469099521636963\n",
      "AE loss : 2.774886131286621, ANN loss : 1.76598060131073, Total loss : 279.2546081542969\n",
      "learning rate A :  tf.Tensor(9.8670826e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1282 is 0.0775 sec\n",
      "train AE loss : 2.8091354370117188, train ANN loss : 2.141920566558838\n",
      "AE loss : 2.7221643924713135, ANN loss : 1.7646763324737549, Total loss : 273.9811096191406\n",
      "learning rate A :  tf.Tensor(9.8668745e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1283 is 0.0743 sec\n",
      "train AE loss : 2.7570786476135254, train ANN loss : 2.1416046619415283\n",
      "AE loss : 2.671872138977051, ANN loss : 1.7634813785552979, Total loss : 268.9507141113281\n",
      "learning rate A :  tf.Tensor(9.8666664e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1284 is 0.0756 sec\n",
      "train AE loss : 2.707388401031494, train ANN loss : 2.149620771408081\n",
      "AE loss : 2.6238772869110107, ANN loss : 1.7623786926269531, Total loss : 264.1501159667969\n",
      "learning rate A :  tf.Tensor(9.866459e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1285 is 0.0865 sec\n",
      "train AE loss : 2.659943103790283, train ANN loss : 2.150613307952881\n",
      "AE loss : 2.578052043914795, ANN loss : 1.7613624334335327, Total loss : 259.56658935546875\n",
      "learning rate A :  tf.Tensor(9.866251e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1286 is 0.0750 sec\n",
      "train AE loss : 2.614612102508545, train ANN loss : 2.1388211250305176\n",
      "AE loss : 2.6528449058532715, ANN loss : 1.770891785621643, Total loss : 267.05535888671875\n",
      "learning rate A :  tf.Tensor(9.866251e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1287 is 0.0772 sec\n",
      "train AE loss : 2.68916916847229, train ANN loss : 2.1430065631866455\n",
      "AE loss : 2.6053969860076904, ANN loss : 1.769512414932251, Total loss : 262.3092041015625\n",
      "learning rate A :  tf.Tensor(9.866043e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1288 is 0.0759 sec\n",
      "train AE loss : 2.642239570617676, train ANN loss : 2.148059606552124\n",
      "AE loss : 2.5601062774658203, ANN loss : 1.768226146697998, Total loss : 257.77886962890625\n",
      "learning rate A :  tf.Tensor(9.865835e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1289 is 0.0751 sec\n",
      "train AE loss : 2.5974245071411133, train ANN loss : 2.139167070388794\n",
      "AE loss : 2.645982027053833, ANN loss : 1.7784061431884766, Total loss : 266.3766174316406\n",
      "learning rate A :  tf.Tensor(9.865835e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1290 is 0.0796 sec\n",
      "train AE loss : 2.6834616661071777, train ANN loss : 2.1339871883392334\n",
      "AE loss : 2.598592519760132, ANN loss : 1.7766716480255127, Total loss : 261.63592529296875\n",
      "learning rate A :  tf.Tensor(9.865627e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1291 is 0.0772 sec\n",
      "train AE loss : 2.636575222015381, train ANN loss : 2.1338117122650146\n",
      "AE loss : 2.553377389907837, ANN loss : 1.7750349044799805, Total loss : 257.11279296875\n",
      "learning rate A :  tf.Tensor(9.865419e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1292 is 0.0739 sec\n",
      "train AE loss : 2.591823101043701, train ANN loss : 2.1534628868103027\n",
      "AE loss : 2.6293492317199707, ANN loss : 1.7792887687683105, Total loss : 264.7142333984375\n",
      "learning rate A :  tf.Tensor(9.865419e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1293 is 0.0757 sec\n",
      "train AE loss : 2.667891502380371, train ANN loss : 2.144073247909546\n",
      "AE loss : 2.5825998783111572, ANN loss : 1.777372121810913, Total loss : 260.0373229980469\n",
      "learning rate A :  tf.Tensor(9.865212e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1294 is 0.0744 sec\n",
      "train AE loss : 2.621615171432495, train ANN loss : 2.1470870971679688\n",
      "AE loss : 2.5380122661590576, ANN loss : 1.7755849361419678, Total loss : 255.57679748535156\n",
      "learning rate A :  tf.Tensor(9.865004e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1295 is 0.0750 sec\n",
      "train AE loss : 2.5774519443511963, train ANN loss : 2.136573314666748\n",
      "AE loss : 2.4954562187194824, ANN loss : 1.7739028930664062, Total loss : 251.3195037841797\n",
      "learning rate A :  tf.Tensor(9.864796e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1296 is 0.0736 sec\n",
      "train AE loss : 2.535280466079712, train ANN loss : 2.1423752307891846\n",
      "AE loss : 2.4548165798187256, ANN loss : 1.7723121643066406, Total loss : 247.25396728515625\n",
      "learning rate A :  tf.Tensor(9.864588e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1297 is 0.0743 sec\n",
      "train AE loss : 2.494994878768921, train ANN loss : 2.1484851837158203\n",
      "AE loss : 2.521238088607788, ANN loss : 1.7733014822006226, Total loss : 253.89710998535156\n",
      "learning rate A :  tf.Tensor(9.864588e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1298 is 0.0748 sec\n",
      "train AE loss : 2.561349868774414, train ANN loss : 2.139415740966797\n",
      "AE loss : 2.5647544860839844, ANN loss : 1.7731932401657104, Total loss : 258.2486572265625\n",
      "learning rate A :  tf.Tensor(9.864588e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1299 is 0.0750 sec\n",
      "train AE loss : 2.604686737060547, train ANN loss : 2.147334575653076\n",
      "AE loss : 2.5811662673950195, ANN loss : 1.772963523864746, Total loss : 259.8896179199219\n",
      "learning rate A :  tf.Tensor(9.864588e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1300 is 0.0763 sec\n",
      "train AE loss : 2.6210007667541504, train ANN loss : 2.1535215377807617\n",
      "AE loss : 2.5365467071533203, ANN loss : 1.771407127380371, Total loss : 255.42608642578125\n",
      "learning rate A :  tf.Tensor(9.86438e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1301 is 0.0742 sec\n",
      "train AE loss : 2.576789140701294, train ANN loss : 2.1321604251861572\n",
      "AE loss : 2.541776418685913, ANN loss : 1.7616256475448608, Total loss : 255.9392547607422\n",
      "learning rate A :  tf.Tensor(9.86438e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1302 is 0.0753 sec\n",
      "train AE loss : 2.58203125, train ANN loss : 2.1527504920959473\n",
      "AE loss : 2.5586097240448, ANN loss : 1.7553595304489136, Total loss : 257.6163635253906\n",
      "learning rate A :  tf.Tensor(9.86438e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1303 is 0.0755 sec\n",
      "train AE loss : 2.5988194942474365, train ANN loss : 2.141958236694336\n",
      "AE loss : 2.51478910446167, ANN loss : 1.754312515258789, Total loss : 253.2332305908203\n",
      "learning rate A :  tf.Tensor(9.864172e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1304 is 0.0736 sec\n",
      "train AE loss : 2.5553982257843018, train ANN loss : 2.13806414604187\n",
      "AE loss : 2.4729535579681396, ANN loss : 1.7533494234085083, Total loss : 249.0487060546875\n",
      "learning rate A :  tf.Tensor(9.863965e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1305 is 0.0742 sec\n",
      "train AE loss : 2.513930320739746, train ANN loss : 2.1392102241516113\n",
      "AE loss : 2.5165603160858154, ANN loss : 1.753151297569275, Total loss : 253.4091796875\n",
      "learning rate A :  tf.Tensor(9.863965e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1306 is 0.0766 sec\n",
      "train AE loss : 2.557587146759033, train ANN loss : 2.1329023838043213\n",
      "AE loss : 2.474404811859131, ANN loss : 1.7520925998687744, Total loss : 249.19256591796875\n",
      "learning rate A :  tf.Tensor(9.863757e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1307 is 0.0740 sec\n",
      "train AE loss : 2.5158019065856934, train ANN loss : 2.157538890838623\n",
      "AE loss : 2.434166431427002, ANN loss : 1.7511191368103027, Total loss : 245.1677703857422\n",
      "learning rate A :  tf.Tensor(9.8635486e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1308 is 0.0746 sec\n",
      "train AE loss : 2.4759082794189453, train ANN loss : 2.1470658779144287\n",
      "AE loss : 2.395753860473633, ANN loss : 1.750230312347412, Total loss : 241.3256072998047\n",
      "learning rate A :  tf.Tensor(9.863341e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1309 is 0.0739 sec\n",
      "train AE loss : 2.4378020763397217, train ANN loss : 2.136098861694336\n",
      "AE loss : 2.3590102195739746, ANN loss : 1.7494093179702759, Total loss : 237.65042114257812\n",
      "learning rate A :  tf.Tensor(9.863133e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1310 is 0.0745 sec\n",
      "train AE loss : 2.401310920715332, train ANN loss : 2.1480014324188232\n",
      "AE loss : 2.323852062225342, ANN loss : 1.7486517429351807, Total loss : 234.13385009765625\n",
      "learning rate A :  tf.Tensor(9.862925e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1311 is 0.0742 sec\n",
      "train AE loss : 2.3663856983184814, train ANN loss : 2.1542749404907227\n",
      "AE loss : 2.397979736328125, ANN loss : 1.7587846517562866, Total loss : 241.5567626953125\n",
      "learning rate A :  tf.Tensor(9.862925e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1312 is 0.0778 sec\n",
      "train AE loss : 2.440873622894287, train ANN loss : 2.140864610671997\n",
      "AE loss : 2.361043691635132, ANN loss : 1.757629156112671, Total loss : 237.86199951171875\n",
      "learning rate A :  tf.Tensor(9.862718e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1313 is 0.0737 sec\n",
      "train AE loss : 2.404174327850342, train ANN loss : 2.140773057937622\n",
      "AE loss : 2.436765670776367, ANN loss : 1.769386887550354, Total loss : 245.44595336914062\n",
      "learning rate A :  tf.Tensor(9.862718e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1314 is 0.0757 sec\n",
      "train AE loss : 2.4806458950042725, train ANN loss : 2.1315979957580566\n",
      "AE loss : 2.3980343341827393, ANN loss : 1.767811894416809, Total loss : 241.57125854492188\n",
      "learning rate A :  tf.Tensor(9.8625096e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1315 is 0.0934 sec\n",
      "train AE loss : 2.442145586013794, train ANN loss : 2.1455419063568115\n",
      "AE loss : 2.4583256244659424, ANN loss : 1.7735226154327393, Total loss : 247.6060791015625\n",
      "learning rate A :  tf.Tensor(9.8625096e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1316 is 0.0752 sec\n",
      "train AE loss : 2.5030345916748047, train ANN loss : 2.143603563308716\n",
      "AE loss : 2.4830405712127686, ANN loss : 1.7682069540023804, Total loss : 250.07225036621094\n",
      "learning rate A :  tf.Tensor(9.8625096e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1317 is 0.0760 sec\n",
      "train AE loss : 2.5279529094696045, train ANN loss : 2.139298439025879\n",
      "AE loss : 2.475386142730713, ANN loss : 1.7636094093322754, Total loss : 249.30224609375\n",
      "learning rate A :  tf.Tensor(9.8625096e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1318 is 0.0766 sec\n",
      "train AE loss : 2.52005934715271, train ANN loss : 2.1371853351593018\n",
      "AE loss : 2.456210136413574, ANN loss : 1.7541624307632446, Total loss : 247.37518310546875\n",
      "learning rate A :  tf.Tensor(9.8625096e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1319 is 0.0755 sec\n",
      "train AE loss : 2.5006051063537598, train ANN loss : 2.1299304962158203\n",
      "AE loss : 2.4168519973754883, ANN loss : 1.7529480457305908, Total loss : 243.43814086914062\n",
      "learning rate A :  tf.Tensor(9.8623015e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1320 is 0.0759 sec\n",
      "train AE loss : 2.4614925384521484, train ANN loss : 2.1512646675109863\n",
      "AE loss : 2.410764217376709, ANN loss : 1.7484203577041626, Total loss : 242.82484436035156\n",
      "learning rate A :  tf.Tensor(9.8623015e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1321 is 0.0752 sec\n",
      "train AE loss : 2.455245018005371, train ANN loss : 2.138206720352173\n",
      "AE loss : 2.3735485076904297, ANN loss : 1.7475943565368652, Total loss : 239.10244750976562\n",
      "learning rate A :  tf.Tensor(9.862094e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1322 is 0.0745 sec\n",
      "train AE loss : 2.418267011642456, train ANN loss : 2.1349315643310547\n",
      "AE loss : 2.337949752807617, ANN loss : 1.7468292713165283, Total loss : 235.5418243408203\n",
      "learning rate A :  tf.Tensor(9.861886e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1323 is 0.0771 sec\n",
      "train AE loss : 2.3828542232513428, train ANN loss : 2.1386380195617676\n",
      "AE loss : 2.3712098598480225, ANN loss : 1.7460354566574097, Total loss : 238.86703491210938\n",
      "learning rate A :  tf.Tensor(9.861886e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1324 is 0.0769 sec\n",
      "train AE loss : 2.4163010120391846, train ANN loss : 2.134915351867676\n",
      "AE loss : 2.3357198238372803, ANN loss : 1.7452324628829956, Total loss : 235.3172149658203\n",
      "learning rate A :  tf.Tensor(9.861678e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1325 is 0.0764 sec\n",
      "train AE loss : 2.380993366241455, train ANN loss : 2.148728132247925\n",
      "AE loss : 2.3982646465301514, ANN loss : 1.7535146474838257, Total loss : 241.57997131347656\n",
      "learning rate A :  tf.Tensor(9.861678e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1326 is 0.0775 sec\n",
      "train AE loss : 2.443939208984375, train ANN loss : 2.132699966430664\n",
      "AE loss : 2.459237575531006, ANN loss : 1.7597835063934326, Total loss : 247.68353271484375\n",
      "learning rate A :  tf.Tensor(9.861678e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1327 is 0.0780 sec\n",
      "train AE loss : 2.5057015419006348, train ANN loss : 2.1351895332336426\n",
      "AE loss : 2.497838258743286, ANN loss : 1.7593625783920288, Total loss : 251.54318237304688\n",
      "learning rate A :  tf.Tensor(9.861678e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1328 is 0.0777 sec\n",
      "train AE loss : 2.544994354248047, train ANN loss : 2.137040615081787\n",
      "AE loss : 2.5197079181671143, ANN loss : 1.7571979761123657, Total loss : 253.7279815673828\n",
      "learning rate A :  tf.Tensor(9.861678e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1329 is 0.0782 sec\n",
      "train AE loss : 2.566901922225952, train ANN loss : 2.13053297996521\n",
      "AE loss : 2.5205888748168945, ANN loss : 1.7514013051986694, Total loss : 253.81027221679688\n",
      "learning rate A :  tf.Tensor(9.861678e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1330 is 0.0762 sec\n",
      "train AE loss : 2.5672597885131836, train ANN loss : 2.1365771293640137\n",
      "AE loss : 2.524825096130371, ANN loss : 1.7457222938537598, Total loss : 254.22821044921875\n",
      "learning rate A :  tf.Tensor(9.861678e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1331 is 0.0763 sec\n",
      "train AE loss : 2.5710294246673584, train ANN loss : 2.1328206062316895\n",
      "AE loss : 2.4823014736175537, ANN loss : 1.7444909811019897, Total loss : 249.97463989257812\n",
      "learning rate A :  tf.Tensor(9.8614706e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1332 is 0.0764 sec\n",
      "train AE loss : 2.5287914276123047, train ANN loss : 2.129669189453125\n",
      "AE loss : 2.441746950149536, ANN loss : 1.7433414459228516, Total loss : 245.91802978515625\n",
      "learning rate A :  tf.Tensor(9.8612625e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1333 is 0.0759 sec\n",
      "train AE loss : 2.488492488861084, train ANN loss : 2.141721487045288\n",
      "AE loss : 2.4599924087524414, ANN loss : 1.733778953552246, Total loss : 247.7330322265625\n",
      "learning rate A :  tf.Tensor(9.8612625e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1334 is 0.0875 sec\n",
      "train AE loss : 2.5069074630737305, train ANN loss : 2.1320302486419678\n",
      "AE loss : 2.5063376426696777, ANN loss : 1.7358118295669556, Total loss : 252.36956787109375\n",
      "learning rate A :  tf.Tensor(9.8612625e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1335 is 0.0776 sec\n",
      "train AE loss : 2.5533664226531982, train ANN loss : 2.124763250350952\n",
      "AE loss : 2.464627504348755, ANN loss : 1.7347372770309448, Total loss : 248.19749450683594\n",
      "learning rate A :  tf.Tensor(9.861055e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1336 is 0.1116 sec\n",
      "train AE loss : 2.5119214057922363, train ANN loss : 2.120490074157715\n",
      "AE loss : 2.4248292446136475, ANN loss : 1.733734130859375, Total loss : 244.21664428710938\n",
      "learning rate A :  tf.Tensor(9.860847e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1337 is 0.0797 sec\n",
      "train AE loss : 2.4723594188690186, train ANN loss : 2.122797727584839\n",
      "AE loss : 2.3868606090545654, ANN loss : 1.7328001260757446, Total loss : 240.4188690185547\n",
      "learning rate A :  tf.Tensor(9.860639e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1338 is 0.0869 sec\n",
      "train AE loss : 2.4345920085906982, train ANN loss : 2.1269681453704834\n",
      "AE loss : 2.3506062030792236, ANN loss : 1.7319221496582031, Total loss : 236.79254150390625\n",
      "learning rate A :  tf.Tensor(9.8604316e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1339 is 0.0758 sec\n",
      "train AE loss : 2.3984925746917725, train ANN loss : 2.1365392208099365\n",
      "AE loss : 2.418483018875122, ANN loss : 1.7423558235168457, Total loss : 243.59063720703125\n",
      "learning rate A :  tf.Tensor(9.8604316e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1340 is 0.0795 sec\n",
      "train AE loss : 2.466792106628418, train ANN loss : 2.129368305206299\n",
      "AE loss : 2.4838249683380127, ANN loss : 1.7529534101486206, Total loss : 250.1354522705078\n",
      "learning rate A :  tf.Tensor(9.8604316e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1341 is 0.0783 sec\n",
      "train AE loss : 2.532766819000244, train ANN loss : 2.1329309940338135\n",
      "AE loss : 2.4430434703826904, ANN loss : 1.751389980316162, Total loss : 246.0557403564453\n",
      "learning rate A :  tf.Tensor(9.860224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1342 is 0.0761 sec\n",
      "train AE loss : 2.4921655654907227, train ANN loss : 2.137315273284912\n",
      "AE loss : 2.4867382049560547, ANN loss : 1.750008463859558, Total loss : 250.42384338378906\n",
      "learning rate A :  tf.Tensor(9.860224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1343 is 0.0781 sec\n",
      "train AE loss : 2.5365476608276367, train ANN loss : 2.1319050788879395\n",
      "AE loss : 2.5050559043884277, ANN loss : 1.7443735599517822, Total loss : 252.24996948242188\n",
      "learning rate A :  tf.Tensor(9.860224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1344 is 0.0781 sec\n",
      "train AE loss : 2.5548765659332275, train ANN loss : 2.12161922454834\n",
      "AE loss : 2.5092973709106445, ANN loss : 1.739800214767456, Total loss : 252.66954040527344\n",
      "learning rate A :  tf.Tensor(9.860224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1345 is 0.0776 sec\n",
      "train AE loss : 2.558511734008789, train ANN loss : 2.1143808364868164\n",
      "AE loss : 2.508835554122925, ANN loss : 1.7385783195495605, Total loss : 252.62213134765625\n",
      "learning rate A :  tf.Tensor(9.860224e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1346 is 0.0785 sec\n",
      "train AE loss : 2.5575368404388428, train ANN loss : 2.1209754943847656\n",
      "AE loss : 2.4668710231781006, ANN loss : 1.737343192100525, Total loss : 248.4244384765625\n",
      "learning rate A :  tf.Tensor(9.860016e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1347 is 0.0760 sec\n",
      "train AE loss : 2.5157904624938965, train ANN loss : 2.1398112773895264\n",
      "AE loss : 2.467334747314453, ANN loss : 1.731387734413147, Total loss : 248.46487426757812\n",
      "learning rate A :  tf.Tensor(9.860016e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1348 is 0.0774 sec\n",
      "train AE loss : 2.5161452293395996, train ANN loss : 2.131525754928589\n",
      "AE loss : 2.4272773265838623, ANN loss : 1.7303924560546875, Total loss : 244.4581298828125\n",
      "learning rate A :  tf.Tensor(9.859809e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1349 is 0.0769 sec\n",
      "train AE loss : 2.476283073425293, train ANN loss : 2.116506338119507\n",
      "AE loss : 2.453185558319092, ANN loss : 1.7304495573043823, Total loss : 247.0489959716797\n",
      "learning rate A :  tf.Tensor(9.859809e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1350 is 0.0769 sec\n",
      "train AE loss : 2.5025081634521484, train ANN loss : 2.1096951961517334\n",
      "AE loss : 2.413806915283203, ANN loss : 1.7294858694076538, Total loss : 243.1101837158203\n",
      "learning rate A :  tf.Tensor(9.859601e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1351 is 0.0751 sec\n",
      "train AE loss : 2.463296413421631, train ANN loss : 2.117621421813965\n",
      "AE loss : 2.3762431144714355, ANN loss : 1.7285926342010498, Total loss : 239.3529052734375\n",
      "learning rate A :  tf.Tensor(9.859393e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1352 is 0.0759 sec\n",
      "train AE loss : 2.4258604049682617, train ANN loss : 2.134993314743042\n",
      "AE loss : 2.430140733718872, ANN loss : 1.7331445217132568, Total loss : 244.74722290039062\n",
      "learning rate A :  tf.Tensor(9.859393e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1353 is 0.0777 sec\n",
      "train AE loss : 2.4800140857696533, train ANN loss : 2.1276133060455322\n",
      "AE loss : 2.3918514251708984, ANN loss : 1.732041358947754, Total loss : 240.9171905517578\n",
      "learning rate A :  tf.Tensor(9.859185e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1354 is 0.0746 sec\n",
      "train AE loss : 2.4418506622314453, train ANN loss : 2.129220962524414\n",
      "AE loss : 2.454559087753296, ANN loss : 1.7449043989181519, Total loss : 247.2008056640625\n",
      "learning rate A :  tf.Tensor(9.859185e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1355 is 0.0784 sec\n",
      "train AE loss : 2.5047872066497803, train ANN loss : 2.119049310684204\n",
      "AE loss : 2.4150919914245605, ANN loss : 1.7434712648391724, Total loss : 243.252685546875\n",
      "learning rate A :  tf.Tensor(9.858978e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1356 is 0.0974 sec\n",
      "train AE loss : 2.4654369354248047, train ANN loss : 2.1180641651153564\n",
      "AE loss : 2.3774776458740234, ANN loss : 1.742100715637207, Total loss : 239.48988342285156\n",
      "learning rate A :  tf.Tensor(9.85877e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1357 is 0.0755 sec\n",
      "train AE loss : 2.427913188934326, train ANN loss : 2.1342201232910156\n",
      "AE loss : 2.3416006565093994, ANN loss : 1.7407978773117065, Total loss : 235.90086364746094\n",
      "learning rate A :  tf.Tensor(9.8585624e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1358 is 0.0747 sec\n",
      "train AE loss : 2.3920936584472656, train ANN loss : 2.117372751235962\n",
      "AE loss : 2.3073513507843018, ANN loss : 1.739551305770874, Total loss : 232.4746856689453\n",
      "learning rate A :  tf.Tensor(9.858354e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1359 is 0.0737 sec\n",
      "train AE loss : 2.3578743934631348, train ANN loss : 2.1220364570617676\n",
      "AE loss : 2.3511316776275635, ANN loss : 1.7436268329620361, Total loss : 236.85679626464844\n",
      "learning rate A :  tf.Tensor(9.858354e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1360 is 0.0814 sec\n",
      "train AE loss : 2.4024786949157715, train ANN loss : 2.1163036823272705\n",
      "AE loss : 2.3165574073791504, ANN loss : 1.7422553300857544, Total loss : 233.3979949951172\n",
      "learning rate A :  tf.Tensor(9.858147e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1361 is 0.0764 sec\n",
      "train AE loss : 2.367901563644409, train ANN loss : 2.129389762878418\n",
      "AE loss : 2.345573902130127, ANN loss : 1.7410815954208374, Total loss : 236.2984619140625\n",
      "learning rate A :  tf.Tensor(9.858147e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1362 is 0.0761 sec\n",
      "train AE loss : 2.3978285789489746, train ANN loss : 2.124816417694092\n",
      "AE loss : 2.311361789703369, ANN loss : 1.739701509475708, Total loss : 232.87588500976562\n",
      "learning rate A :  tf.Tensor(9.857939e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1363 is 0.0755 sec\n",
      "train AE loss : 2.363604784011841, train ANN loss : 2.117079257965088\n",
      "AE loss : 2.278728485107422, ANN loss : 1.7383944988250732, Total loss : 229.6112518310547\n",
      "learning rate A :  tf.Tensor(9.8577315e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1364 is 0.0751 sec\n",
      "train AE loss : 2.3309316635131836, train ANN loss : 2.1126699447631836\n",
      "AE loss : 2.2475907802581787, ANN loss : 1.737146258354187, Total loss : 226.4962158203125\n",
      "learning rate A :  tf.Tensor(9.857524e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1365 is 0.0743 sec\n",
      "train AE loss : 2.2997195720672607, train ANN loss : 2.1239333152770996\n",
      "AE loss : 2.217881679534912, ANN loss : 1.7359504699707031, Total loss : 223.52410888671875\n",
      "learning rate A :  tf.Tensor(9.857316e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1366 is 0.0740 sec\n",
      "train AE loss : 2.269897937774658, train ANN loss : 2.1114449501037598\n",
      "AE loss : 2.2449944019317627, ANN loss : 1.7352113723754883, Total loss : 226.23464965820312\n",
      "learning rate A :  tf.Tensor(9.857316e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1367 is 0.0757 sec\n",
      "train AE loss : 2.297386646270752, train ANN loss : 2.1160359382629395\n",
      "AE loss : 2.215360641479492, ANN loss : 1.7339779138565063, Total loss : 223.27003479003906\n",
      "learning rate A :  tf.Tensor(9.857109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1368 is 0.0738 sec\n",
      "train AE loss : 2.267622709274292, train ANN loss : 2.131624221801758\n",
      "AE loss : 2.2353270053863525, ANN loss : 1.7345982789993286, Total loss : 225.26730346679688\n",
      "learning rate A :  tf.Tensor(9.857109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1369 is 0.0766 sec\n",
      "train AE loss : 2.2874321937561035, train ANN loss : 2.1079366207122803\n",
      "AE loss : 2.2508199214935303, ANN loss : 1.730452299118042, Total loss : 226.81243896484375\n",
      "learning rate A :  tf.Tensor(9.857109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1370 is 0.0756 sec\n",
      "train AE loss : 2.303102970123291, train ANN loss : 2.12648344039917\n",
      "AE loss : 2.2588095664978027, ANN loss : 1.7232826948165894, Total loss : 227.60423278808594\n",
      "learning rate A :  tf.Tensor(9.857109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1371 is 0.0760 sec\n",
      "train AE loss : 2.3117358684539795, train ANN loss : 2.108884811401367\n",
      "AE loss : 2.2688982486724854, ANN loss : 1.719831943511963, Total loss : 228.6096649169922\n",
      "learning rate A :  tf.Tensor(9.857109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1372 is 0.0766 sec\n",
      "train AE loss : 2.3224406242370605, train ANN loss : 2.1145575046539307\n",
      "AE loss : 2.287736177444458, ANN loss : 1.7239245176315308, Total loss : 230.49754333496094\n",
      "learning rate A :  tf.Tensor(9.857109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1373 is 0.0762 sec\n",
      "train AE loss : 2.3418543338775635, train ANN loss : 2.123924970626831\n",
      "AE loss : 2.3127293586730957, ANN loss : 1.7265385389328003, Total loss : 232.9994659423828\n",
      "learning rate A :  tf.Tensor(9.857109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1374 is 0.0764 sec\n",
      "train AE loss : 2.367037296295166, train ANN loss : 2.114684581756592\n",
      "AE loss : 2.3387937545776367, ANN loss : 1.7253358364105225, Total loss : 235.60472106933594\n",
      "learning rate A :  tf.Tensor(9.857109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1375 is 0.0766 sec\n",
      "train AE loss : 2.39333176612854, train ANN loss : 2.1010916233062744\n",
      "AE loss : 2.3553273677825928, ANN loss : 1.7224960327148438, Total loss : 237.25521850585938\n",
      "learning rate A :  tf.Tensor(9.857109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1376 is 0.0760 sec\n",
      "train AE loss : 2.410053014755249, train ANN loss : 2.121765613555908\n",
      "AE loss : 2.372100591659546, ANN loss : 1.7222739458084106, Total loss : 238.9323272705078\n",
      "learning rate A :  tf.Tensor(9.857109e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1377 is 0.0767 sec\n",
      "train AE loss : 2.42667818069458, train ANN loss : 2.122854471206665\n",
      "AE loss : 2.3358426094055176, ANN loss : 1.7210232019424438, Total loss : 235.30528259277344\n",
      "learning rate A :  tf.Tensor(9.8569006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1378 is 0.0743 sec\n",
      "train AE loss : 2.3903560638427734, train ANN loss : 2.109616756439209\n",
      "AE loss : 2.3524820804595947, ANN loss : 1.7186505794525146, Total loss : 236.96688842773438\n",
      "learning rate A :  tf.Tensor(9.8569006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1379 is 0.0758 sec\n",
      "train AE loss : 2.4073588848114014, train ANN loss : 2.1156764030456543\n",
      "AE loss : 2.368926525115967, ANN loss : 1.7165833711624146, Total loss : 238.60923767089844\n",
      "learning rate A :  tf.Tensor(9.8569006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1380 is 0.0758 sec\n",
      "train AE loss : 2.4244279861450195, train ANN loss : 2.1044602394104004\n",
      "AE loss : 2.391251564025879, ANN loss : 1.7185170650482178, Total loss : 240.8436737060547\n",
      "learning rate A :  tf.Tensor(9.8569006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1381 is 0.0770 sec\n",
      "train AE loss : 2.4474284648895264, train ANN loss : 2.1144912242889404\n",
      "AE loss : 2.4245166778564453, ANN loss : 1.7230335474014282, Total loss : 244.1746826171875\n",
      "learning rate A :  tf.Tensor(9.8569006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1382 is 0.0772 sec\n",
      "train AE loss : 2.4808733463287354, train ANN loss : 2.1118462085723877\n",
      "AE loss : 2.4507393836975098, ANN loss : 1.7253756523132324, Total loss : 246.79931640625\n",
      "learning rate A :  tf.Tensor(9.8569006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1383 is 0.0759 sec\n",
      "train AE loss : 2.5072312355041504, train ANN loss : 2.1096932888031006\n",
      "AE loss : 2.465827465057373, ANN loss : 1.7207998037338257, Total loss : 248.3035430908203\n",
      "learning rate A :  tf.Tensor(9.8569006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1384 is 0.0768 sec\n",
      "train AE loss : 2.5226216316223145, train ANN loss : 2.1078290939331055\n",
      "AE loss : 2.4813730716705322, ANN loss : 1.716224193572998, Total loss : 249.85354614257812\n",
      "learning rate A :  tf.Tensor(9.8569006e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1385 is 0.0763 sec\n",
      "train AE loss : 2.5382814407348633, train ANN loss : 2.1074254512786865\n",
      "AE loss : 2.4394943714141846, ANN loss : 1.7148305177688599, Total loss : 245.6642608642578\n",
      "learning rate A :  tf.Tensor(9.856693e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1386 is 0.0741 sec\n",
      "train AE loss : 2.496469259262085, train ANN loss : 2.1131808757781982\n",
      "AE loss : 2.450631618499756, ANN loss : 1.7090431451797485, Total loss : 246.77220153808594\n",
      "learning rate A :  tf.Tensor(9.856693e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1387 is 0.0773 sec\n",
      "train AE loss : 2.5076510906219482, train ANN loss : 2.099959373474121\n",
      "AE loss : 2.4100561141967773, ANN loss : 1.707732915878296, Total loss : 242.71334838867188\n",
      "learning rate A :  tf.Tensor(9.856485e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1388 is 0.0765 sec\n",
      "train AE loss : 2.467120409011841, train ANN loss : 2.1049230098724365\n",
      "AE loss : 2.3715295791625977, ANN loss : 1.7064979076385498, Total loss : 238.8594512939453\n",
      "learning rate A :  tf.Tensor(9.856276e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1389 is 0.0753 sec\n",
      "train AE loss : 2.428561210632324, train ANN loss : 2.104918956756592\n",
      "AE loss : 2.334907054901123, ANN loss : 1.7053157091140747, Total loss : 235.19601440429688\n",
      "learning rate A :  tf.Tensor(9.856069e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1390 is 0.0773 sec\n",
      "train AE loss : 2.3918442726135254, train ANN loss : 2.1069867610931396\n",
      "AE loss : 2.3001089096069336, ANN loss : 1.704195261001587, Total loss : 231.71510314941406\n",
      "learning rate A :  tf.Tensor(9.8558616e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1391 is 0.0748 sec\n",
      "train AE loss : 2.3569376468658447, train ANN loss : 2.116396188735962\n",
      "AE loss : 2.266935348510742, ANN loss : 1.703139066696167, Total loss : 228.3966827392578\n",
      "learning rate A :  tf.Tensor(9.8556535e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1392 is 0.0757 sec\n",
      "train AE loss : 2.323638916015625, train ANN loss : 2.0977094173431396\n",
      "AE loss : 2.2353010177612305, ANN loss : 1.702143907546997, Total loss : 225.23223876953125\n",
      "learning rate A :  tf.Tensor(9.855446e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1393 is 0.0761 sec\n",
      "train AE loss : 2.291841745376587, train ANN loss : 2.1087028980255127\n",
      "AE loss : 2.261504650115967, ANN loss : 1.7055282592773438, Total loss : 227.85598754882812\n",
      "learning rate A :  tf.Tensor(9.855446e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1394 is 0.0768 sec\n",
      "train AE loss : 2.318479061126709, train ANN loss : 2.1022305488586426\n",
      "AE loss : 2.2299747467041016, ANN loss : 1.7044360637664795, Total loss : 224.701904296875\n",
      "learning rate A :  tf.Tensor(9.855238e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1395 is 0.0767 sec\n",
      "train AE loss : 2.2867677211761475, train ANN loss : 2.105543613433838\n",
      "AE loss : 2.199965000152588, ANN loss : 1.7034046649932861, Total loss : 221.6999053955078\n",
      "learning rate A :  tf.Tensor(9.855031e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1396 is 0.0759 sec\n",
      "train AE loss : 2.256559133529663, train ANN loss : 2.112274169921875\n",
      "AE loss : 2.244797945022583, ANN loss : 1.7143867015838623, Total loss : 226.19418334960938\n",
      "learning rate A :  tf.Tensor(9.855031e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1397 is 0.0784 sec\n",
      "train AE loss : 2.302528142929077, train ANN loss : 2.1034739017486572\n",
      "AE loss : 2.291977643966675, ANN loss : 1.7187412977218628, Total loss : 230.91651916503906\n",
      "learning rate A :  tf.Tensor(9.855031e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1398 is 0.0775 sec\n",
      "train AE loss : 2.350966215133667, train ANN loss : 2.1126041412353516\n",
      "AE loss : 2.259042263031006, ANN loss : 1.7173892259597778, Total loss : 227.62161254882812\n",
      "learning rate A :  tf.Tensor(9.854823e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1399 is 0.0771 sec\n",
      "train AE loss : 2.3178369998931885, train ANN loss : 2.1007957458496094\n",
      "AE loss : 2.227628231048584, ANN loss : 1.7161003351211548, Total loss : 224.4789276123047\n",
      "learning rate A :  tf.Tensor(9.854615e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1400 is 0.0758 sec\n",
      "train AE loss : 2.2862164974212646, train ANN loss : 2.1074817180633545\n",
      "AE loss : 2.197728395462036, ANN loss : 1.714874505996704, Total loss : 221.4877166748047\n",
      "learning rate A :  tf.Tensor(9.854408e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1401 is 0.0755 sec\n",
      "train AE loss : 2.2560911178588867, train ANN loss : 2.1067516803741455\n",
      "AE loss : 2.169025421142578, ANN loss : 1.713695764541626, Total loss : 218.61622619628906\n",
      "learning rate A :  tf.Tensor(9.8542005e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1402 is 0.0768 sec\n",
      "train AE loss : 2.2271370887756348, train ANN loss : 2.0993480682373047\n",
      "AE loss : 2.1413121223449707, ANN loss : 1.712570309638977, Total loss : 215.84378051757812\n",
      "learning rate A :  tf.Tensor(9.8539924e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1403 is 0.0936 sec\n",
      "train AE loss : 2.1991488933563232, train ANN loss : 2.099935531616211\n",
      "AE loss : 2.1848745346069336, ANN loss : 1.7227907180786133, Total loss : 220.2102508544922\n",
      "learning rate A :  tf.Tensor(9.8539924e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1404 is 0.0809 sec\n",
      "train AE loss : 2.24372935295105, train ANN loss : 2.105431079864502\n",
      "AE loss : 2.15663743019104, ANN loss : 1.721513271331787, Total loss : 217.38523864746094\n",
      "learning rate A :  tf.Tensor(9.853785e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1405 is 0.0805 sec\n",
      "train AE loss : 2.215240716934204, train ANN loss : 2.105398416519165\n",
      "AE loss : 2.1904289722442627, ANN loss : 1.7277052402496338, Total loss : 220.77059936523438\n",
      "learning rate A :  tf.Tensor(9.853785e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1406 is 0.0791 sec\n",
      "train AE loss : 2.2497987747192383, train ANN loss : 2.114347219467163\n",
      "AE loss : 2.1620328426361084, ANN loss : 1.726356863975525, Total loss : 217.92962646484375\n",
      "learning rate A :  tf.Tensor(9.853578e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1407 is 0.0792 sec\n",
      "train AE loss : 2.2211806774139404, train ANN loss : 2.0939433574676514\n",
      "AE loss : 2.178363800048828, ANN loss : 1.7230826616287231, Total loss : 219.55947875976562\n",
      "learning rate A :  tf.Tensor(9.853578e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1408 is 0.0783 sec\n",
      "train AE loss : 2.237968921661377, train ANN loss : 2.0976486206054688\n",
      "AE loss : 2.150420904159546, ANN loss : 1.721771001815796, Total loss : 216.7638397216797\n",
      "learning rate A :  tf.Tensor(9.8533696e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1409 is 0.0762 sec\n",
      "train AE loss : 2.209782838821411, train ANN loss : 2.1038990020751953\n",
      "AE loss : 2.123422145843506, ANN loss : 1.720511794090271, Total loss : 214.06272888183594\n",
      "learning rate A :  tf.Tensor(9.853162e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1410 is 0.0782 sec\n",
      "train AE loss : 2.182495594024658, train ANN loss : 2.101668119430542\n",
      "AE loss : 2.1325693130493164, ANN loss : 1.7088478803634644, Total loss : 214.96575927734375\n",
      "learning rate A :  tf.Tensor(9.853162e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1411 is 0.0770 sec\n",
      "train AE loss : 2.1920340061187744, train ANN loss : 2.107942581176758\n",
      "AE loss : 2.143359661102295, ANN loss : 1.706424355506897, Total loss : 216.04238891601562\n",
      "learning rate A :  tf.Tensor(9.853162e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1412 is 0.0781 sec\n",
      "train AE loss : 2.20287823677063, train ANN loss : 2.0959925651550293\n",
      "AE loss : 2.116594076156616, ANN loss : 1.7053842544555664, Total loss : 213.3647918701172\n",
      "learning rate A :  tf.Tensor(9.852955e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1413 is 0.0784 sec\n",
      "train AE loss : 2.1758038997650146, train ANN loss : 2.10554838180542\n",
      "AE loss : 2.0907351970672607, ANN loss : 1.704395055770874, Total loss : 210.77792358398438\n",
      "learning rate A :  tf.Tensor(9.852747e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1414 is 0.0766 sec\n",
      "train AE loss : 2.1496002674102783, train ANN loss : 2.1041953563690186\n",
      "AE loss : 2.112457513809204, ANN loss : 1.7102545499801636, Total loss : 212.95602416992188\n",
      "learning rate A :  tf.Tensor(9.852747e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1415 is 0.0783 sec\n",
      "train AE loss : 2.171780824661255, train ANN loss : 2.1047418117523193\n",
      "AE loss : 2.086740255355835, ANN loss : 1.7092719078063965, Total loss : 210.38330078125\n",
      "learning rate A :  tf.Tensor(9.8525394e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1416 is 0.0770 sec\n",
      "train AE loss : 2.145707845687866, train ANN loss : 2.0990796089172363\n",
      "AE loss : 2.0618762969970703, ANN loss : 1.7083308696746826, Total loss : 207.8959503173828\n",
      "learning rate A :  tf.Tensor(9.852331e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1417 is 0.0759 sec\n",
      "train AE loss : 2.120474100112915, train ANN loss : 2.0888924598693848\n",
      "AE loss : 2.0377919673919678, ANN loss : 1.7074224948883057, Total loss : 205.4866180419922\n",
      "learning rate A :  tf.Tensor(9.852124e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1418 is 0.0766 sec\n",
      "train AE loss : 2.096039056777954, train ANN loss : 2.112396717071533\n",
      "AE loss : 2.0144760608673096, ANN loss : 1.7065438032150269, Total loss : 203.15414428710938\n",
      "learning rate A :  tf.Tensor(9.851916e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1419 is 0.0771 sec\n",
      "train AE loss : 2.072380781173706, train ANN loss : 2.106168746948242\n",
      "AE loss : 2.052816152572632, ANN loss : 1.7059098482131958, Total loss : 206.987548828125\n",
      "learning rate A :  tf.Tensor(9.851916e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1420 is 0.0781 sec\n",
      "train AE loss : 2.11198091506958, train ANN loss : 2.1049277782440186\n",
      "AE loss : 2.1003434658050537, ANN loss : 1.7119840383529663, Total loss : 211.74632263183594\n",
      "learning rate A :  tf.Tensor(9.851916e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1421 is 0.0789 sec\n",
      "train AE loss : 2.1607367992401123, train ANN loss : 2.093642473220825\n",
      "AE loss : 2.1391642093658447, ANN loss : 1.7132714986801147, Total loss : 215.62969970703125\n",
      "learning rate A :  tf.Tensor(9.851916e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1422 is 0.0783 sec\n",
      "train AE loss : 2.200538396835327, train ANN loss : 2.1077544689178467\n",
      "AE loss : 2.159074306488037, ANN loss : 1.7092050313949585, Total loss : 217.61663818359375\n",
      "learning rate A :  tf.Tensor(9.851916e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1423 is 0.0763 sec\n",
      "train AE loss : 2.220953941345215, train ANN loss : 2.094942092895508\n",
      "AE loss : 2.167487144470215, ANN loss : 1.7030813694000244, Total loss : 218.45179748535156\n",
      "learning rate A :  tf.Tensor(9.851916e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1424 is 0.0777 sec\n",
      "train AE loss : 2.2290728092193604, train ANN loss : 2.1098461151123047\n",
      "AE loss : 2.1399848461151123, ANN loss : 1.7018287181854248, Total loss : 215.7003173828125\n",
      "learning rate A :  tf.Tensor(9.8517085e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1425 is 0.0753 sec\n",
      "train AE loss : 2.201260566711426, train ANN loss : 2.0920040607452393\n",
      "AE loss : 2.1426730155944824, ANN loss : 1.6985974311828613, Total loss : 215.96591186523438\n",
      "learning rate A :  tf.Tensor(9.8517085e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1426 is 0.0775 sec\n",
      "train AE loss : 2.2031290531158447, train ANN loss : 2.087486982345581\n",
      "AE loss : 2.1158363819122314, ANN loss : 1.6974798440933228, Total loss : 213.28111267089844\n",
      "learning rate A :  tf.Tensor(9.851501e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1427 is 0.0749 sec\n",
      "train AE loss : 2.175954580307007, train ANN loss : 2.093592643737793\n",
      "AE loss : 2.0899033546447754, ANN loss : 1.6964092254638672, Total loss : 210.68675231933594\n",
      "learning rate A :  tf.Tensor(9.851293e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1428 is 0.0875 sec\n",
      "train AE loss : 2.149649143218994, train ANN loss : 2.098520517349243\n",
      "AE loss : 2.101896047592163, ANN loss : 1.6987895965576172, Total loss : 211.88839721679688\n",
      "learning rate A :  tf.Tensor(9.851293e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1429 is 0.0758 sec\n",
      "train AE loss : 2.1614463329315186, train ANN loss : 2.0930449962615967\n",
      "AE loss : 2.076317310333252, ANN loss : 1.6978435516357422, Total loss : 209.32957458496094\n",
      "learning rate A :  tf.Tensor(9.8510856e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1430 is 0.0777 sec\n",
      "train AE loss : 2.1355183124542236, train ANN loss : 2.1127936840057373\n",
      "AE loss : 2.1025447845458984, ANN loss : 1.6990447044372559, Total loss : 211.95350646972656\n",
      "learning rate A :  tf.Tensor(9.8510856e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1431 is 0.0775 sec\n",
      "train AE loss : 2.162909746170044, train ANN loss : 2.105642795562744\n",
      "AE loss : 2.140866994857788, ANN loss : 1.7048853635787964, Total loss : 215.79159545898438\n",
      "learning rate A :  tf.Tensor(9.8510856e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1432 is 0.0780 sec\n",
      "train AE loss : 2.202880382537842, train ANN loss : 2.089374542236328\n",
      "AE loss : 2.113917827606201, ANN loss : 1.7037866115570068, Total loss : 213.09556579589844\n",
      "learning rate A :  tf.Tensor(9.850878e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1433 is 0.0763 sec\n",
      "train AE loss : 2.175579071044922, train ANN loss : 2.1085927486419678\n",
      "AE loss : 2.151170492172241, ANN loss : 1.7106095552444458, Total loss : 216.82765197753906\n",
      "learning rate A :  tf.Tensor(9.850878e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1434 is 0.0777 sec\n",
      "train AE loss : 2.2141354084014893, train ANN loss : 2.080744743347168\n",
      "AE loss : 2.1238296031951904, ANN loss : 1.7093476057052612, Total loss : 214.09231567382812\n",
      "learning rate A :  tf.Tensor(9.850671e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1435 is 0.0751 sec\n",
      "train AE loss : 2.18645977973938, train ANN loss : 2.1015818119049072\n",
      "AE loss : 2.150106191635132, ANN loss : 1.7115451097488403, Total loss : 216.72216796875\n",
      "learning rate A :  tf.Tensor(9.850671e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1436 is 0.0775 sec\n",
      "train AE loss : 2.2132771015167236, train ANN loss : 2.0901503562927246\n",
      "AE loss : 2.1629841327667236, ANN loss : 1.7058466672897339, Total loss : 218.0042724609375\n",
      "learning rate A :  tf.Tensor(9.850671e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1437 is 0.0791 sec\n",
      "train AE loss : 2.2258923053741455, train ANN loss : 2.092362642288208\n",
      "AE loss : 2.165743350982666, ANN loss : 1.6981374025344849, Total loss : 218.27249145507812\n",
      "learning rate A :  tf.Tensor(9.850671e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1438 is 0.0760 sec\n",
      "train AE loss : 2.227691173553467, train ANN loss : 2.084890365600586\n",
      "AE loss : 2.1660678386688232, ANN loss : 1.6940991878509521, Total loss : 218.30088806152344\n",
      "learning rate A :  tf.Tensor(9.850671e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1439 is 0.0765 sec\n",
      "train AE loss : 2.2268669605255127, train ANN loss : 2.0910563468933105\n",
      "AE loss : 2.17010760307312, ANN loss : 1.6922197341918945, Total loss : 218.70298767089844\n",
      "learning rate A :  tf.Tensor(9.850671e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1440 is 0.0781 sec\n",
      "train AE loss : 2.2305634021759033, train ANN loss : 2.091961622238159\n",
      "AE loss : 2.1411142349243164, ANN loss : 1.6911920309066772, Total loss : 215.8026123046875\n",
      "learning rate A :  tf.Tensor(9.850463e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1441 is 0.0750 sec\n",
      "train AE loss : 2.2012882232666016, train ANN loss : 2.0824198722839355\n",
      "AE loss : 2.113182306289673, ANN loss : 1.690200686454773, Total loss : 213.00843811035156\n",
      "learning rate A :  tf.Tensor(9.8502554e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1442 is 0.0754 sec\n",
      "train AE loss : 2.1730430126190186, train ANN loss : 2.103360891342163\n",
      "AE loss : 2.0862200260162354, ANN loss : 1.689252495765686, Total loss : 210.31126403808594\n",
      "learning rate A :  tf.Tensor(9.850048e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1443 is 0.0780 sec\n",
      "train AE loss : 2.1457183361053467, train ANN loss : 2.1047985553741455\n",
      "AE loss : 2.0601859092712402, ANN loss : 1.6883431673049927, Total loss : 207.70693969726562\n",
      "learning rate A :  tf.Tensor(9.849841e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1444 is 0.0749 sec\n",
      "train AE loss : 2.1193132400512695, train ANN loss : 2.094249963760376\n",
      "AE loss : 2.035033941268921, ANN loss : 1.6874756813049316, Total loss : 205.1908721923828\n",
      "learning rate A :  tf.Tensor(9.849633e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1445 is 0.0849 sec\n",
      "train AE loss : 2.0938076972961426, train ANN loss : 2.088911771774292\n",
      "AE loss : 2.0107009410858154, ANN loss : 1.6866499185562134, Total loss : 202.75674438476562\n",
      "learning rate A :  tf.Tensor(9.849425e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1446 is 0.0761 sec\n",
      "train AE loss : 2.069139242172241, train ANN loss : 2.0802738666534424\n",
      "AE loss : 1.9871679544448853, ANN loss : 1.6858632564544678, Total loss : 200.40264892578125\n",
      "learning rate A :  tf.Tensor(9.849218e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1447 is 0.0751 sec\n",
      "train AE loss : 2.045285940170288, train ANN loss : 2.0757484436035156\n",
      "AE loss : 1.96442449092865, ANN loss : 1.6851115226745605, Total loss : 198.1275634765625\n",
      "learning rate A :  tf.Tensor(9.8490105e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1448 is 0.0754 sec\n",
      "train AE loss : 2.022202491760254, train ANN loss : 2.094604253768921\n",
      "AE loss : 1.9920551776885986, ANN loss : 1.6869455575942993, Total loss : 200.8924560546875\n",
      "learning rate A :  tf.Tensor(9.8490105e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1449 is 0.0779 sec\n",
      "train AE loss : 2.0511839389801025, train ANN loss : 2.1002235412597656\n",
      "AE loss : 1.9691962003707886, ANN loss : 1.6861485242843628, Total loss : 198.6057586669922\n",
      "learning rate A :  tf.Tensor(9.848803e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1450 is 0.0745 sec\n",
      "train AE loss : 2.0279717445373535, train ANN loss : 2.1005055904388428\n",
      "AE loss : 1.9470802545547485, ANN loss : 1.6853829622268677, Total loss : 196.39341735839844\n",
      "learning rate A :  tf.Tensor(9.848596e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1451 is 0.0752 sec\n",
      "train AE loss : 2.0055079460144043, train ANN loss : 2.0999948978424072\n",
      "AE loss : 1.9986867904663086, ANN loss : 1.6922787427902222, Total loss : 201.5609588623047\n",
      "learning rate A :  tf.Tensor(9.848596e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1452 is 0.0795 sec\n",
      "train AE loss : 2.0597524642944336, train ANN loss : 2.088430881500244\n",
      "AE loss : 1.9757957458496094, ANN loss : 1.6913174390792847, Total loss : 199.27090454101562\n",
      "learning rate A :  tf.Tensor(9.8483884e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1453 is 0.0759 sec\n",
      "train AE loss : 2.036442279815674, train ANN loss : 2.0885207653045654\n",
      "AE loss : 1.9536573886871338, ANN loss : 1.6903810501098633, Total loss : 197.05612182617188\n",
      "learning rate A :  tf.Tensor(9.84818e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1454 is 0.0765 sec\n",
      "train AE loss : 2.013866901397705, train ANN loss : 2.0810067653656006\n",
      "AE loss : 2.012744665145874, ANN loss : 1.7037850618362427, Total loss : 202.97824096679688\n",
      "learning rate A :  tf.Tensor(9.84818e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1455 is 0.0793 sec\n",
      "train AE loss : 2.0752205848693848, train ANN loss : 2.096273183822632\n",
      "AE loss : 1.989434003829956, ANN loss : 1.7025139331817627, Total loss : 200.6459197998047\n",
      "learning rate A :  tf.Tensor(9.847973e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1456 is 0.0756 sec\n",
      "train AE loss : 2.0515127182006836, train ANN loss : 2.084707021713257\n",
      "AE loss : 1.9669040441513062, ANN loss : 1.7012799978256226, Total loss : 198.39169311523438\n",
      "learning rate A :  tf.Tensor(9.8477656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1457 is 0.0758 sec\n",
      "train AE loss : 2.028590202331543, train ANN loss : 2.0711898803710938\n",
      "AE loss : 2.0097458362579346, ANN loss : 1.7108851671218872, Total loss : 202.68545532226562\n",
      "learning rate A :  tf.Tensor(9.8477656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1458 is 0.0787 sec\n",
      "train AE loss : 2.072726011276245, train ANN loss : 2.096953868865967\n",
      "AE loss : 2.0324089527130127, ANN loss : 1.7115193605422974, Total loss : 204.95240783691406\n",
      "learning rate A :  tf.Tensor(9.8477656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1459 is 0.0777 sec\n",
      "train AE loss : 2.096022605895996, train ANN loss : 2.085742235183716\n",
      "AE loss : 2.033223867416382, ANN loss : 1.7022106647491455, Total loss : 205.02459716796875\n",
      "learning rate A :  tf.Tensor(9.8477656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1460 is 0.0780 sec\n",
      "train AE loss : 2.096526622772217, train ANN loss : 2.075854539871216\n",
      "AE loss : 2.0278756618499756, ANN loss : 1.6935087442398071, Total loss : 204.4810791015625\n",
      "learning rate A :  tf.Tensor(9.8477656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1461 is 0.0801 sec\n",
      "train AE loss : 2.090726375579834, train ANN loss : 2.084667205810547\n",
      "AE loss : 2.027231216430664, ANN loss : 1.6877256631851196, Total loss : 204.41082763671875\n",
      "learning rate A :  tf.Tensor(9.8477656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1462 is 0.0776 sec\n",
      "train AE loss : 2.0903162956237793, train ANN loss : 2.0970001220703125\n",
      "AE loss : 2.039929151535034, ANN loss : 1.6915345191955566, Total loss : 205.6844482421875\n",
      "learning rate A :  tf.Tensor(9.8477656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1463 is 0.0871 sec\n",
      "train AE loss : 2.1037209033966064, train ANN loss : 2.1099658012390137\n",
      "AE loss : 2.06520938873291, ANN loss : 1.6934551000595093, Total loss : 208.21438598632812\n",
      "learning rate A :  tf.Tensor(9.8477656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1464 is 0.0785 sec\n",
      "train AE loss : 2.1296510696411133, train ANN loss : 2.0693016052246094\n",
      "AE loss : 2.0397989749908447, ANN loss : 1.6923818588256836, Total loss : 205.6722869873047\n",
      "learning rate A :  tf.Tensor(9.847558e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1465 is 0.0760 sec\n",
      "train AE loss : 2.103834390640259, train ANN loss : 2.086050271987915\n",
      "AE loss : 2.0646607875823975, ANN loss : 1.6961511373519897, Total loss : 208.16221618652344\n",
      "learning rate A :  tf.Tensor(9.847558e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1466 is 0.0789 sec\n",
      "train AE loss : 2.1288704872131348, train ANN loss : 2.0816545486450195\n",
      "AE loss : 2.08306884765625, ANN loss : 1.6923282146453857, Total loss : 209.9992218017578\n",
      "learning rate A :  tf.Tensor(9.847558e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1467 is 0.0769 sec\n",
      "train AE loss : 2.1470892429351807, train ANN loss : 2.071791887283325\n",
      "AE loss : 2.092694044113159, ANN loss : 1.6892272233963013, Total loss : 210.95864868164062\n",
      "learning rate A :  tf.Tensor(9.847558e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1468 is 0.0772 sec\n",
      "train AE loss : 2.1568524837493896, train ANN loss : 2.0805957317352295\n",
      "AE loss : 2.1020474433898926, ANN loss : 1.682390570640564, Total loss : 211.8871307373047\n",
      "learning rate A :  tf.Tensor(9.847558e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1469 is 0.0790 sec\n",
      "train AE loss : 2.16622257232666, train ANN loss : 2.0871756076812744\n",
      "AE loss : 2.0747017860412598, ANN loss : 1.6812951564788818, Total loss : 209.15147399902344\n",
      "learning rate A :  tf.Tensor(9.84735e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1470 is 0.0757 sec\n",
      "train AE loss : 2.1385130882263184, train ANN loss : 2.1007142066955566\n",
      "AE loss : 2.0880894660949707, ANN loss : 1.6807007789611816, Total loss : 210.48963928222656\n",
      "learning rate A :  tf.Tensor(9.84735e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1471 is 0.0776 sec\n",
      "train AE loss : 2.152129888534546, train ANN loss : 2.0910611152648926\n",
      "AE loss : 2.1058998107910156, ANN loss : 1.6821811199188232, Total loss : 212.2721710205078\n",
      "learning rate A :  tf.Tensor(9.84735e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1472 is 0.0776 sec\n",
      "train AE loss : 2.1705477237701416, train ANN loss : 2.089186906814575\n",
      "AE loss : 2.127169609069824, ANN loss : 1.6811331510543823, Total loss : 214.39810180664062\n",
      "learning rate A :  tf.Tensor(9.84735e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1473 is 0.0776 sec\n",
      "train AE loss : 2.192927122116089, train ANN loss : 2.083707332611084\n",
      "AE loss : 2.098879337310791, ANN loss : 1.679912805557251, Total loss : 211.56785583496094\n",
      "learning rate A :  tf.Tensor(9.847143e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1474 is 0.0755 sec\n",
      "train AE loss : 2.164280891418457, train ANN loss : 2.0877745151519775\n",
      "AE loss : 2.0716068744659424, ANN loss : 1.6787282228469849, Total loss : 208.8394317626953\n",
      "learning rate A :  tf.Tensor(9.8469354e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1475 is 0.0767 sec\n",
      "train AE loss : 2.136634588241577, train ANN loss : 2.082404851913452\n",
      "AE loss : 2.045266628265381, ANN loss : 1.6775836944580078, Total loss : 206.20425415039062\n",
      "learning rate A :  tf.Tensor(9.846728e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1476 is 0.0762 sec\n",
      "train AE loss : 2.109931707382202, train ANN loss : 2.0727453231811523\n",
      "AE loss : 2.019876003265381, ANN loss : 1.676485300064087, Total loss : 203.66407775878906\n",
      "learning rate A :  tf.Tensor(9.846521e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1477 is 0.0759 sec\n",
      "train AE loss : 2.084184169769287, train ANN loss : 2.0718398094177246\n",
      "AE loss : 2.0491127967834473, ANN loss : 1.6802281141281128, Total loss : 206.5915069580078\n",
      "learning rate A :  tf.Tensor(9.846521e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1478 is 0.0792 sec\n",
      "train AE loss : 2.114534854888916, train ANN loss : 2.0744431018829346\n",
      "AE loss : 2.082458019256592, ANN loss : 1.6882736682891846, Total loss : 209.93408203125\n",
      "learning rate A :  tf.Tensor(9.846521e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1479 is 0.0774 sec\n",
      "train AE loss : 2.1490466594696045, train ANN loss : 2.0898003578186035\n",
      "AE loss : 2.1103196144104004, ANN loss : 1.6919276714324951, Total loss : 212.72390747070312\n",
      "learning rate A :  tf.Tensor(9.846521e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1480 is 0.0777 sec\n",
      "train AE loss : 2.1776363849639893, train ANN loss : 2.0983684062957764\n",
      "AE loss : 2.0828440189361572, ANN loss : 1.6904770135879517, Total loss : 209.9748992919922\n",
      "learning rate A :  tf.Tensor(9.846313e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1481 is 0.0766 sec\n",
      "train AE loss : 2.149779796600342, train ANN loss : 2.0818004608154297\n",
      "AE loss : 2.056330680847168, ANN loss : 1.6890735626220703, Total loss : 207.32215881347656\n",
      "learning rate A :  tf.Tensor(9.846105e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1482 is 0.0759 sec\n",
      "train AE loss : 2.1228761672973633, train ANN loss : 2.092059373855591\n",
      "AE loss : 2.0736851692199707, ANN loss : 1.6891803741455078, Total loss : 209.05770874023438\n",
      "learning rate A :  tf.Tensor(9.846105e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1483 is 0.0764 sec\n",
      "train AE loss : 2.1405413150787354, train ANN loss : 2.083371639251709\n",
      "AE loss : 2.04744553565979, ANN loss : 1.6878045797348022, Total loss : 206.43234252929688\n",
      "learning rate A :  tf.Tensor(9.845898e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1484 is 0.0763 sec\n",
      "train AE loss : 2.113901138305664, train ANN loss : 2.0861730575561523\n",
      "AE loss : 2.0554301738739014, ANN loss : 1.6891744136810303, Total loss : 207.23219299316406\n",
      "learning rate A :  tf.Tensor(9.845898e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1485 is 0.0776 sec\n",
      "train AE loss : 2.121901273727417, train ANN loss : 2.0781781673431396\n",
      "AE loss : 2.0530285835266113, ANN loss : 1.6867009401321411, Total loss : 206.98956298828125\n",
      "learning rate A :  tf.Tensor(9.845898e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1486 is 0.0782 sec\n",
      "train AE loss : 2.1192445755004883, train ANN loss : 2.086228370666504\n",
      "AE loss : 2.053509473800659, ANN loss : 1.6789189577102661, Total loss : 207.02987670898438\n",
      "learning rate A :  tf.Tensor(9.845898e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1487 is 0.0777 sec\n",
      "train AE loss : 2.119546890258789, train ANN loss : 2.0841381549835205\n",
      "AE loss : 2.0278050899505615, ANN loss : 1.6777187585830688, Total loss : 204.4582061767578\n",
      "learning rate A :  tf.Tensor(9.8456905e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1488 is 0.0733 sec\n",
      "train AE loss : 2.0934624671936035, train ANN loss : 2.094750165939331\n",
      "AE loss : 2.037961483001709, ANN loss : 1.6777820587158203, Total loss : 205.4739227294922\n",
      "learning rate A :  tf.Tensor(9.8456905e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1489 is 0.0764 sec\n",
      "train AE loss : 2.1037662029266357, train ANN loss : 2.067742347717285\n",
      "AE loss : 2.0127856731414795, ANN loss : 1.6766352653503418, Total loss : 202.95521545410156\n",
      "learning rate A :  tf.Tensor(9.845483e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1490 is 0.0752 sec\n",
      "train AE loss : 2.0781896114349365, train ANN loss : 2.076554298400879\n",
      "AE loss : 1.988534688949585, ANN loss : 1.6755350828170776, Total loss : 200.5290069580078\n",
      "learning rate A :  tf.Tensor(9.845275e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1491 is 0.0743 sec\n",
      "train AE loss : 2.0535621643066406, train ANN loss : 2.087604284286499\n",
      "AE loss : 2.016202688217163, ANN loss : 1.686585545539856, Total loss : 203.30686950683594\n",
      "learning rate A :  tf.Tensor(9.845275e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1492 is 0.0762 sec\n",
      "train AE loss : 2.0820364952087402, train ANN loss : 2.0836241245269775\n",
      "AE loss : 2.041107177734375, ANN loss : 1.6884124279022217, Total loss : 205.7991180419922\n",
      "learning rate A :  tf.Tensor(9.845275e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1493 is 0.0779 sec\n",
      "train AE loss : 2.107754707336426, train ANN loss : 2.0714609622955322\n",
      "AE loss : 2.058192253112793, ANN loss : 1.6864354610443115, Total loss : 207.5056610107422\n",
      "learning rate A :  tf.Tensor(9.845275e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1494 is 0.0761 sec\n",
      "train AE loss : 2.1256747245788574, train ANN loss : 2.078875780105591\n",
      "AE loss : 2.0643653869628906, ANN loss : 1.6803616285324097, Total loss : 208.1168975830078\n",
      "learning rate A :  tf.Tensor(9.845275e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1495 is 0.0760 sec\n",
      "train AE loss : 2.1321499347686768, train ANN loss : 2.0837857723236084\n",
      "AE loss : 2.0381205081939697, ANN loss : 1.6790796518325806, Total loss : 205.49114990234375\n",
      "learning rate A :  tf.Tensor(9.845068e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1496 is 0.0758 sec\n",
      "train AE loss : 2.105468511581421, train ANN loss : 2.0775845050811768\n",
      "AE loss : 2.0127999782562256, ANN loss : 1.6778290271759033, Total loss : 202.95782470703125\n",
      "learning rate A :  tf.Tensor(9.84486e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1497 is 0.0737 sec\n",
      "train AE loss : 2.079699993133545, train ANN loss : 2.0788207054138184\n",
      "AE loss : 1.9883308410644531, ANN loss : 1.6766077280044556, Total loss : 200.5096893310547\n",
      "learning rate A :  tf.Tensor(9.844653e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1498 is 0.0744 sec\n",
      "train AE loss : 2.054792881011963, train ANN loss : 2.0522656440734863\n",
      "AE loss : 1.9947069883346558, ANN loss : 1.6764094829559326, Total loss : 201.14710998535156\n",
      "learning rate A :  tf.Tensor(9.844653e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1499 is 0.0815 sec\n",
      "train AE loss : 2.061656951904297, train ANN loss : 2.064507484436035\n",
      "AE loss : 1.9707337617874146, ANN loss : 1.6752063035964966, Total loss : 198.7485809326172\n",
      "learning rate A :  tf.Tensor(9.8444456e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1500 is 0.0763 sec\n",
      "train AE loss : 2.037245512008667, train ANN loss : 2.0742604732513428\n",
      "AE loss : 1.947580337524414, ANN loss : 1.6740450859069824, Total loss : 196.43206787109375\n",
      "learning rate A :  tf.Tensor(9.844238e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1501 is 0.0755 sec\n",
      "train AE loss : 2.0136632919311523, train ANN loss : 2.074289083480835\n",
      "AE loss : 1.925247311592102, ANN loss : 1.6729285717010498, Total loss : 194.19766235351562\n",
      "learning rate A :  tf.Tensor(9.84403e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1502 is 0.0759 sec\n",
      "train AE loss : 1.9909136295318604, train ANN loss : 2.082794189453125\n",
      "AE loss : 1.9036680459976196, ANN loss : 1.6718450784683228, Total loss : 192.0386505126953\n",
      "learning rate A :  tf.Tensor(9.843823e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1503 is 0.0741 sec\n",
      "train AE loss : 1.9689083099365234, train ANN loss : 2.0710067749023438\n",
      "AE loss : 1.916913390159607, ANN loss : 1.6651124954223633, Total loss : 193.35646057128906\n",
      "learning rate A :  tf.Tensor(9.843823e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1504 is 0.0771 sec\n",
      "train AE loss : 1.9830135107040405, train ANN loss : 2.0731418132781982\n",
      "AE loss : 1.9378314018249512, ANN loss : 1.6654818058013916, Total loss : 195.44862365722656\n",
      "learning rate A :  tf.Tensor(9.843823e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1505 is 0.0777 sec\n",
      "train AE loss : 2.00480055809021, train ANN loss : 2.085651159286499\n",
      "AE loss : 1.9157447814941406, ANN loss : 1.6644026041030884, Total loss : 193.2388916015625\n",
      "learning rate A :  tf.Tensor(9.8436154e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1506 is 0.0741 sec\n",
      "train AE loss : 1.9822818040847778, train ANN loss : 2.058424234390259\n",
      "AE loss : 1.8944154977798462, ANN loss : 1.663361668586731, Total loss : 191.1049041748047\n",
      "learning rate A :  tf.Tensor(9.843408e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1507 is 0.0747 sec\n",
      "train AE loss : 1.9605158567428589, train ANN loss : 2.0820770263671875\n",
      "AE loss : 1.873823642730713, ANN loss : 1.6623611450195312, Total loss : 189.04473876953125\n",
      "learning rate A :  tf.Tensor(9.843201e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1508 is 0.0753 sec\n",
      "train AE loss : 1.9394737482070923, train ANN loss : 2.065145492553711\n",
      "AE loss : 1.8538964986801147, ANN loss : 1.6613999605178833, Total loss : 187.05104064941406\n",
      "learning rate A :  tf.Tensor(9.842993e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1509 is 0.0748 sec\n",
      "train AE loss : 1.9190940856933594, train ANN loss : 2.0844266414642334\n",
      "AE loss : 1.8928160667419434, ANN loss : 1.6723260879516602, Total loss : 190.95391845703125\n",
      "learning rate A :  tf.Tensor(9.842993e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1510 is 0.0759 sec\n",
      "train AE loss : 1.9595047235488892, train ANN loss : 2.0754051208496094\n",
      "AE loss : 1.8723279237747192, ANN loss : 1.671177625656128, Total loss : 188.90396118164062\n",
      "learning rate A :  tf.Tensor(9.842786e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1511 is 0.0753 sec\n",
      "train AE loss : 1.9385541677474976, train ANN loss : 2.0680770874023438\n",
      "AE loss : 1.9183317422866821, ANN loss : 1.688854455947876, Total loss : 193.52203369140625\n",
      "learning rate A :  tf.Tensor(9.842786e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1512 is 0.0761 sec\n",
      "train AE loss : 1.9863370656967163, train ANN loss : 2.08880352973938\n",
      "AE loss : 1.948474645614624, ANN loss : 1.6951699256896973, Total loss : 196.54263305664062\n",
      "learning rate A :  tf.Tensor(9.842786e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1513 is 0.0764 sec\n",
      "train AE loss : 2.017791509628296, train ANN loss : 2.0622804164886475\n",
      "AE loss : 1.9612536430358887, ANN loss : 1.6921577453613281, Total loss : 197.81753540039062\n",
      "learning rate A :  tf.Tensor(9.842786e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1514 is 0.0775 sec\n",
      "train AE loss : 2.031219005584717, train ANN loss : 2.0697202682495117\n",
      "AE loss : 1.9621976613998413, ANN loss : 1.6809884309768677, Total loss : 197.9007568359375\n",
      "learning rate A :  tf.Tensor(9.842786e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1515 is 0.0759 sec\n",
      "train AE loss : 2.0320606231689453, train ANN loss : 2.073838472366333\n",
      "AE loss : 1.962306022644043, ANN loss : 1.6778346300125122, Total loss : 197.908447265625\n",
      "learning rate A :  tf.Tensor(9.842786e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1516 is 0.0762 sec\n",
      "train AE loss : 2.031266212463379, train ANN loss : 2.06868314743042\n",
      "AE loss : 1.9392499923706055, ANN loss : 1.6765369176864624, Total loss : 195.60153198242188\n",
      "learning rate A :  tf.Tensor(9.8425786e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1517 is 0.0760 sec\n",
      "train AE loss : 2.0077426433563232, train ANN loss : 2.07306170463562\n",
      "AE loss : 1.9170265197753906, ANN loss : 1.675280213356018, Total loss : 193.3779296875\n",
      "learning rate A :  tf.Tensor(9.842371e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1518 is 0.0748 sec\n",
      "train AE loss : 1.985036015510559, train ANN loss : 2.0765645503997803\n",
      "AE loss : 1.8955813646316528, ANN loss : 1.6740612983703613, Total loss : 191.23220825195312\n",
      "learning rate A :  tf.Tensor(9.842164e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1519 is 0.0759 sec\n",
      "train AE loss : 1.9630972146987915, train ANN loss : 2.0683064460754395\n",
      "AE loss : 1.9012601375579834, ANN loss : 1.6615595817565918, Total loss : 191.78756713867188\n",
      "learning rate A :  tf.Tensor(9.842164e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1520 is 0.0784 sec\n",
      "train AE loss : 1.9687265157699585, train ANN loss : 2.066596031188965\n",
      "AE loss : 1.8801921606063843, ANN loss : 1.6605027914047241, Total loss : 189.67971801757812\n",
      "learning rate A :  tf.Tensor(9.8419565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1521 is 0.0763 sec\n",
      "train AE loss : 1.9471843242645264, train ANN loss : 2.067680835723877\n",
      "AE loss : 1.859868049621582, ANN loss : 1.659487009048462, Total loss : 187.6462860107422\n",
      "learning rate A :  tf.Tensor(9.841749e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1522 is 0.0749 sec\n",
      "train AE loss : 1.9263768196105957, train ANN loss : 2.0579700469970703\n",
      "AE loss : 1.8832042217254639, ANN loss : 1.6609728336334229, Total loss : 189.98138427734375\n",
      "learning rate A :  tf.Tensor(9.841749e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1523 is 0.0876 sec\n",
      "train AE loss : 1.9504833221435547, train ANN loss : 2.0530622005462646\n",
      "AE loss : 1.9161906242370605, ANN loss : 1.6703964471817017, Total loss : 193.28945922851562\n",
      "learning rate A :  tf.Tensor(9.841749e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1524 is 0.0871 sec\n",
      "train AE loss : 1.9844542741775513, train ANN loss : 2.0750303268432617\n",
      "AE loss : 1.8943873643875122, ANN loss : 1.6692054271697998, Total loss : 191.10794067382812\n",
      "learning rate A :  tf.Tensor(9.841542e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1525 is 0.0786 sec\n",
      "train AE loss : 1.9621964693069458, train ANN loss : 2.072331428527832\n",
      "AE loss : 1.8733757734298706, ANN loss : 1.668060064315796, Total loss : 189.005615234375\n",
      "learning rate A :  tf.Tensor(9.841334e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1526 is 0.0764 sec\n",
      "train AE loss : 1.9407318830490112, train ANN loss : 2.0772156715393066\n",
      "AE loss : 1.853076457977295, ANN loss : 1.6669481992721558, Total loss : 186.97459411621094\n",
      "learning rate A :  tf.Tensor(9.841127e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1527 is 0.0749 sec\n",
      "train AE loss : 1.919961929321289, train ANN loss : 2.057130813598633\n",
      "AE loss : 1.884863018989563, ANN loss : 1.6747037172317505, Total loss : 190.1610107421875\n",
      "learning rate A :  tf.Tensor(9.841127e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1528 is 0.0801 sec\n",
      "train AE loss : 1.9528090953826904, train ANN loss : 2.068727970123291\n",
      "AE loss : 1.9122697114944458, ANN loss : 1.6776306629180908, Total loss : 192.90460205078125\n",
      "learning rate A :  tf.Tensor(9.841127e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1529 is 0.0773 sec\n",
      "train AE loss : 1.981081247329712, train ANN loss : 2.077167510986328\n",
      "AE loss : 1.8905096054077148, ANN loss : 1.6763784885406494, Total loss : 190.7273406982422\n",
      "learning rate A :  tf.Tensor(9.84092e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1530 is 0.0753 sec\n",
      "train AE loss : 1.958889365196228, train ANN loss : 2.0605154037475586\n",
      "AE loss : 1.9077157974243164, ANN loss : 1.6738555431365967, Total loss : 192.44541931152344\n",
      "learning rate A :  tf.Tensor(9.84092e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1531 is 0.0793 sec\n",
      "train AE loss : 1.9765018224716187, train ANN loss : 2.0756070613861084\n",
      "AE loss : 1.8860868215560913, ANN loss : 1.6726605892181396, Total loss : 190.28134155273438\n",
      "learning rate A :  tf.Tensor(9.840712e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1532 is 0.0748 sec\n",
      "train AE loss : 1.9544380903244019, train ANN loss : 2.0612354278564453\n",
      "AE loss : 1.865214228630066, ANN loss : 1.6715031862258911, Total loss : 188.19293212890625\n",
      "learning rate A :  tf.Tensor(9.840505e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1533 is 0.0765 sec\n",
      "train AE loss : 1.9331223964691162, train ANN loss : 2.069629430770874\n",
      "AE loss : 1.8771038055419922, ANN loss : 1.6689722537994385, Total loss : 189.37936401367188\n",
      "learning rate A :  tf.Tensor(9.840505e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1534 is 0.0783 sec\n",
      "train AE loss : 1.945088505744934, train ANN loss : 2.0655219554901123\n",
      "AE loss : 1.856521725654602, ANN loss : 1.6678522825241089, Total loss : 187.32003784179688\n",
      "learning rate A :  tf.Tensor(9.8402976e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1535 is 0.0748 sec\n",
      "train AE loss : 1.9240533113479614, train ANN loss : 2.0669329166412354\n",
      "AE loss : 1.863527774810791, ANN loss : 1.6639868021011353, Total loss : 188.01678466796875\n",
      "learning rate A :  tf.Tensor(9.8402976e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1536 is 0.0778 sec\n",
      "train AE loss : 1.9310184717178345, train ANN loss : 2.0659937858581543\n",
      "AE loss : 1.8434072732925415, ANN loss : 1.66286039352417, Total loss : 186.0035858154297\n",
      "learning rate A :  tf.Tensor(9.84009e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1537 is 0.0766 sec\n",
      "train AE loss : 1.9104177951812744, train ANN loss : 2.077441692352295\n",
      "AE loss : 1.854265570640564, ANN loss : 1.658475399017334, Total loss : 187.0850372314453\n",
      "learning rate A :  tf.Tensor(9.84009e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1538 is 0.0780 sec\n",
      "train AE loss : 1.9215519428253174, train ANN loss : 2.053924083709717\n",
      "AE loss : 1.8723537921905518, ANN loss : 1.6611595153808594, Total loss : 188.89654541015625\n",
      "learning rate A :  tf.Tensor(9.84009e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1539 is 0.0778 sec\n",
      "train AE loss : 1.9402750730514526, train ANN loss : 2.0623786449432373\n",
      "AE loss : 1.8519141674041748, ANN loss : 1.6600228548049927, Total loss : 186.8514404296875\n",
      "learning rate A :  tf.Tensor(9.839883e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1540 is 0.0774 sec\n",
      "train AE loss : 1.9193576574325562, train ANN loss : 2.050607442855835\n",
      "AE loss : 1.8321908712387085, ANN loss : 1.658919334411621, Total loss : 184.8780059814453\n",
      "learning rate A :  tf.Tensor(9.8396755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1541 is 0.0802 sec\n",
      "train AE loss : 1.8991353511810303, train ANN loss : 2.059485912322998\n",
      "AE loss : 1.8573912382125854, ANN loss : 1.6640807390213013, Total loss : 187.4031982421875\n",
      "learning rate A :  tf.Tensor(9.8396755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1542 is 0.0806 sec\n",
      "train AE loss : 1.9252195358276367, train ANN loss : 2.0566153526306152\n",
      "AE loss : 1.8826582431793213, ANN loss : 1.6732414960861206, Total loss : 189.93907165527344\n",
      "learning rate A :  tf.Tensor(9.8396755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1543 is 0.0790 sec\n",
      "train AE loss : 1.9509481191635132, train ANN loss : 2.072631359100342\n",
      "AE loss : 1.8971006870269775, ANN loss : 1.6703673601150513, Total loss : 191.38043212890625\n",
      "learning rate A :  tf.Tensor(9.8396755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1544 is 0.0775 sec\n",
      "train AE loss : 1.9653303623199463, train ANN loss : 2.06835675239563\n",
      "AE loss : 1.8977395296096802, ANN loss : 1.6651251316070557, Total loss : 191.43907165527344\n",
      "learning rate A :  tf.Tensor(9.8396755e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1545 is 0.0770 sec\n",
      "train AE loss : 1.9658833742141724, train ANN loss : 2.06341814994812\n",
      "AE loss : 1.8761450052261353, ANN loss : 1.6638981103897095, Total loss : 189.2783966064453\n",
      "learning rate A :  tf.Tensor(9.839468e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1546 is 0.0866 sec\n",
      "train AE loss : 1.9438210725784302, train ANN loss : 2.064188003540039\n",
      "AE loss : 1.855324387550354, ANN loss : 1.66269850730896, Total loss : 187.1951446533203\n",
      "learning rate A :  tf.Tensor(9.839261e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1547 is 0.0774 sec\n",
      "train AE loss : 1.9225131273269653, train ANN loss : 2.0617144107818604\n",
      "AE loss : 1.8591240644454956, ANN loss : 1.6582951545715332, Total loss : 187.57069396972656\n",
      "learning rate A :  tf.Tensor(9.839261e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1548 is 0.0817 sec\n",
      "train AE loss : 1.9266912937164307, train ANN loss : 2.05248761177063\n",
      "AE loss : 1.8389112949371338, ANN loss : 1.6572331190109253, Total loss : 185.54835510253906\n",
      "learning rate A :  tf.Tensor(9.8390534e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1549 is 0.0765 sec\n",
      "train AE loss : 1.905990481376648, train ANN loss : 2.0674326419830322\n",
      "AE loss : 1.8193857669830322, ANN loss : 1.6562081575393677, Total loss : 183.5947723388672\n",
      "learning rate A :  tf.Tensor(9.838846e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1550 is 0.0756 sec\n",
      "train AE loss : 1.8859601020812988, train ANN loss : 2.080993413925171\n",
      "AE loss : 1.838120698928833, ANN loss : 1.6610558032989502, Total loss : 185.47314453125\n",
      "learning rate A :  tf.Tensor(9.838846e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1551 is 0.0828 sec\n",
      "train AE loss : 1.9055016040802002, train ANN loss : 2.0534231662750244\n",
      "AE loss : 1.8186088800430298, ANN loss : 1.6599797010421753, Total loss : 183.5208740234375\n",
      "learning rate A :  tf.Tensor(9.838639e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1552 is 0.0749 sec\n",
      "train AE loss : 1.8854848146438599, train ANN loss : 2.069660186767578\n",
      "AE loss : 1.849399209022522, ANN loss : 1.666054129600525, Total loss : 186.60597229003906\n",
      "learning rate A :  tf.Tensor(9.838639e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1553 is 0.0762 sec\n",
      "train AE loss : 1.9176076650619507, train ANN loss : 2.068000078201294\n",
      "AE loss : 1.8295015096664429, ANN loss : 1.664853572845459, Total loss : 184.61500549316406\n",
      "learning rate A :  tf.Tensor(9.838432e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1554 is 0.0766 sec\n",
      "train AE loss : 1.8971785306930542, train ANN loss : 2.0535051822662354\n",
      "AE loss : 1.8546944856643677, ANN loss : 1.6672307252883911, Total loss : 187.13668823242188\n",
      "learning rate A :  tf.Tensor(9.838432e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1555 is 0.0762 sec\n",
      "train AE loss : 1.9239295721054077, train ANN loss : 2.064910888671875\n",
      "AE loss : 1.834610939025879, ANN loss : 1.6660808324813843, Total loss : 185.12716674804688\n",
      "learning rate A :  tf.Tensor(9.838225e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1556 is 0.0747 sec\n",
      "train AE loss : 1.9033809900283813, train ANN loss : 2.0620532035827637\n",
      "AE loss : 1.8556866645812988, ANN loss : 1.6655269861221313, Total loss : 187.23419189453125\n",
      "learning rate A :  tf.Tensor(9.838225e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1557 is 0.0783 sec\n",
      "train AE loss : 1.9256211519241333, train ANN loss : 2.057471990585327\n",
      "AE loss : 1.8700484037399292, ANN loss : 1.6643925905227661, Total loss : 188.6692352294922\n",
      "learning rate A :  tf.Tensor(9.838225e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1558 is 0.0769 sec\n",
      "train AE loss : 1.940643310546875, train ANN loss : 2.0701987743377686\n",
      "AE loss : 1.8792107105255127, ANN loss : 1.6592475175857544, Total loss : 189.58030700683594\n",
      "learning rate A :  tf.Tensor(9.838225e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1559 is 0.0781 sec\n",
      "train AE loss : 1.9501391649246216, train ANN loss : 2.049478054046631\n",
      "AE loss : 1.8581455945968628, ANN loss : 1.6579673290252686, Total loss : 187.47251892089844\n",
      "learning rate A :  tf.Tensor(9.838017e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1560 is 0.0760 sec\n",
      "train AE loss : 1.9286155700683594, train ANN loss : 2.066549062728882\n",
      "AE loss : 1.8634371757507324, ANN loss : 1.6570301055908203, Total loss : 188.00074768066406\n",
      "learning rate A :  tf.Tensor(9.838017e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1561 is 0.0762 sec\n",
      "train AE loss : 1.933945655822754, train ANN loss : 2.056906223297119\n",
      "AE loss : 1.8682012557983398, ANN loss : 1.6543958187103271, Total loss : 188.4745330810547\n",
      "learning rate A :  tf.Tensor(9.838017e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1562 is 0.0769 sec\n",
      "train AE loss : 1.9387836456298828, train ANN loss : 2.050367593765259\n",
      "AE loss : 1.8769903182983398, ANN loss : 1.6533479690551758, Total loss : 189.35238647460938\n",
      "learning rate A :  tf.Tensor(9.838017e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1563 is 0.0777 sec\n",
      "train AE loss : 1.9480184316635132, train ANN loss : 2.058298349380493\n",
      "AE loss : 1.8892778158187866, ANN loss : 1.6551117897033691, Total loss : 190.58290100097656\n",
      "learning rate A :  tf.Tensor(9.838017e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1564 is 0.0764 sec\n",
      "train AE loss : 1.9607969522476196, train ANN loss : 2.0613627433776855\n",
      "AE loss : 1.8676344156265259, ANN loss : 1.6539368629455566, Total loss : 188.41737365722656\n",
      "learning rate A :  tf.Tensor(9.837809e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1565 is 0.0739 sec\n",
      "train AE loss : 1.9386796951293945, train ANN loss : 2.0600078105926514\n",
      "AE loss : 1.8467684984207153, ANN loss : 1.6527938842773438, Total loss : 186.3296356201172\n",
      "learning rate A :  tf.Tensor(9.837602e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1566 is 0.0772 sec\n",
      "train AE loss : 1.9173080921173096, train ANN loss : 2.049454689025879\n",
      "AE loss : 1.8266749382019043, ANN loss : 1.6516894102096558, Total loss : 184.31918334960938\n",
      "learning rate A :  tf.Tensor(9.837395e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1567 is 0.0747 sec\n",
      "train AE loss : 1.8967043161392212, train ANN loss : 2.0533318519592285\n",
      "AE loss : 1.8473674058914185, ANN loss : 1.656893253326416, Total loss : 186.39364624023438\n",
      "learning rate A :  tf.Tensor(9.837395e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1568 is 0.0758 sec\n",
      "train AE loss : 1.9184341430664062, train ANN loss : 2.043032646179199\n",
      "AE loss : 1.8273268938064575, ANN loss : 1.655739188194275, Total loss : 184.38844299316406\n",
      "learning rate A :  tf.Tensor(9.837188e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1569 is 0.0807 sec\n",
      "train AE loss : 1.8978866338729858, train ANN loss : 2.058864116668701\n",
      "AE loss : 1.8079885244369507, ANN loss : 1.6546190977096558, Total loss : 182.45347595214844\n",
      "learning rate A :  tf.Tensor(9.8369805e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1570 is 0.0755 sec\n",
      "train AE loss : 1.8780462741851807, train ANN loss : 2.0365774631500244\n",
      "AE loss : 1.8332754373550415, ANN loss : 1.6650663614273071, Total loss : 184.99261474609375\n",
      "learning rate A :  tf.Tensor(9.8369805e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1571 is 0.0770 sec\n",
      "train AE loss : 1.904471516609192, train ANN loss : 2.065690279006958\n",
      "AE loss : 1.813783049583435, ANN loss : 1.6638953685760498, Total loss : 183.04220581054688\n",
      "learning rate A :  tf.Tensor(9.836773e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1572 is 0.0758 sec\n",
      "train AE loss : 1.8844696283340454, train ANN loss : 2.056262493133545\n",
      "AE loss : 1.8372496366500854, ANN loss : 1.6672043800354004, Total loss : 185.3921661376953\n",
      "learning rate A :  tf.Tensor(9.836773e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1573 is 0.0764 sec\n",
      "train AE loss : 1.9086862802505493, train ANN loss : 2.063859701156616\n",
      "AE loss : 1.8175781965255737, ANN loss : 1.6660054922103882, Total loss : 183.42381286621094\n",
      "learning rate A :  tf.Tensor(9.8365665e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1574 is 0.0746 sec\n",
      "train AE loss : 1.8885095119476318, train ANN loss : 2.0600390434265137\n",
      "AE loss : 1.7986149787902832, ANN loss : 1.6648379564285278, Total loss : 181.5263214111328\n",
      "learning rate A :  tf.Tensor(9.836359e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1575 is 0.0754 sec\n",
      "train AE loss : 1.869038701057434, train ANN loss : 2.0477194786071777\n",
      "AE loss : 1.8145568370819092, ANN loss : 1.6624490022659302, Total loss : 183.11813354492188\n",
      "learning rate A :  tf.Tensor(9.836359e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1576 is 0.0762 sec\n",
      "train AE loss : 1.885197401046753, train ANN loss : 2.0621891021728516\n",
      "AE loss : 1.821692943572998, ANN loss : 1.6615321636199951, Total loss : 183.83082580566406\n",
      "learning rate A :  tf.Tensor(9.836359e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1577 is 0.0766 sec\n",
      "train AE loss : 1.8922559022903442, train ANN loss : 2.0356862545013428\n",
      "AE loss : 1.8023521900177002, ANN loss : 1.6603487730026245, Total loss : 181.89556884765625\n",
      "learning rate A :  tf.Tensor(9.836151e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1578 is 0.0755 sec\n",
      "train AE loss : 1.8724099397659302, train ANN loss : 2.0515923500061035\n",
      "AE loss : 1.8089579343795776, ANN loss : 1.6576101779937744, Total loss : 182.55340576171875\n",
      "learning rate A :  tf.Tensor(9.836151e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1579 is 0.0760 sec\n",
      "train AE loss : 1.8792561292648315, train ANN loss : 2.0442161560058594\n",
      "AE loss : 1.815036654472351, ANN loss : 1.6437841653823853, Total loss : 183.14743041992188\n",
      "learning rate A :  tf.Tensor(9.836151e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1580 is 0.0761 sec\n",
      "train AE loss : 1.8856884241104126, train ANN loss : 2.054009199142456\n",
      "AE loss : 1.7958532571792603, ANN loss : 1.6426496505737305, Total loss : 181.2279815673828\n",
      "learning rate A :  tf.Tensor(9.8359444e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1581 is 0.0766 sec\n",
      "train AE loss : 1.8659950494766235, train ANN loss : 2.050940752029419\n",
      "AE loss : 1.8126683235168457, ANN loss : 1.6455365419387817, Total loss : 182.91236877441406\n",
      "learning rate A :  tf.Tensor(9.8359444e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1582 is 0.0772 sec\n",
      "train AE loss : 1.8832147121429443, train ANN loss : 2.052225112915039\n",
      "AE loss : 1.7935068607330322, ANN loss : 1.644379734992981, Total loss : 180.9950714111328\n",
      "learning rate A :  tf.Tensor(9.835737e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1583 is 0.0748 sec\n",
      "train AE loss : 1.863532304763794, train ANN loss : 2.0670504570007324\n",
      "AE loss : 1.7750170230865479, ANN loss : 1.6432560682296753, Total loss : 179.1449737548828\n",
      "learning rate A :  tf.Tensor(9.8355296e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1584 is 0.0765 sec\n",
      "train AE loss : 1.8445104360580444, train ANN loss : 2.0629241466522217\n",
      "AE loss : 1.7571666240692139, ANN loss : 1.6421632766723633, Total loss : 177.35882568359375\n",
      "learning rate A :  tf.Tensor(9.835323e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1585 is 0.0768 sec\n",
      "train AE loss : 1.8261361122131348, train ANN loss : 2.064765691757202\n",
      "AE loss : 1.7849417924880981, ANN loss : 1.646244764328003, Total loss : 180.14044189453125\n",
      "learning rate A :  tf.Tensor(9.835323e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1586 is 0.0786 sec\n",
      "train AE loss : 1.8549803495407104, train ANN loss : 2.048835515975952\n",
      "AE loss : 1.7667590379714966, ANN loss : 1.6450538635253906, Total loss : 178.32095336914062\n",
      "learning rate A :  tf.Tensor(9.8351156e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1587 is 0.0761 sec\n",
      "train AE loss : 1.8362425565719604, train ANN loss : 2.0489606857299805\n",
      "AE loss : 1.7491888999938965, ANN loss : 1.6438965797424316, Total loss : 176.56277465820312\n",
      "learning rate A :  tf.Tensor(9.834908e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1588 is 0.0760 sec\n",
      "train AE loss : 1.8181370496749878, train ANN loss : 2.0394821166992188\n",
      "AE loss : 1.7783145904541016, ANN loss : 1.6567270755767822, Total loss : 179.4881591796875\n",
      "learning rate A :  tf.Tensor(9.834908e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1589 is 0.0772 sec\n",
      "train AE loss : 1.8485575914382935, train ANN loss : 2.06501841545105\n",
      "AE loss : 1.7602818012237549, ANN loss : 1.655527114868164, Total loss : 177.68370056152344\n",
      "learning rate A :  tf.Tensor(9.834701e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1590 is 0.1105 sec\n",
      "train AE loss : 1.8299891948699951, train ANN loss : 2.0544116497039795\n",
      "AE loss : 1.783255934715271, ANN loss : 1.6659820079803467, Total loss : 179.99156188964844\n",
      "learning rate A :  tf.Tensor(9.834701e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1591 is 0.0856 sec\n",
      "train AE loss : 1.8538421392440796, train ANN loss : 2.0500855445861816\n",
      "AE loss : 1.794903039932251, ANN loss : 1.6622287034988403, Total loss : 181.1525421142578\n",
      "learning rate A :  tf.Tensor(9.834701e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1592 is 0.0790 sec\n",
      "train AE loss : 1.8658849000930786, train ANN loss : 2.0389134883880615\n",
      "AE loss : 1.7760614156723022, ANN loss : 1.661030650138855, Total loss : 179.26718139648438\n",
      "learning rate A :  tf.Tensor(9.834493e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1593 is 0.0762 sec\n",
      "train AE loss : 1.8465855121612549, train ANN loss : 2.0596847534179688\n",
      "AE loss : 1.7579114437103271, ANN loss : 1.6598626375198364, Total loss : 177.45098876953125\n",
      "learning rate A :  tf.Tensor(9.8342854e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1594 is 0.0761 sec\n",
      "train AE loss : 1.8279221057891846, train ANN loss : 2.045954942703247\n",
      "AE loss : 1.7647619247436523, ANN loss : 1.6522812843322754, Total loss : 178.1284637451172\n",
      "learning rate A :  tf.Tensor(9.8342854e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1595 is 0.0783 sec\n",
      "train AE loss : 1.834942102432251, train ANN loss : 2.0663793087005615\n",
      "AE loss : 1.7710593938827515, ANN loss : 1.6438980102539062, Total loss : 178.74984741210938\n",
      "learning rate A :  tf.Tensor(9.8342854e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1596 is 0.0772 sec\n",
      "train AE loss : 1.8412996530532837, train ANN loss : 2.0596766471862793\n",
      "AE loss : 1.7530072927474976, ANN loss : 1.6427282094955444, Total loss : 176.94346618652344\n",
      "learning rate A :  tf.Tensor(9.834078e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1597 is 0.0750 sec\n",
      "train AE loss : 1.822691798210144, train ANN loss : 2.039165735244751\n",
      "AE loss : 1.7356001138687134, ANN loss : 1.6415889263153076, Total loss : 175.2016143798828\n",
      "learning rate A :  tf.Tensor(9.8338714e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1598 is 0.0771 sec\n",
      "train AE loss : 1.8047287464141846, train ANN loss : 2.065835475921631\n",
      "AE loss : 1.718803882598877, ANN loss : 1.640489935874939, Total loss : 173.5208740234375\n",
      "learning rate A :  tf.Tensor(9.833664e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1599 is 0.0756 sec\n",
      "train AE loss : 1.787393569946289, train ANN loss : 2.044152021408081\n",
      "AE loss : 1.7025864124298096, ANN loss : 1.639418125152588, Total loss : 171.89805603027344\n",
      "learning rate A :  tf.Tensor(9.833457e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1600 is 0.0761 sec\n",
      "train AE loss : 1.770651936531067, train ANN loss : 2.0483295917510986\n",
      "AE loss : 1.714592695236206, ANN loss : 1.642886996269226, Total loss : 173.1021728515625\n",
      "learning rate A :  tf.Tensor(9.833457e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1601 is 0.0776 sec\n",
      "train AE loss : 1.783104419708252, train ANN loss : 2.0460939407348633\n",
      "AE loss : 1.698481559753418, ANN loss : 1.6418927907943726, Total loss : 171.49005126953125\n",
      "learning rate A :  tf.Tensor(9.83325e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1602 is 0.0763 sec\n",
      "train AE loss : 1.7664676904678345, train ANN loss : 2.064417600631714\n",
      "AE loss : 1.6829278469085693, ANN loss : 1.6409319639205933, Total loss : 169.9337158203125\n",
      "learning rate A :  tf.Tensor(9.833043e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1603 is 0.0762 sec\n",
      "train AE loss : 1.750391960144043, train ANN loss : 2.0567338466644287\n",
      "AE loss : 1.7050856351852417, ANN loss : 1.643594741821289, Total loss : 172.15216064453125\n",
      "learning rate A :  tf.Tensor(9.833043e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1604 is 0.0788 sec\n",
      "train AE loss : 1.7736196517944336, train ANN loss : 2.0464956760406494\n",
      "AE loss : 1.6893205642700195, ANN loss : 1.6425670385360718, Total loss : 170.57461547851562\n",
      "learning rate A :  tf.Tensor(9.832835e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1605 is 0.0750 sec\n",
      "train AE loss : 1.7573095560073853, train ANN loss : 2.0480687618255615\n",
      "AE loss : 1.6741002798080444, ANN loss : 1.6415706872940063, Total loss : 169.0515899658203\n",
      "learning rate A :  tf.Tensor(9.832628e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1606 is 0.0758 sec\n",
      "train AE loss : 1.7415566444396973, train ANN loss : 2.046043872833252\n",
      "AE loss : 1.7015677690505981, ANN loss : 1.6518175601959229, Total loss : 171.80860900878906\n",
      "learning rate A :  tf.Tensor(9.832628e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1607 is 0.0794 sec\n",
      "train AE loss : 1.7703646421432495, train ANN loss : 2.041966438293457\n",
      "AE loss : 1.7217462062835693, ANN loss : 1.6591014862060547, Total loss : 173.83372497558594\n",
      "learning rate A :  tf.Tensor(9.832628e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1608 is 0.0776 sec\n",
      "train AE loss : 1.7912744283676147, train ANN loss : 2.0471417903900146\n",
      "AE loss : 1.7053831815719604, ANN loss : 1.6578731536865234, Total loss : 172.19619750976562\n",
      "learning rate A :  tf.Tensor(9.8324206e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1609 is 0.0750 sec\n",
      "train AE loss : 1.7744477987289429, train ANN loss : 2.0507423877716064\n",
      "AE loss : 1.6895906925201416, ANN loss : 1.6566743850708008, Total loss : 170.61575317382812\n",
      "learning rate A :  tf.Tensor(9.832214e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1610 is 0.0818 sec\n",
      "train AE loss : 1.758167028427124, train ANN loss : 2.048893928527832\n",
      "AE loss : 1.704477310180664, ANN loss : 1.659510612487793, Total loss : 172.10723876953125\n",
      "learning rate A :  tf.Tensor(9.832214e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1611 is 0.0796 sec\n",
      "train AE loss : 1.7734997272491455, train ANN loss : 2.0529911518096924\n",
      "AE loss : 1.6887212991714478, ANN loss : 1.6583125591278076, Total loss : 170.53042602539062\n",
      "learning rate A :  tf.Tensor(9.8320066e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1612 is 0.0762 sec\n",
      "train AE loss : 1.7572683095932007, train ANN loss : 2.04546856880188\n",
      "AE loss : 1.6961170434951782, ANN loss : 1.6488348245620728, Total loss : 171.2605438232422\n",
      "learning rate A :  tf.Tensor(9.8320066e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1613 is 0.0779 sec\n",
      "train AE loss : 1.7649672031402588, train ANN loss : 2.048480749130249\n",
      "AE loss : 1.6806482076644897, ANN loss : 1.6476649045944214, Total loss : 169.7124786376953\n",
      "learning rate A :  tf.Tensor(9.8318e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1614 is 0.0754 sec\n",
      "train AE loss : 1.7489862442016602, train ANN loss : 2.0421524047851562\n",
      "AE loss : 1.6657277345657349, ANN loss : 1.6465299129486084, Total loss : 168.21929931640625\n",
      "learning rate A :  tf.Tensor(9.831592e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1615 is 0.0756 sec\n",
      "train AE loss : 1.733544945716858, train ANN loss : 2.048200845718384\n",
      "AE loss : 1.6707199811935425, ANN loss : 1.6392011642456055, Total loss : 168.71119689941406\n",
      "learning rate A :  tf.Tensor(9.831592e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1616 is 0.0803 sec\n",
      "train AE loss : 1.7387712001800537, train ANN loss : 2.0390565395355225\n",
      "AE loss : 1.678134799003601, ANN loss : 1.636693000793457, Total loss : 169.45018005371094\n",
      "learning rate A :  tf.Tensor(9.831592e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1617 is 0.0760 sec\n",
      "train AE loss : 1.7463982105255127, train ANN loss : 2.0435800552368164\n",
      "AE loss : 1.6893539428710938, ANN loss : 1.639712929725647, Total loss : 170.5751190185547\n",
      "learning rate A :  tf.Tensor(9.831592e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1618 is 0.0756 sec\n",
      "train AE loss : 1.7582837343215942, train ANN loss : 2.034895181655884\n",
      "AE loss : 1.7084476947784424, ANN loss : 1.644734501838684, Total loss : 172.48948669433594\n",
      "learning rate A :  tf.Tensor(9.831592e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1619 is 0.0780 sec\n",
      "train AE loss : 1.7783130407333374, train ANN loss : 2.0457489490509033\n",
      "AE loss : 1.6924997568130493, ANN loss : 1.6436246633529663, Total loss : 170.8936004638672\n",
      "learning rate A :  tf.Tensor(9.831385e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1620 is 0.0739 sec\n",
      "train AE loss : 1.7618392705917358, train ANN loss : 2.0287463665008545\n",
      "AE loss : 1.6771239042282104, ANN loss : 1.6425429582595825, Total loss : 169.3549346923828\n",
      "learning rate A :  tf.Tensor(9.831178e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1621 is 0.0741 sec\n",
      "train AE loss : 1.7459255456924438, train ANN loss : 2.048898220062256\n",
      "AE loss : 1.6999921798706055, ANN loss : 1.649924397468567, Total loss : 171.64913940429688\n",
      "learning rate A :  tf.Tensor(9.831178e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1622 is 0.0766 sec\n",
      "train AE loss : 1.7697325944900513, train ANN loss : 2.0344698429107666\n",
      "AE loss : 1.7145962715148926, ANN loss : 1.650957465171814, Total loss : 173.11058044433594\n",
      "learning rate A :  tf.Tensor(9.831178e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1623 is 0.0764 sec\n",
      "train AE loss : 1.7850277423858643, train ANN loss : 2.045795440673828\n",
      "AE loss : 1.6985043287277222, ANN loss : 1.6497573852539062, Total loss : 171.50018310546875\n",
      "learning rate A :  tf.Tensor(9.8309705e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1624 is 0.0737 sec\n",
      "train AE loss : 1.768445372581482, train ANN loss : 2.0338973999023438\n",
      "AE loss : 1.7060717344284058, ANN loss : 1.642870545387268, Total loss : 172.25006103515625\n",
      "learning rate A :  tf.Tensor(9.8309705e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1625 is 0.0775 sec\n",
      "train AE loss : 1.7766263484954834, train ANN loss : 2.0428056716918945\n",
      "AE loss : 1.7076350450515747, ANN loss : 1.638981819152832, Total loss : 172.40248107910156\n",
      "learning rate A :  tf.Tensor(9.8309705e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1626 is 0.0760 sec\n",
      "train AE loss : 1.7785298824310303, train ANN loss : 2.0577518939971924\n",
      "AE loss : 1.6918995380401611, ANN loss : 1.6378847360610962, Total loss : 170.8278350830078\n",
      "learning rate A :  tf.Tensor(9.830764e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1627 is 0.0739 sec\n",
      "train AE loss : 1.7622562646865845, train ANN loss : 2.0380139350891113\n",
      "AE loss : 1.6955273151397705, ANN loss : 1.6389193534851074, Total loss : 171.19166564941406\n",
      "learning rate A :  tf.Tensor(9.830764e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1628 is 0.0763 sec\n",
      "train AE loss : 1.7661255598068237, train ANN loss : 2.0432562828063965\n",
      "AE loss : 1.6801902055740356, ANN loss : 1.637864589691162, Total loss : 169.65689086914062\n",
      "learning rate A :  tf.Tensor(9.8305565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1629 is 0.0911 sec\n",
      "train AE loss : 1.7502415180206299, train ANN loss : 2.0263216495513916\n",
      "AE loss : 1.6903374195098877, ANN loss : 1.6413824558258057, Total loss : 170.67514038085938\n",
      "learning rate A :  tf.Tensor(9.8305565e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1630 is 0.0865 sec\n",
      "train AE loss : 1.7606340646743774, train ANN loss : 2.035419464111328\n",
      "AE loss : 1.675094723701477, ANN loss : 1.6402934789657593, Total loss : 169.14976501464844\n",
      "learning rate A :  tf.Tensor(9.830349e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1631 is 0.0741 sec\n",
      "train AE loss : 1.7448501586914062, train ANN loss : 2.044494152069092\n",
      "AE loss : 1.660391092300415, ANN loss : 1.6392353773117065, Total loss : 167.6783447265625\n",
      "learning rate A :  tf.Tensor(9.830142e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1632 is 0.0739 sec\n",
      "train AE loss : 1.7295947074890137, train ANN loss : 2.0477406978607178\n",
      "AE loss : 1.6749463081359863, ANN loss : 1.6427409648895264, Total loss : 169.13735961914062\n",
      "learning rate A :  tf.Tensor(9.830142e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1633 is 0.0776 sec\n",
      "train AE loss : 1.7445067167282104, train ANN loss : 2.048813819885254\n",
      "AE loss : 1.6914433240890503, ANN loss : 1.6426423788070679, Total loss : 170.7869873046875\n",
      "learning rate A :  tf.Tensor(9.830142e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1634 is 0.0760 sec\n",
      "train AE loss : 1.7613770961761475, train ANN loss : 2.0435049533843994\n",
      "AE loss : 1.6759917736053467, ANN loss : 1.6414481401443481, Total loss : 169.24061584472656\n",
      "learning rate A :  tf.Tensor(9.829935e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1635 is 0.0751 sec\n",
      "train AE loss : 1.7454339265823364, train ANN loss : 2.031477689743042\n",
      "AE loss : 1.6610866785049438, ANN loss : 1.6402908563613892, Total loss : 167.74896240234375\n",
      "learning rate A :  tf.Tensor(9.829728e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1636 is 0.0755 sec\n",
      "train AE loss : 1.7300325632095337, train ANN loss : 2.0353264808654785\n",
      "AE loss : 1.6467175483703613, ANN loss : 1.6391651630401611, Total loss : 166.31092834472656\n",
      "learning rate A :  tf.Tensor(9.829521e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1637 is 0.0746 sec\n",
      "train AE loss : 1.7151436805725098, train ANN loss : 2.024846076965332\n",
      "AE loss : 1.6650567054748535, ANN loss : 1.6389729976654053, Total loss : 168.14463806152344\n",
      "learning rate A :  tf.Tensor(9.829521e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1638 is 0.0776 sec\n",
      "train AE loss : 1.73423433303833, train ANN loss : 2.026764392852783\n",
      "AE loss : 1.6812167167663574, ANN loss : 1.641587734222412, Total loss : 169.7632598876953\n",
      "learning rate A :  tf.Tensor(9.829521e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1639 is 0.0786 sec\n",
      "train AE loss : 1.7512136697769165, train ANN loss : 2.02982497215271\n",
      "AE loss : 1.6937066316604614, ANN loss : 1.6443198919296265, Total loss : 171.01499938964844\n",
      "learning rate A :  tf.Tensor(9.829521e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1640 is 0.0768 sec\n",
      "train AE loss : 1.764174461364746, train ANN loss : 2.0473580360412598\n",
      "AE loss : 1.7013490200042725, ANN loss : 1.6428394317626953, Total loss : 171.77774047851562\n",
      "learning rate A :  tf.Tensor(9.829521e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1641 is 0.0763 sec\n",
      "train AE loss : 1.7720698118209839, train ANN loss : 2.0546982288360596\n",
      "AE loss : 1.6855677366256714, ANN loss : 1.6416302919387817, Total loss : 170.1984100341797\n",
      "learning rate A :  tf.Tensor(9.829314e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1642 is 0.0839 sec\n",
      "train AE loss : 1.7558132410049438, train ANN loss : 2.0564279556274414\n",
      "AE loss : 1.6703410148620605, ANN loss : 1.6404485702514648, Total loss : 168.674560546875\n",
      "learning rate A :  tf.Tensor(9.8291064e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1643 is 0.0745 sec\n",
      "train AE loss : 1.7401009798049927, train ANN loss : 2.0381064414978027\n",
      "AE loss : 1.6556402444839478, ANN loss : 1.6392858028411865, Total loss : 167.20330810546875\n",
      "learning rate A :  tf.Tensor(9.8289e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1644 is 0.0749 sec\n",
      "train AE loss : 1.724910020828247, train ANN loss : 2.037994384765625\n",
      "AE loss : 1.6414521932601929, ANN loss : 1.638153076171875, Total loss : 165.7833709716797\n",
      "learning rate A :  tf.Tensor(9.8286924e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1645 is 0.0749 sec\n",
      "train AE loss : 1.7102203369140625, train ANN loss : 2.0390305519104004\n",
      "AE loss : 1.648789644241333, ANN loss : 1.6299338340759277, Total loss : 166.5089111328125\n",
      "learning rate A :  tf.Tensor(9.8286924e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1646 is 0.0874 sec\n",
      "train AE loss : 1.7178356647491455, train ANN loss : 2.0297889709472656\n",
      "AE loss : 1.6613900661468506, ANN loss : 1.632138967514038, Total loss : 167.77113342285156\n",
      "learning rate A :  tf.Tensor(9.8286924e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1647 is 0.0772 sec\n",
      "train AE loss : 1.7311387062072754, train ANN loss : 2.0318264961242676\n",
      "AE loss : 1.6467838287353516, ANN loss : 1.6311039924621582, Total loss : 166.3094940185547\n",
      "learning rate A :  tf.Tensor(9.828486e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1648 is 0.0762 sec\n",
      "train AE loss : 1.7160040140151978, train ANN loss : 2.035087823867798\n",
      "AE loss : 1.6611108779907227, ANN loss : 1.6379570960998535, Total loss : 167.74905395507812\n",
      "learning rate A :  tf.Tensor(9.828486e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1649 is 0.0773 sec\n",
      "train AE loss : 1.7311831712722778, train ANN loss : 2.0332155227661133\n",
      "AE loss : 1.6771090030670166, ANN loss : 1.6420226097106934, Total loss : 169.35292053222656\n",
      "learning rate A :  tf.Tensor(9.828486e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1650 is 0.0780 sec\n",
      "train AE loss : 1.7481541633605957, train ANN loss : 2.0302038192749023\n",
      "AE loss : 1.6884115934371948, ANN loss : 1.6396523714065552, Total loss : 170.48081970214844\n",
      "learning rate A :  tf.Tensor(9.828486e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1651 is 0.0779 sec\n",
      "train AE loss : 1.7602050304412842, train ANN loss : 2.035402774810791\n",
      "AE loss : 1.6939400434494019, ANN loss : 1.6304347515106201, Total loss : 171.02444458007812\n",
      "learning rate A :  tf.Tensor(9.828486e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1652 is 0.0789 sec\n",
      "train AE loss : 1.7662380933761597, train ANN loss : 2.0331997871398926\n",
      "AE loss : 1.6780251264572144, ANN loss : 1.6292803287506104, Total loss : 169.43179321289062\n",
      "learning rate A :  tf.Tensor(9.8282784e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1653 is 0.0760 sec\n",
      "train AE loss : 1.7498328685760498, train ANN loss : 2.0242834091186523\n",
      "AE loss : 1.6827343702316284, ANN loss : 1.6280325651168823, Total loss : 169.90147399902344\n",
      "learning rate A :  tf.Tensor(9.8282784e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1654 is 0.0783 sec\n",
      "train AE loss : 1.7548058032989502, train ANN loss : 2.0524752140045166\n",
      "AE loss : 1.667126178741455, ANN loss : 1.6268904209136963, Total loss : 168.33950805664062\n",
      "learning rate A :  tf.Tensor(9.828071e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1655 is 0.0755 sec\n",
      "train AE loss : 1.7386891841888428, train ANN loss : 2.0260634422302246\n",
      "AE loss : 1.67570960521698, ANN loss : 1.6281530857086182, Total loss : 169.19911193847656\n",
      "learning rate A :  tf.Tensor(9.828071e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1656 is 0.0861 sec\n",
      "train AE loss : 1.7474843263626099, train ANN loss : 2.035942316055298\n",
      "AE loss : 1.6602551937103271, ANN loss : 1.6270068883895874, Total loss : 167.6525115966797\n",
      "learning rate A :  tf.Tensor(9.827864e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1657 is 0.0770 sec\n",
      "train AE loss : 1.7315400838851929, train ANN loss : 2.0349419116973877\n",
      "AE loss : 1.64537513256073, ANN loss : 1.625890851020813, Total loss : 166.1634063720703\n",
      "learning rate A :  tf.Tensor(9.827657e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1658 is 0.0756 sec\n",
      "train AE loss : 1.7161471843719482, train ANN loss : 2.0403621196746826\n",
      "AE loss : 1.6573548316955566, ANN loss : 1.6283740997314453, Total loss : 167.36386108398438\n",
      "learning rate A :  tf.Tensor(9.827657e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1659 is 0.0778 sec\n",
      "train AE loss : 1.7286603450775146, train ANN loss : 2.0246808528900146\n",
      "AE loss : 1.6425682306289673, ANN loss : 1.6272826194763184, Total loss : 165.88409423828125\n",
      "learning rate A :  tf.Tensor(9.82745e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1660 is 0.0761 sec\n",
      "train AE loss : 1.7133426666259766, train ANN loss : 2.0431063175201416\n",
      "AE loss : 1.6283042430877686, ANN loss : 1.6262110471725464, Total loss : 164.45663452148438\n",
      "learning rate A :  tf.Tensor(9.827243e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1661 is 0.0762 sec\n",
      "train AE loss : 1.69851815700531, train ANN loss : 2.035223960876465\n",
      "AE loss : 1.6448884010314941, ANN loss : 1.6316173076629639, Total loss : 166.12045288085938\n",
      "learning rate A :  tf.Tensor(9.827243e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1662 is 0.0777 sec\n",
      "train AE loss : 1.7161469459533691, train ANN loss : 2.0338969230651855\n",
      "AE loss : 1.6604870557785034, ANN loss : 1.6360913515090942, Total loss : 167.68479919433594\n",
      "learning rate A :  tf.Tensor(9.827243e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1663 is 0.0785 sec\n",
      "train AE loss : 1.7327417135238647, train ANN loss : 2.024951457977295\n",
      "AE loss : 1.6456971168518066, ANN loss : 1.6349437236785889, Total loss : 166.2046661376953\n",
      "learning rate A :  tf.Tensor(9.827036e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1664 is 0.0765 sec\n",
      "train AE loss : 1.7174378633499146, train ANN loss : 2.0443036556243896\n",
      "AE loss : 1.6586291790008545, ANN loss : 1.6342352628707886, Total loss : 167.4971466064453\n",
      "learning rate A :  tf.Tensor(9.827036e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1665 is 0.0772 sec\n",
      "train AE loss : 1.7311593294143677, train ANN loss : 2.0277841091156006\n",
      "AE loss : 1.6667633056640625, ANN loss : 1.6312006711959839, Total loss : 168.30752563476562\n",
      "learning rate A :  tf.Tensor(9.827036e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1666 is 0.0785 sec\n",
      "train AE loss : 1.7397189140319824, train ANN loss : 2.043811321258545\n",
      "AE loss : 1.6518020629882812, ANN loss : 1.6300511360168457, Total loss : 166.8102569580078\n",
      "learning rate A :  tf.Tensor(9.826828e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1667 is 0.0753 sec\n",
      "train AE loss : 1.7242804765701294, train ANN loss : 2.0203280448913574\n",
      "AE loss : 1.6582534313201904, ANN loss : 1.628153920173645, Total loss : 167.45350646972656\n",
      "learning rate A :  tf.Tensor(9.826828e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1668 is 0.0780 sec\n",
      "train AE loss : 1.7308613061904907, train ANN loss : 2.042273759841919\n",
      "AE loss : 1.6608092784881592, ANN loss : 1.62538480758667, Total loss : 167.70631408691406\n",
      "learning rate A :  tf.Tensor(9.826828e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1669 is 0.0786 sec\n",
      "train AE loss : 1.7331061363220215, train ANN loss : 2.0165398120880127\n",
      "AE loss : 1.6458224058151245, ANN loss : 1.6242759227752686, Total loss : 166.20652770996094\n",
      "learning rate A :  tf.Tensor(9.826622e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1670 is 0.0751 sec\n",
      "train AE loss : 1.7176209688186646, train ANN loss : 2.040808916091919\n",
      "AE loss : 1.6504508256912231, ANN loss : 1.629047155380249, Total loss : 166.67413330078125\n",
      "learning rate A :  tf.Tensor(9.826622e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1671 is 0.0781 sec\n",
      "train AE loss : 1.7218023538589478, train ANN loss : 2.0348780155181885\n",
      "AE loss : 1.6571499109268188, ANN loss : 1.634832501411438, Total loss : 167.34982299804688\n",
      "learning rate A :  tf.Tensor(9.826622e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1672 is 0.0783 sec\n",
      "train AE loss : 1.7283918857574463, train ANN loss : 2.026541233062744\n",
      "AE loss : 1.642096757888794, ANN loss : 1.6336939334869385, Total loss : 165.84335327148438\n",
      "learning rate A :  tf.Tensor(9.826415e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1673 is 0.0760 sec\n",
      "train AE loss : 1.7128316164016724, train ANN loss : 2.034276008605957\n",
      "AE loss : 1.6276047229766846, ANN loss : 1.6325863599777222, Total loss : 164.39305114746094\n",
      "learning rate A :  tf.Tensor(9.826208e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1674 is 0.0758 sec\n",
      "train AE loss : 1.697817087173462, train ANN loss : 2.026764392852783\n",
      "AE loss : 1.6432263851165771, ANN loss : 1.6324814558029175, Total loss : 165.95510864257812\n",
      "learning rate A :  tf.Tensor(9.826208e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1675 is 0.0786 sec\n",
      "train AE loss : 1.7139956951141357, train ANN loss : 2.0287182331085205\n",
      "AE loss : 1.6576892137527466, ANN loss : 1.6317194700241089, Total loss : 167.400634765625\n",
      "learning rate A :  tf.Tensor(9.826208e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1676 is 0.0775 sec\n",
      "train AE loss : 1.7289049625396729, train ANN loss : 2.023573637008667\n",
      "AE loss : 1.6428567171096802, ANN loss : 1.6305413246154785, Total loss : 165.91619873046875\n",
      "learning rate A :  tf.Tensor(9.826001e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1677 is 0.0760 sec\n",
      "train AE loss : 1.7136062383651733, train ANN loss : 2.027431011199951\n",
      "AE loss : 1.6523385047912598, ANN loss : 1.6297101974487305, Total loss : 166.8635711669922\n",
      "learning rate A :  tf.Tensor(9.826001e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1678 is 0.0783 sec\n",
      "train AE loss : 1.7234997749328613, train ANN loss : 2.031116485595703\n",
      "AE loss : 1.6564674377441406, ANN loss : 1.625645399093628, Total loss : 167.2723846435547\n",
      "learning rate A :  tf.Tensor(9.826001e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1679 is 0.0776 sec\n",
      "train AE loss : 1.7277991771697998, train ANN loss : 2.0210185050964355\n",
      "AE loss : 1.6608970165252686, ANN loss : 1.6250935792922974, Total loss : 167.7147979736328\n",
      "learning rate A :  tf.Tensor(9.826001e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1680 is 0.0788 sec\n",
      "train AE loss : 1.7323405742645264, train ANN loss : 2.0199389457702637\n",
      "AE loss : 1.6679601669311523, ANN loss : 1.6206835508346558, Total loss : 168.4167022705078\n",
      "learning rate A :  tf.Tensor(9.826001e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1681 is 0.0883 sec\n",
      "train AE loss : 1.7394771575927734, train ANN loss : 2.0355160236358643\n",
      "AE loss : 1.6527386903762817, ANN loss : 1.6195462942123413, Total loss : 166.89341735839844\n",
      "learning rate A :  tf.Tensor(9.825793e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1682 is 0.0749 sec\n",
      "train AE loss : 1.7237908840179443, train ANN loss : 2.0136682987213135\n",
      "AE loss : 1.6629457473754883, ANN loss : 1.6239376068115234, Total loss : 167.9185028076172\n",
      "learning rate A :  tf.Tensor(9.825793e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1683 is 0.0762 sec\n",
      "train AE loss : 1.7341140508651733, train ANN loss : 2.0210299491882324\n",
      "AE loss : 1.6478047370910645, ANN loss : 1.6227784156799316, Total loss : 166.40325927734375\n",
      "learning rate A :  tf.Tensor(9.825586e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1684 is 0.0743 sec\n",
      "train AE loss : 1.7185068130493164, train ANN loss : 2.025630235671997\n",
      "AE loss : 1.6611851453781128, ANN loss : 1.6241273880004883, Total loss : 167.74264526367188\n",
      "learning rate A :  tf.Tensor(9.825586e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1685 is 0.0765 sec\n",
      "train AE loss : 1.7324320077896118, train ANN loss : 2.020796060562134\n",
      "AE loss : 1.6461491584777832, ANN loss : 1.6229548454284668, Total loss : 166.2378692626953\n",
      "learning rate A :  tf.Tensor(9.82538e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1686 is 0.0741 sec\n",
      "train AE loss : 1.716946005821228, train ANN loss : 2.022609233856201\n",
      "AE loss : 1.631624460220337, ANN loss : 1.6218018531799316, Total loss : 164.78424072265625\n",
      "learning rate A :  tf.Tensor(9.825172e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1687 is 0.0750 sec\n",
      "train AE loss : 1.7019662857055664, train ANN loss : 2.0026655197143555\n",
      "AE loss : 1.6469597816467285, ANN loss : 1.6265602111816406, Total loss : 166.3225555419922\n",
      "learning rate A :  tf.Tensor(9.825172e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1688 is 0.0771 sec\n",
      "train AE loss : 1.7178868055343628, train ANN loss : 2.023547887802124\n",
      "AE loss : 1.6577649116516113, ANN loss : 1.6267393827438354, Total loss : 167.40322875976562\n",
      "learning rate A :  tf.Tensor(9.825172e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1689 is 0.0772 sec\n",
      "train AE loss : 1.7289767265319824, train ANN loss : 2.020437717437744\n",
      "AE loss : 1.6611781120300293, ANN loss : 1.6270393133163452, Total loss : 167.74485778808594\n",
      "learning rate A :  tf.Tensor(9.825172e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1690 is 0.0766 sec\n",
      "train AE loss : 1.732439637184143, train ANN loss : 2.0222902297973633\n",
      "AE loss : 1.6460943222045898, ANN loss : 1.6258472204208374, Total loss : 166.23529052734375\n",
      "learning rate A :  tf.Tensor(9.824966e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1691 is 0.0733 sec\n",
      "train AE loss : 1.7169420719146729, train ANN loss : 2.0216565132141113\n",
      "AE loss : 1.6463903188705444, ANN loss : 1.6185364723205566, Total loss : 166.25755310058594\n",
      "learning rate A :  tf.Tensor(9.824966e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1692 is 0.0772 sec\n",
      "train AE loss : 1.7172329425811768, train ANN loss : 2.0157864093780518\n",
      "AE loss : 1.648514747619629, ANN loss : 1.6170828342437744, Total loss : 166.4685516357422\n",
      "learning rate A :  tf.Tensor(9.824966e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1693 is 0.0880 sec\n",
      "train AE loss : 1.7192881107330322, train ANN loss : 2.030163049697876\n",
      "AE loss : 1.6335967779159546, ANN loss : 1.6159683465957642, Total loss : 164.97564697265625\n",
      "learning rate A :  tf.Tensor(9.824758e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1694 is 0.0734 sec\n",
      "train AE loss : 1.7038955688476562, train ANN loss : 2.0358946323394775\n",
      "AE loss : 1.6452592611312866, ANN loss : 1.622588872909546, Total loss : 166.1485137939453\n",
      "learning rate A :  tf.Tensor(9.824758e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1695 is 0.0774 sec\n",
      "train AE loss : 1.7159284353256226, train ANN loss : 2.016221284866333\n",
      "AE loss : 1.6599918603897095, ANN loss : 1.6202269792556763, Total loss : 167.61941528320312\n",
      "learning rate A :  tf.Tensor(9.824758e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1696 is 0.0771 sec\n",
      "train AE loss : 1.7314974069595337, train ANN loss : 2.0143160820007324\n",
      "AE loss : 1.6760530471801758, ANN loss : 1.6212120056152344, Total loss : 169.2265167236328\n",
      "learning rate A :  tf.Tensor(9.824758e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1697 is 0.0759 sec\n",
      "train AE loss : 1.7484418153762817, train ANN loss : 2.0143227577209473\n",
      "AE loss : 1.6913501024246216, ANN loss : 1.62740159034729, Total loss : 170.7624053955078\n",
      "learning rate A :  tf.Tensor(9.824758e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1698 is 0.0762 sec\n",
      "train AE loss : 1.7641843557357788, train ANN loss : 2.0259971618652344\n",
      "AE loss : 1.7006464004516602, ANN loss : 1.6315146684646606, Total loss : 171.69615173339844\n",
      "learning rate A :  tf.Tensor(9.824758e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1699 is 0.0782 sec\n",
      "train AE loss : 1.7737176418304443, train ANN loss : 2.029712677001953\n",
      "AE loss : 1.701243281364441, ANN loss : 1.6233826875686646, Total loss : 171.74771118164062\n",
      "learning rate A :  tf.Tensor(9.824758e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1700 is 0.0759 sec\n",
      "train AE loss : 1.7745224237442017, train ANN loss : 2.0210750102996826\n",
      "AE loss : 1.698109745979309, ANN loss : 1.6106901168823242, Total loss : 171.42166137695312\n",
      "learning rate A :  tf.Tensor(9.824758e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1701 is 0.0773 sec\n",
      "train AE loss : 1.771610140800476, train ANN loss : 2.014145612716675\n",
      "AE loss : 1.7060116529464722, ANN loss : 1.6089279651641846, Total loss : 172.21009826660156\n",
      "learning rate A :  tf.Tensor(9.824758e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1702 is 0.0772 sec\n",
      "train AE loss : 1.779974102973938, train ANN loss : 2.013288736343384\n",
      "AE loss : 1.688551664352417, ANN loss : 1.6077855825424194, Total loss : 170.46295166015625\n",
      "learning rate A :  tf.Tensor(9.824551e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1703 is 0.0749 sec\n",
      "train AE loss : 1.7620294094085693, train ANN loss : 2.0154097080230713\n",
      "AE loss : 1.702512502670288, ANN loss : 1.617990255355835, Total loss : 171.86924743652344\n",
      "learning rate A :  tf.Tensor(9.824551e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1704 is 0.0770 sec\n",
      "train AE loss : 1.7765369415283203, train ANN loss : 2.023627758026123\n",
      "AE loss : 1.685246229171753, ANN loss : 1.6168208122253418, Total loss : 170.1414337158203\n",
      "learning rate A :  tf.Tensor(9.824344e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1705 is 0.0746 sec\n",
      "train AE loss : 1.7587928771972656, train ANN loss : 2.020878314971924\n",
      "AE loss : 1.704460620880127, ANN loss : 1.617213249206543, Total loss : 172.06326293945312\n",
      "learning rate A :  tf.Tensor(9.824344e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1706 is 0.0759 sec\n",
      "train AE loss : 1.778518795967102, train ANN loss : 2.027918577194214\n",
      "AE loss : 1.687248945236206, ANN loss : 1.6160273551940918, Total loss : 170.34092712402344\n",
      "learning rate A :  tf.Tensor(9.824138e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1707 is 0.0742 sec\n",
      "train AE loss : 1.7608897686004639, train ANN loss : 2.0240237712860107\n",
      "AE loss : 1.6706703901290894, ANN loss : 1.6148717403411865, Total loss : 168.68190002441406\n",
      "learning rate A :  tf.Tensor(9.82393e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1708 is 0.0745 sec\n",
      "train AE loss : 1.7438689470291138, train ANN loss : 2.006789207458496\n",
      "AE loss : 1.6546993255615234, ANN loss : 1.613738775253296, Total loss : 167.08367919921875\n",
      "learning rate A :  tf.Tensor(9.823723e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1709 is 0.0739 sec\n",
      "train AE loss : 1.7274330854415894, train ANN loss : 2.017307996749878\n",
      "AE loss : 1.6773186922073364, ANN loss : 1.6190779209136963, Total loss : 169.35093688964844\n",
      "learning rate A :  tf.Tensor(9.823723e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1710 is 0.0767 sec\n",
      "train AE loss : 1.7503457069396973, train ANN loss : 2.0345635414123535\n",
      "AE loss : 1.6611889600753784, ANN loss : 1.6178932189941406, Total loss : 167.73678588867188\n",
      "learning rate A :  tf.Tensor(9.8235156e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1711 is 0.0743 sec\n",
      "train AE loss : 1.7338005304336548, train ANN loss : 2.011925458908081\n",
      "AE loss : 1.6456565856933594, ANN loss : 1.6167404651641846, Total loss : 166.18240356445312\n",
      "learning rate A :  tf.Tensor(9.823308e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1712 is 0.0745 sec\n",
      "train AE loss : 1.7178480625152588, train ANN loss : 2.0069355964660645\n",
      "AE loss : 1.6306946277618408, ANN loss : 1.6156195402145386, Total loss : 164.68507385253906\n",
      "learning rate A :  tf.Tensor(9.8231016e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1713 is 0.0755 sec\n",
      "train AE loss : 1.7024401426315308, train ANN loss : 2.020613670349121\n",
      "AE loss : 1.6505320072174072, ANN loss : 1.6201287508010864, Total loss : 166.67333984375\n",
      "learning rate A :  tf.Tensor(9.8231016e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1714 is 0.0780 sec\n",
      "train AE loss : 1.722365379333496, train ANN loss : 2.0105550289154053\n",
      "AE loss : 1.6353280544281006, ANN loss : 1.6189109086990356, Total loss : 165.15171813964844\n",
      "learning rate A :  tf.Tensor(9.822895e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1715 is 0.0765 sec\n",
      "train AE loss : 1.7067322731018066, train ANN loss : 2.0111780166625977\n",
      "AE loss : 1.6488364934921265, ANN loss : 1.625140905380249, Total loss : 166.5087890625\n",
      "learning rate A :  tf.Tensor(9.822895e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1716 is 0.0780 sec\n",
      "train AE loss : 1.7205232381820679, train ANN loss : 2.02117919921875\n",
      "AE loss : 1.633640170097351, ANN loss : 1.623887300491333, Total loss : 164.98789978027344\n",
      "learning rate A :  tf.Tensor(9.8226876e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1717 is 0.0771 sec\n",
      "train AE loss : 1.7048869132995605, train ANN loss : 2.023175001144409\n",
      "AE loss : 1.6189779043197632, ANN loss : 1.6226636171340942, Total loss : 163.5204620361328\n",
      "learning rate A :  tf.Tensor(9.822481e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1718 is 0.0747 sec\n",
      "train AE loss : 1.6898000240325928, train ANN loss : 2.027554512023926\n",
      "AE loss : 1.6048318147659302, ANN loss : 1.621474027633667, Total loss : 162.1046600341797\n",
      "learning rate A :  tf.Tensor(9.8222736e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1719 is 0.0753 sec\n",
      "train AE loss : 1.6752114295959473, train ANN loss : 2.012200355529785\n",
      "AE loss : 1.5911585092544556, ANN loss : 1.6203047037124634, Total loss : 160.73614501953125\n",
      "learning rate A :  tf.Tensor(9.822067e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1720 is 0.0772 sec\n",
      "train AE loss : 1.6610783338546753, train ANN loss : 2.013035535812378\n",
      "AE loss : 1.6026043891906738, ANN loss : 1.6243785619735718, Total loss : 161.8848114013672\n",
      "learning rate A :  tf.Tensor(9.822067e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1721 is 0.0776 sec\n",
      "train AE loss : 1.6731215715408325, train ANN loss : 2.0235753059387207\n",
      "AE loss : 1.5890460014343262, ANN loss : 1.6232320070266724, Total loss : 160.52783203125\n",
      "learning rate A :  tf.Tensor(9.82186e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1722 is 0.0772 sec\n",
      "train AE loss : 1.6590943336486816, train ANN loss : 2.0123212337493896\n",
      "AE loss : 1.6035300493240356, ANN loss : 1.624097466468811, Total loss : 161.97711181640625\n",
      "learning rate A :  tf.Tensor(9.82186e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1723 is 0.0802 sec\n",
      "train AE loss : 1.6742750406265259, train ANN loss : 2.0189778804779053\n",
      "AE loss : 1.5899895429611206, ANN loss : 1.622934103012085, Total loss : 160.62188720703125\n",
      "learning rate A :  tf.Tensor(9.821653e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1724 is 0.0762 sec\n",
      "train AE loss : 1.6602710485458374, train ANN loss : 2.018542528152466\n",
      "AE loss : 1.5769308805465698, ANN loss : 1.6217995882034302, Total loss : 159.3148956298828\n",
      "learning rate A :  tf.Tensor(9.8214456e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1725 is 0.0757 sec\n",
      "train AE loss : 1.6467361450195312, train ANN loss : 2.0102038383483887\n",
      "AE loss : 1.5897516012191772, ANN loss : 1.6225745677947998, Total loss : 160.5977325439453\n",
      "learning rate A :  tf.Tensor(9.8214456e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1726 is 0.0775 sec\n",
      "train AE loss : 1.6603002548217773, train ANN loss : 2.0025017261505127\n",
      "AE loss : 1.5767308473587036, ANN loss : 1.621445894241333, Total loss : 159.29452514648438\n",
      "learning rate A :  tf.Tensor(9.821239e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1727 is 0.0836 sec\n",
      "train AE loss : 1.6468334197998047, train ANN loss : 2.0019192695617676\n",
      "AE loss : 1.5880179405212402, ANN loss : 1.6165837049484253, Total loss : 160.4183807373047\n",
      "learning rate A :  tf.Tensor(9.821239e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1728 is 0.0799 sec\n",
      "train AE loss : 1.6585209369659424, train ANN loss : 2.018364191055298\n",
      "AE loss : 1.6000392436981201, ANN loss : 1.6157444715499878, Total loss : 161.61965942382812\n",
      "learning rate A :  tf.Tensor(9.821239e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1729 is 0.0787 sec\n",
      "train AE loss : 1.6705996990203857, train ANN loss : 2.0059776306152344\n",
      "AE loss : 1.6087419986724854, ANN loss : 1.611806035041809, Total loss : 162.4860076904297\n",
      "learning rate A :  tf.Tensor(9.821239e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1730 is 0.0769 sec\n",
      "train AE loss : 1.6794443130493164, train ANN loss : 2.0231781005859375\n",
      "AE loss : 1.5945991277694702, ANN loss : 1.6106576919555664, Total loss : 161.07057189941406\n",
      "learning rate A :  tf.Tensor(9.821032e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1731 is 0.0757 sec\n",
      "train AE loss : 1.6648937463760376, train ANN loss : 2.0064680576324463\n",
      "AE loss : 1.6010749340057373, ANN loss : 1.607870101928711, Total loss : 161.7153778076172\n",
      "learning rate A :  tf.Tensor(9.821032e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1732 is 0.0784 sec\n",
      "train AE loss : 1.671834111213684, train ANN loss : 2.0015430450439453\n",
      "AE loss : 1.614405632019043, ANN loss : 1.6060395240783691, Total loss : 163.04660034179688\n",
      "learning rate A :  tf.Tensor(9.821032e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1733 is 0.0774 sec\n",
      "train AE loss : 1.685866117477417, train ANN loss : 2.0193488597869873\n",
      "AE loss : 1.600009799003601, ANN loss : 1.6049567461013794, Total loss : 161.60592651367188\n",
      "learning rate A :  tf.Tensor(9.820825e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1734 is 0.0835 sec\n",
      "train AE loss : 1.6710373163223267, train ANN loss : 2.0164108276367188\n",
      "AE loss : 1.5861490964889526, ANN loss : 1.6038987636566162, Total loss : 160.21881103515625\n",
      "learning rate A :  tf.Tensor(9.820618e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1735 is 0.0767 sec\n",
      "train AE loss : 1.6567178964614868, train ANN loss : 2.0170719623565674\n",
      "AE loss : 1.603933572769165, ANN loss : 1.6078623533248901, Total loss : 162.00120544433594\n",
      "learning rate A :  tf.Tensor(9.820618e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1736 is 0.0773 sec\n",
      "train AE loss : 1.675322413444519, train ANN loss : 2.0236268043518066\n",
      "AE loss : 1.5900557041168213, ANN loss : 1.6067616939544678, Total loss : 160.61233520507812\n",
      "learning rate A :  tf.Tensor(9.820412e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1737 is 0.0759 sec\n",
      "train AE loss : 1.661016583442688, train ANN loss : 2.0042524337768555\n",
      "AE loss : 1.609521746635437, ANN loss : 1.6141282320022583, Total loss : 162.56629943847656\n",
      "learning rate A :  tf.Tensor(9.820412e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1738 is 0.0775 sec\n",
      "train AE loss : 1.6812559366226196, train ANN loss : 2.016279935836792\n",
      "AE loss : 1.5956023931503296, ANN loss : 1.6129759550094604, Total loss : 161.17323303222656\n",
      "learning rate A :  tf.Tensor(9.820204e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1739 is 0.0751 sec\n",
      "train AE loss : 1.6668779850006104, train ANN loss : 1.9902756214141846\n",
      "AE loss : 1.61122727394104, ANN loss : 1.617113471031189, Total loss : 162.73985290527344\n",
      "learning rate A :  tf.Tensor(9.820204e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1740 is 0.0765 sec\n",
      "train AE loss : 1.683234691619873, train ANN loss : 2.0188381671905518\n",
      "AE loss : 1.5973514318466187, ANN loss : 1.6159754991531372, Total loss : 161.3511199951172\n",
      "learning rate A :  tf.Tensor(9.819998e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1741 is 0.0752 sec\n",
      "train AE loss : 1.6689000129699707, train ANN loss : 1.999564528465271\n",
      "AE loss : 1.5839754343032837, ANN loss : 1.6148649454116821, Total loss : 160.01239013671875\n",
      "learning rate A :  tf.Tensor(9.81979e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1742 is 0.0752 sec\n",
      "train AE loss : 1.6550620794296265, train ANN loss : 2.0000646114349365\n",
      "AE loss : 1.5710828304290771, ANN loss : 1.6137775182724, Total loss : 158.72206115722656\n",
      "learning rate A :  tf.Tensor(9.819584e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1743 is 0.0749 sec\n",
      "train AE loss : 1.6417059898376465, train ANN loss : 2.0140700340270996\n",
      "AE loss : 1.5846385955810547, ANN loss : 1.6146982908248901, Total loss : 160.0785675048828\n",
      "learning rate A :  tf.Tensor(9.819584e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1744 is 0.0785 sec\n",
      "train AE loss : 1.6559042930603027, train ANN loss : 2.010258436203003\n",
      "AE loss : 1.5943809747695923, ANN loss : 1.6154232025146484, Total loss : 161.0535125732422\n",
      "learning rate A :  tf.Tensor(9.819584e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1745 is 0.0780 sec\n",
      "train AE loss : 1.6659220457077026, train ANN loss : 2.0125832557678223\n",
      "AE loss : 1.601855993270874, ANN loss : 1.6151241064071655, Total loss : 161.8007049560547\n",
      "learning rate A :  tf.Tensor(9.819584e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1746 is 0.1188 sec\n",
      "train AE loss : 1.6735515594482422, train ANN loss : 2.0244054794311523\n",
      "AE loss : 1.605376958847046, ANN loss : 1.6108734607696533, Total loss : 162.14857482910156\n",
      "learning rate A :  tf.Tensor(9.819584e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1747 is 0.0782 sec\n",
      "train AE loss : 1.677471399307251, train ANN loss : 2.0106160640716553\n",
      "AE loss : 1.5915725231170654, ANN loss : 1.6097259521484375, Total loss : 160.76698303222656\n",
      "learning rate A :  tf.Tensor(9.819377e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1748 is 0.0838 sec\n",
      "train AE loss : 1.6631983518600464, train ANN loss : 1.998237133026123\n",
      "AE loss : 1.5783147811889648, ANN loss : 1.608618140220642, Total loss : 159.44009399414062\n",
      "learning rate A :  tf.Tensor(9.81917e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1749 is 0.0848 sec\n",
      "train AE loss : 1.6494948863983154, train ANN loss : 2.0077106952667236\n",
      "AE loss : 1.5864064693450928, ANN loss : 1.6075876951217651, Total loss : 160.2482452392578\n",
      "learning rate A :  tf.Tensor(9.81917e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1750 is 0.0759 sec\n",
      "train AE loss : 1.6581006050109863, train ANN loss : 2.0085885524749756\n",
      "AE loss : 1.573283314704895, ANN loss : 1.606519103050232, Total loss : 158.9348602294922\n",
      "learning rate A :  tf.Tensor(9.818963e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1751 is 0.0743 sec\n",
      "train AE loss : 1.6445236206054688, train ANN loss : 2.0140838623046875\n",
      "AE loss : 1.5928528308868408, ANN loss : 1.6102097034454346, Total loss : 160.89547729492188\n",
      "learning rate A :  tf.Tensor(9.818963e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1752 is 0.0764 sec\n",
      "train AE loss : 1.6648353338241577, train ANN loss : 2.0061495304107666\n",
      "AE loss : 1.5794434547424316, ANN loss : 1.609063982963562, Total loss : 159.55340576171875\n",
      "learning rate A :  tf.Tensor(9.818756e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1753 is 0.0743 sec\n",
      "train AE loss : 1.6509568691253662, train ANN loss : 2.004793167114258\n",
      "AE loss : 1.5665533542633057, ANN loss : 1.6079524755477905, Total loss : 158.26327514648438\n",
      "learning rate A :  tf.Tensor(9.818549e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1754 is 0.0746 sec\n",
      "train AE loss : 1.6375881433486938, train ANN loss : 1.9992077350616455\n",
      "AE loss : 1.5541541576385498, ANN loss : 1.6068722009658813, Total loss : 157.0222930908203\n",
      "learning rate A :  tf.Tensor(9.8183424e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1755 is 0.0748 sec\n",
      "train AE loss : 1.6247119903564453, train ANN loss : 1.9972370862960815\n",
      "AE loss : 1.5736464262008667, ANN loss : 1.6135951280593872, Total loss : 158.97824096679688\n",
      "learning rate A :  tf.Tensor(9.8183424e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1756 is 0.0753 sec\n",
      "train AE loss : 1.6449793577194214, train ANN loss : 2.0015788078308105\n",
      "AE loss : 1.5609171390533447, ANN loss : 1.6124478578567505, Total loss : 157.70416259765625\n",
      "learning rate A :  tf.Tensor(9.818135e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1757 is 0.0838 sec\n",
      "train AE loss : 1.631779432296753, train ANN loss : 2.000403881072998\n",
      "AE loss : 1.577811598777771, ANN loss : 1.6104241609573364, Total loss : 159.39158630371094\n",
      "learning rate A :  tf.Tensor(9.818135e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1758 is 0.0774 sec\n",
      "train AE loss : 1.649278998374939, train ANN loss : 2.0142576694488525\n",
      "AE loss : 1.5649110078811646, ANN loss : 1.6093149185180664, Total loss : 158.1004180908203\n",
      "learning rate A :  tf.Tensor(9.8179284e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1759 is 0.0742 sec\n",
      "train AE loss : 1.6359225511550903, train ANN loss : 2.0046229362487793\n",
      "AE loss : 1.5748907327651978, ANN loss : 1.6118272542953491, Total loss : 159.1009063720703\n",
      "learning rate A :  tf.Tensor(9.8179284e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1760 is 0.0756 sec\n",
      "train AE loss : 1.6462018489837646, train ANN loss : 2.020895004272461\n",
      "AE loss : 1.5823640823364258, ANN loss : 1.610477089881897, Total loss : 159.8468780517578\n",
      "learning rate A :  tf.Tensor(9.8179284e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1761 is 0.0779 sec\n",
      "train AE loss : 1.6536282300949097, train ANN loss : 2.012688398361206\n",
      "AE loss : 1.5690851211547852, ANN loss : 1.609376311302185, Total loss : 158.51788330078125\n",
      "learning rate A :  tf.Tensor(9.817722e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1762 is 0.0741 sec\n",
      "train AE loss : 1.6398999691009521, train ANN loss : 2.001624345779419\n",
      "AE loss : 1.5563093423843384, ANN loss : 1.6083011627197266, Total loss : 157.23922729492188\n",
      "learning rate A :  tf.Tensor(9.817515e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1763 is 0.0739 sec\n",
      "train AE loss : 1.626660704612732, train ANN loss : 1.9917685985565186\n",
      "AE loss : 1.5595148801803589, ANN loss : 1.6044232845306396, Total loss : 157.555908203125\n",
      "learning rate A :  tf.Tensor(9.817515e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1764 is 0.0755 sec\n",
      "train AE loss : 1.629714012145996, train ANN loss : 2.011131763458252\n",
      "AE loss : 1.5469812154769897, ANN loss : 1.6033482551574707, Total loss : 156.30148315429688\n",
      "learning rate A :  tf.Tensor(9.817308e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1765 is 0.0748 sec\n",
      "train AE loss : 1.6167082786560059, train ANN loss : 2.0089919567108154\n",
      "AE loss : 1.551532506942749, ANN loss : 1.5948632955551147, Total loss : 156.74810791015625\n",
      "learning rate A :  tf.Tensor(9.817308e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1766 is 0.0771 sec\n",
      "train AE loss : 1.6214125156402588, train ANN loss : 2.0006444454193115\n",
      "AE loss : 1.5607179403305054, ANN loss : 1.596028208732605, Total loss : 157.66783142089844\n",
      "learning rate A :  tf.Tensor(9.817308e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1767 is 0.0765 sec\n",
      "train AE loss : 1.6310275793075562, train ANN loss : 2.0000760555267334\n",
      "AE loss : 1.5712553262710571, ANN loss : 1.6024831533432007, Total loss : 158.72801208496094\n",
      "learning rate A :  tf.Tensor(9.817308e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1768 is 0.0755 sec\n",
      "train AE loss : 1.6418635845184326, train ANN loss : 1.993451714515686\n",
      "AE loss : 1.5783339738845825, ANN loss : 1.6076308488845825, Total loss : 159.44102478027344\n",
      "learning rate A :  tf.Tensor(9.817308e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1769 is 0.0759 sec\n",
      "train AE loss : 1.6488759517669678, train ANN loss : 1.9872660636901855\n",
      "AE loss : 1.565242886543274, ANN loss : 1.6064218282699585, Total loss : 158.13072204589844\n",
      "learning rate A :  tf.Tensor(9.817101e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1770 is 0.0749 sec\n",
      "train AE loss : 1.6353000402450562, train ANN loss : 2.0041210651397705\n",
      "AE loss : 1.5710681676864624, ANN loss : 1.6088128089904785, Total loss : 158.7156219482422\n",
      "learning rate A :  tf.Tensor(9.817101e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1771 is 0.0762 sec\n",
      "train AE loss : 1.6409895420074463, train ANN loss : 2.007798433303833\n",
      "AE loss : 1.5732473134994507, ANN loss : 1.6020632982254028, Total loss : 158.9268035888672\n",
      "learning rate A :  tf.Tensor(9.817101e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1772 is 0.0758 sec\n",
      "train AE loss : 1.6432121992111206, train ANN loss : 1.9802043437957764\n",
      "AE loss : 1.5603207349777222, ANN loss : 1.6008672714233398, Total loss : 157.6329345703125\n",
      "learning rate A :  tf.Tensor(9.8168945e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1773 is 0.0746 sec\n",
      "train AE loss : 1.6298233270645142, train ANN loss : 2.012066602706909\n",
      "AE loss : 1.5656027793884277, ANN loss : 1.6006617546081543, Total loss : 158.1609344482422\n",
      "learning rate A :  tf.Tensor(9.8168945e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1774 is 0.0771 sec\n",
      "train AE loss : 1.635475754737854, train ANN loss : 2.0020840167999268\n",
      "AE loss : 1.553025245666504, ANN loss : 1.5995545387268066, Total loss : 156.90206909179688\n",
      "learning rate A :  tf.Tensor(9.816688e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1775 is 0.0740 sec\n",
      "train AE loss : 1.6224209070205688, train ANN loss : 2.0056159496307373\n",
      "AE loss : 1.5629602670669556, ANN loss : 1.6094180345535278, Total loss : 157.90542602539062\n",
      "learning rate A :  tf.Tensor(9.816688e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1776 is 0.0770 sec\n",
      "train AE loss : 1.6325701475143433, train ANN loss : 1.9998455047607422\n",
      "AE loss : 1.5728172063827515, ANN loss : 1.6023300886154175, Total loss : 158.88404846191406\n",
      "learning rate A :  tf.Tensor(9.816688e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1777 is 0.0762 sec\n",
      "train AE loss : 1.642756462097168, train ANN loss : 2.0244951248168945\n",
      "AE loss : 1.5600521564483643, ANN loss : 1.601199746131897, Total loss : 157.60641479492188\n",
      "learning rate A :  tf.Tensor(9.8164805e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1778 is 0.0740 sec\n",
      "train AE loss : 1.629530906677246, train ANN loss : 2.014491319656372\n",
      "AE loss : 1.5477734804153442, ANN loss : 1.6001033782958984, Total loss : 156.37745666503906\n",
      "learning rate A :  tf.Tensor(9.816274e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1779 is 0.0752 sec\n",
      "train AE loss : 1.616790533065796, train ANN loss : 2.0030956268310547\n",
      "AE loss : 1.5582973957061768, ANN loss : 1.604468822479248, Total loss : 157.4342041015625\n",
      "learning rate A :  tf.Tensor(9.816274e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1780 is 0.0771 sec\n",
      "train AE loss : 1.627514123916626, train ANN loss : 2.0059545040130615\n",
      "AE loss : 1.5460784435272217, ANN loss : 1.6033616065979004, Total loss : 156.21121215820312\n",
      "learning rate A :  tf.Tensor(9.816067e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1781 is 0.0745 sec\n",
      "train AE loss : 1.6148278713226318, train ANN loss : 2.0233817100524902\n",
      "AE loss : 1.5343135595321655, ANN loss : 1.6022840738296509, Total loss : 155.03363037109375\n",
      "learning rate A :  tf.Tensor(9.81586e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1782 is 0.0755 sec\n",
      "train AE loss : 1.6025995016098022, train ANN loss : 2.0036849975585938\n",
      "AE loss : 1.5229932069778442, ANN loss : 1.601235032081604, Total loss : 153.9005584716797\n",
      "learning rate A :  tf.Tensor(9.815653e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1783 is 0.0756 sec\n",
      "train AE loss : 1.590809941291809, train ANN loss : 2.0050363540649414\n",
      "AE loss : 1.53441321849823, ANN loss : 1.601011872291565, Total loss : 155.04232788085938\n",
      "learning rate A :  tf.Tensor(9.815653e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1784 is 0.0768 sec\n",
      "train AE loss : 1.6024487018585205, train ANN loss : 2.007845401763916\n",
      "AE loss : 1.5441887378692627, ANN loss : 1.605043888092041, Total loss : 156.02392578125\n",
      "learning rate A :  tf.Tensor(9.815653e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1785 is 0.0774 sec\n",
      "train AE loss : 1.6124581098556519, train ANN loss : 2.0187745094299316\n",
      "AE loss : 1.5526165962219238, ANN loss : 1.606134295463562, Total loss : 156.8677978515625\n",
      "learning rate A :  tf.Tensor(9.815653e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1786 is 0.0776 sec\n",
      "train AE loss : 1.6212810277938843, train ANN loss : 1.997572660446167\n",
      "AE loss : 1.5606352090835571, ANN loss : 1.6005200147628784, Total loss : 157.66404724121094\n",
      "learning rate A :  tf.Tensor(9.815653e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1787 is 0.0774 sec\n",
      "train AE loss : 1.6298415660858154, train ANN loss : 1.9914700984954834\n",
      "AE loss : 1.5712162256240845, ANN loss : 1.6012730598449707, Total loss : 158.722900390625\n",
      "learning rate A :  tf.Tensor(9.815653e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1788 is 0.0775 sec\n",
      "train AE loss : 1.6409974098205566, train ANN loss : 2.000527858734131\n",
      "AE loss : 1.5582064390182495, ANN loss : 1.600070834159851, Total loss : 157.42071533203125\n",
      "learning rate A :  tf.Tensor(9.8154465e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1789 is 0.0751 sec\n",
      "train AE loss : 1.6274969577789307, train ANN loss : 2.0032849311828613\n",
      "AE loss : 1.5671803951263428, ANN loss : 1.5986937284469604, Total loss : 158.31674194335938\n",
      "learning rate A :  tf.Tensor(9.8154465e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1790 is 0.0779 sec\n",
      "train AE loss : 1.636973261833191, train ANN loss : 2.0117785930633545\n",
      "AE loss : 1.5543608665466309, ANN loss : 1.5974754095077515, Total loss : 157.03355407714844\n",
      "learning rate A :  tf.Tensor(9.81524e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1791 is 0.0783 sec\n",
      "train AE loss : 1.6236603260040283, train ANN loss : 1.9923819303512573\n",
      "AE loss : 1.5420470237731934, ANN loss : 1.5962895154953003, Total loss : 155.8009796142578\n",
      "learning rate A :  tf.Tensor(9.8150325e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1792 is 0.0760 sec\n",
      "train AE loss : 1.6108418703079224, train ANN loss : 1.9971792697906494\n",
      "AE loss : 1.5489239692687988, ANN loss : 1.5986486673355103, Total loss : 156.4910430908203\n",
      "learning rate A :  tf.Tensor(9.8150325e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1793 is 0.0779 sec\n",
      "train AE loss : 1.618131160736084, train ANN loss : 2.00431227684021\n",
      "AE loss : 1.5368592739105225, ANN loss : 1.597494125366211, Total loss : 155.28341674804688\n",
      "learning rate A :  tf.Tensor(9.814826e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1794 is 0.0755 sec\n",
      "train AE loss : 1.6055641174316406, train ANN loss : 1.9997811317443848\n",
      "AE loss : 1.5459529161453247, ANN loss : 1.602020502090454, Total loss : 156.1973114013672\n",
      "learning rate A :  tf.Tensor(9.814826e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1795 is 0.0765 sec\n",
      "train AE loss : 1.6151384115219116, train ANN loss : 2.0100765228271484\n",
      "AE loss : 1.5514140129089355, ANN loss : 1.5990365743637085, Total loss : 156.7404327392578\n",
      "learning rate A :  tf.Tensor(9.814826e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1796 is 0.0776 sec\n",
      "train AE loss : 1.6207407712936401, train ANN loss : 1.9819273948669434\n",
      "AE loss : 1.5541868209838867, ANN loss : 1.5953929424285889, Total loss : 157.0140838623047\n",
      "learning rate A :  tf.Tensor(9.814826e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1797 is 0.0777 sec\n",
      "train AE loss : 1.6235781908035278, train ANN loss : 2.016416549682617\n",
      "AE loss : 1.5417003631591797, ANN loss : 1.5942856073379517, Total loss : 155.76431274414062\n",
      "learning rate A :  tf.Tensor(9.814619e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1798 is 0.0750 sec\n",
      "train AE loss : 1.6106042861938477, train ANN loss : 1.991529941558838\n",
      "AE loss : 1.5454877614974976, ANN loss : 1.5952200889587402, Total loss : 156.14401245117188\n",
      "learning rate A :  tf.Tensor(9.814619e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1799 is 0.0893 sec\n",
      "train AE loss : 1.6147078275680542, train ANN loss : 1.9997838735580444\n",
      "AE loss : 1.5545600652694702, ANN loss : 1.6017556190490723, Total loss : 157.05776977539062\n",
      "learning rate A :  tf.Tensor(9.814619e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1800 is 0.0769 sec\n",
      "train AE loss : 1.624233365058899, train ANN loss : 2.0082898139953613\n",
      "AE loss : 1.5420467853546143, ANN loss : 1.6006298065185547, Total loss : 155.80531311035156\n",
      "learning rate A :  tf.Tensor(9.8144126e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1801 is 0.0845 sec\n",
      "train AE loss : 1.6112228631973267, train ANN loss : 1.9933607578277588\n",
      "AE loss : 1.5535074472427368, ANN loss : 1.5960513353347778, Total loss : 156.94677734375\n",
      "learning rate A :  tf.Tensor(9.8144126e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1802 is 0.0787 sec\n",
      "train AE loss : 1.6232101917266846, train ANN loss : 1.9957878589630127\n",
      "AE loss : 1.5650169849395752, ANN loss : 1.5911219120025635, Total loss : 158.09283447265625\n",
      "learning rate A :  tf.Tensor(9.8144126e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1803 is 0.0787 sec\n",
      "train AE loss : 1.6353551149368286, train ANN loss : 2.001310110092163\n",
      "AE loss : 1.552032709121704, ANN loss : 1.5899620056152344, Total loss : 156.79324340820312\n",
      "learning rate A :  tf.Tensor(9.814205e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1804 is 0.0844 sec\n",
      "train AE loss : 1.6218667030334473, train ANN loss : 1.9848666191101074\n",
      "AE loss : 1.539579153060913, ANN loss : 1.5888378620147705, Total loss : 155.5467529296875\n",
      "learning rate A :  tf.Tensor(9.8139986e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1805 is 0.0755 sec\n",
      "train AE loss : 1.6089056730270386, train ANN loss : 1.998756766319275\n",
      "AE loss : 1.5276113748550415, ANN loss : 1.5877418518066406, Total loss : 154.348876953125\n",
      "learning rate A :  tf.Tensor(9.813792e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1806 is 0.0799 sec\n",
      "train AE loss : 1.596418857574463, train ANN loss : 1.9898183345794678\n",
      "AE loss : 1.516103744506836, ANN loss : 1.586678147315979, Total loss : 153.1970672607422\n",
      "learning rate A :  tf.Tensor(9.813585e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1807 is 0.0755 sec\n",
      "train AE loss : 1.5844069719314575, train ANN loss : 1.996687650680542\n",
      "AE loss : 1.5050126314163208, ANN loss : 1.5856446027755737, Total loss : 152.08692932128906\n",
      "learning rate A :  tf.Tensor(9.813378e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1808 is 0.0751 sec\n",
      "train AE loss : 1.5728180408477783, train ANN loss : 1.9901565313339233\n",
      "AE loss : 1.494327187538147, ANN loss : 1.584633708000183, Total loss : 151.01734924316406\n",
      "learning rate A :  tf.Tensor(9.813172e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1809 is 0.0763 sec\n",
      "train AE loss : 1.5616240501403809, train ANN loss : 2.004443645477295\n",
      "AE loss : 1.5091464519500732, ANN loss : 1.5913219451904297, Total loss : 152.50596618652344\n",
      "learning rate A :  tf.Tensor(9.813172e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1810 is 0.0775 sec\n",
      "train AE loss : 1.577059030532837, train ANN loss : 1.9864405393600464\n",
      "AE loss : 1.498321533203125, ANN loss : 1.590308427810669, Total loss : 151.42245483398438\n",
      "learning rate A :  tf.Tensor(9.8129654e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1811 is 0.0857 sec\n",
      "train AE loss : 1.5657278299331665, train ANN loss : 2.0065360069274902\n",
      "AE loss : 1.4878644943237305, ANN loss : 1.5893176794052124, Total loss : 150.37576293945312\n",
      "learning rate A :  tf.Tensor(9.812758e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1812 is 0.0756 sec\n",
      "train AE loss : 1.5547690391540527, train ANN loss : 2.0150582790374756\n",
      "AE loss : 1.4777776002883911, ANN loss : 1.5883514881134033, Total loss : 149.36611938476562\n",
      "learning rate A :  tf.Tensor(9.812551e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1813 is 0.0744 sec\n",
      "train AE loss : 1.5441750288009644, train ANN loss : 2.0076491832733154\n",
      "AE loss : 1.4964361190795898, ANN loss : 1.6006659269332886, Total loss : 151.24427795410156\n",
      "learning rate A :  tf.Tensor(9.812551e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1814 is 0.0774 sec\n",
      "train AE loss : 1.563659906387329, train ANN loss : 2.0038273334503174\n",
      "AE loss : 1.5131709575653076, ANN loss : 1.6043673753738403, Total loss : 152.9214630126953\n",
      "learning rate A :  tf.Tensor(9.812551e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1815 is 0.0764 sec\n",
      "train AE loss : 1.5812169313430786, train ANN loss : 1.9980883598327637\n",
      "AE loss : 1.5021864175796509, ANN loss : 1.6032655239105225, Total loss : 151.8218994140625\n",
      "learning rate A :  tf.Tensor(9.812344e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1816 is 0.0751 sec\n",
      "train AE loss : 1.5697003602981567, train ANN loss : 1.9765596389770508\n",
      "AE loss : 1.4916105270385742, ANN loss : 1.602190375328064, Total loss : 150.7632598876953\n",
      "learning rate A :  tf.Tensor(9.8121374e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1817 is 0.0749 sec\n",
      "train AE loss : 1.5585981607437134, train ANN loss : 1.9941260814666748\n",
      "AE loss : 1.481425404548645, ANN loss : 1.6011427640914917, Total loss : 149.74368286132812\n",
      "learning rate A :  tf.Tensor(9.81193e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1818 is 0.0733 sec\n",
      "train AE loss : 1.5478798151016235, train ANN loss : 1.985119342803955\n",
      "AE loss : 1.4716154336929321, ANN loss : 1.600124716758728, Total loss : 148.7616729736328\n",
      "learning rate A :  tf.Tensor(9.8117234e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1819 is 0.0739 sec\n",
      "train AE loss : 1.5375456809997559, train ANN loss : 1.9944759607315063\n",
      "AE loss : 1.4621580839157104, ANN loss : 1.5991368293762207, Total loss : 147.81494140625\n",
      "learning rate A :  tf.Tensor(9.811517e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1820 is 0.0735 sec\n",
      "train AE loss : 1.527549147605896, train ANN loss : 2.004088878631592\n",
      "AE loss : 1.4530121088027954, ANN loss : 1.5981720685958862, Total loss : 146.89938354492188\n",
      "learning rate A :  tf.Tensor(9.81131e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1821 is 0.0747 sec\n",
      "train AE loss : 1.5178906917572021, train ANN loss : 2.003171682357788\n",
      "AE loss : 1.4441734552383423, ANN loss : 1.5972282886505127, Total loss : 146.01458740234375\n",
      "learning rate A :  tf.Tensor(9.8111035e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1822 is 0.0740 sec\n",
      "train AE loss : 1.5085409879684448, train ANN loss : 1.9687508344650269\n",
      "AE loss : 1.460415244102478, ANN loss : 1.5978294610977173, Total loss : 147.63934326171875\n",
      "learning rate A :  tf.Tensor(9.8111035e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1823 is 0.0847 sec\n",
      "train AE loss : 1.525719165802002, train ANN loss : 1.9923473596572876\n",
      "AE loss : 1.4734948873519897, ANN loss : 1.5975979566574097, Total loss : 148.9470977783203\n",
      "learning rate A :  tf.Tensor(9.8111035e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1824 is 0.0760 sec\n",
      "train AE loss : 1.5395634174346924, train ANN loss : 1.9828827381134033\n",
      "AE loss : 1.463901162147522, ANN loss : 1.596521019935608, Total loss : 147.9866485595703\n",
      "learning rate A :  tf.Tensor(9.810897e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1825 is 0.0746 sec\n",
      "train AE loss : 1.5294240713119507, train ANN loss : 1.9976752996444702\n",
      "AE loss : 1.4546641111373901, ANN loss : 1.5954725742340088, Total loss : 147.0618896484375\n",
      "learning rate A :  tf.Tensor(9.81069e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1826 is 0.0735 sec\n",
      "train AE loss : 1.5196435451507568, train ANN loss : 1.9910205602645874\n",
      "AE loss : 1.4636117219924927, ANN loss : 1.5911712646484375, Total loss : 147.9523468017578\n",
      "learning rate A :  tf.Tensor(9.81069e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1827 is 0.0762 sec\n",
      "train AE loss : 1.5291821956634521, train ANN loss : 2.0029282569885254\n",
      "AE loss : 1.4683854579925537, ANN loss : 1.5885611772537231, Total loss : 148.42710876464844\n",
      "learning rate A :  tf.Tensor(9.81069e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1828 is 0.0771 sec\n",
      "train AE loss : 1.5342622995376587, train ANN loss : 1.977471947669983\n",
      "AE loss : 1.4588749408721924, ANN loss : 1.5875587463378906, Total loss : 147.4750518798828\n",
      "learning rate A :  tf.Tensor(9.810483e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1829 is 0.0740 sec\n",
      "train AE loss : 1.524183988571167, train ANN loss : 2.0010781288146973\n",
      "AE loss : 1.4663505554199219, ANN loss : 1.5923537015914917, Total loss : 148.22740173339844\n",
      "learning rate A :  tf.Tensor(9.810483e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1830 is 0.0762 sec\n",
      "train AE loss : 1.5319775342941284, train ANN loss : 1.9928796291351318\n",
      "AE loss : 1.456788182258606, ANN loss : 1.5913617610931396, Total loss : 147.27017211914062\n",
      "learning rate A :  tf.Tensor(9.810276e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1831 is 0.0733 sec\n",
      "train AE loss : 1.5218560695648193, train ANN loss : 1.9947127103805542\n",
      "AE loss : 1.4699335098266602, ANN loss : 1.5916177034378052, Total loss : 148.58497619628906\n",
      "learning rate A :  tf.Tensor(9.810276e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1832 is 0.0756 sec\n",
      "train AE loss : 1.535493016242981, train ANN loss : 1.9977761507034302\n",
      "AE loss : 1.482983112335205, ANN loss : 1.593459129333496, Total loss : 149.8917694091797\n",
      "learning rate A :  tf.Tensor(9.810276e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1833 is 0.0756 sec\n",
      "train AE loss : 1.5491292476654053, train ANN loss : 2.0005340576171875\n",
      "AE loss : 1.4727156162261963, ANN loss : 1.5923374891281128, Total loss : 148.86390686035156\n",
      "learning rate A :  tf.Tensor(9.8100696e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1834 is 0.0741 sec\n",
      "train AE loss : 1.5383257865905762, train ANN loss : 1.9962501525878906\n",
      "AE loss : 1.4818798303604126, ANN loss : 1.5909560918807983, Total loss : 149.77894592285156\n",
      "learning rate A :  tf.Tensor(9.8100696e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1835 is 0.0743 sec\n",
      "train AE loss : 1.5479670763015747, train ANN loss : 1.977673053741455\n",
      "AE loss : 1.4716562032699585, ANN loss : 1.5898661613464355, Total loss : 148.7554931640625\n",
      "learning rate A :  tf.Tensor(9.809863e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1836 is 0.0732 sec\n",
      "train AE loss : 1.5372180938720703, train ANN loss : 1.9923055171966553\n",
      "AE loss : 1.4815200567245483, ANN loss : 1.595710277557373, Total loss : 149.74771118164062\n",
      "learning rate A :  tf.Tensor(9.809863e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1837 is 0.0757 sec\n",
      "train AE loss : 1.5472371578216553, train ANN loss : 1.9710158109664917\n",
      "AE loss : 1.4856324195861816, ANN loss : 1.5932141542434692, Total loss : 150.15646362304688\n",
      "learning rate A :  tf.Tensor(9.809863e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1838 is 0.0765 sec\n",
      "train AE loss : 1.5513765811920166, train ANN loss : 1.9754328727722168\n",
      "AE loss : 1.475204586982727, ANN loss : 1.5920929908752441, Total loss : 149.11256408691406\n",
      "learning rate A :  tf.Tensor(9.809656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1839 is 0.0753 sec\n",
      "train AE loss : 1.540415644645691, train ANN loss : 1.9928590059280396\n",
      "AE loss : 1.475642204284668, ANN loss : 1.5857726335525513, Total loss : 149.14999389648438\n",
      "learning rate A :  tf.Tensor(9.809656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1840 is 0.0764 sec\n",
      "train AE loss : 1.5408282279968262, train ANN loss : 1.9895634651184082\n",
      "AE loss : 1.4788004159927368, ANN loss : 1.5837700366973877, Total loss : 149.46380615234375\n",
      "learning rate A :  tf.Tensor(9.809656e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1841 is 0.0785 sec\n",
      "train AE loss : 1.544083833694458, train ANN loss : 1.9798271656036377\n",
      "AE loss : 1.4687824249267578, ANN loss : 1.5828429460525513, Total loss : 148.46107482910156\n",
      "learning rate A :  tf.Tensor(9.80945e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1842 is 0.0758 sec\n",
      "train AE loss : 1.53352952003479, train ANN loss : 1.9860786199569702\n",
      "AE loss : 1.4591283798217773, ANN loss : 1.5819416046142578, Total loss : 147.49478149414062\n",
      "learning rate A :  tf.Tensor(9.809243e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1843 is 0.0924 sec\n",
      "train AE loss : 1.5233412981033325, train ANN loss : 2.0004093647003174\n",
      "AE loss : 1.4498077630996704, ANN loss : 1.5810645818710327, Total loss : 146.56182861328125\n",
      "learning rate A :  tf.Tensor(9.8090364e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1844 is 0.0823 sec\n",
      "train AE loss : 1.5135101079940796, train ANN loss : 1.9954859018325806\n",
      "AE loss : 1.4408166408538818, ANN loss : 1.5802092552185059, Total loss : 145.661865234375\n",
      "learning rate A :  tf.Tensor(9.80883e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1845 is 0.0801 sec\n",
      "train AE loss : 1.5040123462677002, train ANN loss : 1.9880857467651367\n",
      "AE loss : 1.4541587829589844, ANN loss : 1.5877816677093506, Total loss : 147.003662109375\n",
      "learning rate A :  tf.Tensor(9.80883e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1846 is 0.0817 sec\n",
      "train AE loss : 1.5175232887268066, train ANN loss : 1.9857670068740845\n",
      "AE loss : 1.472656488418579, ANN loss : 1.5924965143203735, Total loss : 148.85813903808594\n",
      "learning rate A :  tf.Tensor(9.80883e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1847 is 0.0842 sec\n",
      "train AE loss : 1.5365389585494995, train ANN loss : 1.9782003164291382\n",
      "AE loss : 1.4627703428268433, ANN loss : 1.5914051532745361, Total loss : 147.86843872070312\n",
      "learning rate A :  tf.Tensor(9.808623e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1848 is 0.0812 sec\n",
      "train AE loss : 1.5261529684066772, train ANN loss : 1.9917778968811035\n",
      "AE loss : 1.4762934446334839, ANN loss : 1.5924699306488037, Total loss : 149.22181701660156\n",
      "learning rate A :  tf.Tensor(9.808623e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1849 is 0.0811 sec\n",
      "train AE loss : 1.5403127670288086, train ANN loss : 1.9976708889007568\n",
      "AE loss : 1.4810720682144165, ANN loss : 1.5920777320861816, Total loss : 149.6992950439453\n",
      "learning rate A :  tf.Tensor(9.808623e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1850 is 0.0824 sec\n",
      "train AE loss : 1.5455654859542847, train ANN loss : 1.9865195751190186\n",
      "AE loss : 1.480302333831787, ANN loss : 1.5902832746505737, Total loss : 149.62051391601562\n",
      "learning rate A :  tf.Tensor(9.808623e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1851 is 0.0812 sec\n",
      "train AE loss : 1.545013189315796, train ANN loss : 1.9818520545959473\n",
      "AE loss : 1.4702311754226685, ANN loss : 1.5892144441604614, Total loss : 148.61233520507812\n",
      "learning rate A :  tf.Tensor(9.808416e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1852 is 0.1817 sec\n",
      "train AE loss : 1.5344315767288208, train ANN loss : 1.9804164171218872\n",
      "AE loss : 1.4662901163101196, ANN loss : 1.5877588987350464, Total loss : 148.21678161621094\n",
      "learning rate A :  tf.Tensor(9.808416e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1853 is 0.0808 sec\n",
      "train AE loss : 1.530471682548523, train ANN loss : 1.9862622022628784\n",
      "AE loss : 1.4566575288772583, ANN loss : 1.5867068767547607, Total loss : 147.25245666503906\n",
      "learning rate A :  tf.Tensor(9.80821e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1854 is 0.0799 sec\n",
      "train AE loss : 1.5202921628952026, train ANN loss : 1.992429256439209\n",
      "AE loss : 1.4571014642715454, ANN loss : 1.57677161693573, Total loss : 147.28692626953125\n",
      "learning rate A :  tf.Tensor(9.80821e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1855 is 0.0847 sec\n",
      "train AE loss : 1.5210845470428467, train ANN loss : 1.9892683029174805\n",
      "AE loss : 1.4478464126586914, ANN loss : 1.5758370161056519, Total loss : 146.3604736328125\n",
      "learning rate A :  tf.Tensor(9.808003e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1856 is 0.0886 sec\n",
      "train AE loss : 1.5112712383270264, train ANN loss : 1.9979335069656372\n",
      "AE loss : 1.458537220954895, ANN loss : 1.5857324600219727, Total loss : 147.43946838378906\n",
      "learning rate A :  tf.Tensor(9.808003e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1857 is 0.0838 sec\n",
      "train AE loss : 1.522659182548523, train ANN loss : 1.9926142692565918\n",
      "AE loss : 1.473950743675232, ANN loss : 1.5904675722122192, Total loss : 148.98553466796875\n",
      "learning rate A :  tf.Tensor(9.808003e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1858 is 0.0808 sec\n",
      "train AE loss : 1.5386626720428467, train ANN loss : 1.9912220239639282\n",
      "AE loss : 1.4639066457748413, ANN loss : 1.5893460512161255, Total loss : 147.98001098632812\n",
      "learning rate A :  tf.Tensor(9.807796e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1859 is 0.0786 sec\n",
      "train AE loss : 1.5280890464782715, train ANN loss : 1.969241976737976\n",
      "AE loss : 1.454237461090088, ANN loss : 1.5882519483566284, Total loss : 147.01199340820312\n",
      "learning rate A :  tf.Tensor(9.80759e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1860 is 0.0818 sec\n",
      "train AE loss : 1.5178813934326172, train ANN loss : 1.9881783723831177\n",
      "AE loss : 1.4682140350341797, ANN loss : 1.5985572338104248, Total loss : 148.4199676513672\n",
      "learning rate A :  tf.Tensor(9.80759e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1861 is 0.0817 sec\n",
      "train AE loss : 1.5324677228927612, train ANN loss : 1.995524287223816\n",
      "AE loss : 1.4772895574569702, ANN loss : 1.5963295698165894, Total loss : 149.32528686523438\n",
      "learning rate A :  tf.Tensor(9.80759e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1862 is 0.0956 sec\n",
      "train AE loss : 1.5422836542129517, train ANN loss : 1.9851627349853516\n",
      "AE loss : 1.4670943021774292, ANN loss : 1.595231533050537, Total loss : 148.3046417236328\n",
      "learning rate A :  tf.Tensor(9.807383e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1863 is 0.0802 sec\n",
      "train AE loss : 1.5315663814544678, train ANN loss : 1.9794889688491821\n",
      "AE loss : 1.4683339595794678, ANN loss : 1.5911206007003784, Total loss : 148.4245147705078\n",
      "learning rate A :  tf.Tensor(9.807383e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1864 is 0.0814 sec\n",
      "train AE loss : 1.5331556797027588, train ANN loss : 1.9976680278778076\n",
      "AE loss : 1.4584683179855347, ANN loss : 1.590091347694397, Total loss : 147.43692016601562\n",
      "learning rate A :  tf.Tensor(9.807177e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1865 is 0.0813 sec\n",
      "train AE loss : 1.5227586030960083, train ANN loss : 1.9866845607757568\n",
      "AE loss : 1.4589154720306396, ANN loss : 1.5790438652038574, Total loss : 147.4705810546875\n",
      "learning rate A :  tf.Tensor(9.807177e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1866 is 0.0822 sec\n",
      "train AE loss : 1.5230844020843506, train ANN loss : 1.9851672649383545\n",
      "AE loss : 1.4492707252502441, ANN loss : 1.5779927968978882, Total loss : 146.5050811767578\n",
      "learning rate A :  tf.Tensor(9.806969e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1867 is 0.0789 sec\n",
      "train AE loss : 1.512878179550171, train ANN loss : 1.978650689125061\n",
      "AE loss : 1.4515180587768555, ANN loss : 1.5803476572036743, Total loss : 146.73216247558594\n",
      "learning rate A :  tf.Tensor(9.806969e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1868 is 0.0911 sec\n",
      "train AE loss : 1.5149030685424805, train ANN loss : 1.9922549724578857\n",
      "AE loss : 1.4420981407165527, ANN loss : 1.579279899597168, Total loss : 145.78909301757812\n",
      "learning rate A :  tf.Tensor(9.8067634e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1869 is 0.0811 sec\n",
      "train AE loss : 1.504916787147522, train ANN loss : 1.9681775569915771\n",
      "AE loss : 1.4467549324035645, ANN loss : 1.580143690109253, Total loss : 146.25563049316406\n",
      "learning rate A :  tf.Tensor(9.8067634e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1870 is 0.0853 sec\n",
      "train AE loss : 1.5095945596694946, train ANN loss : 1.9774219989776611\n",
      "AE loss : 1.4375402927398682, ANN loss : 1.579146385192871, Total loss : 145.3331756591797\n",
      "learning rate A :  tf.Tensor(9.806557e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1871 is 0.0782 sec\n",
      "train AE loss : 1.4998328685760498, train ANN loss : 1.9797836542129517\n",
      "AE loss : 1.4286799430847168, ANN loss : 1.5781793594360352, Total loss : 144.44618225097656\n",
      "learning rate A :  tf.Tensor(9.8063494e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1872 is 0.0792 sec\n",
      "train AE loss : 1.4904199838638306, train ANN loss : 1.9821457862854004\n",
      "AE loss : 1.4392032623291016, ANN loss : 1.5906269550323486, Total loss : 145.51095581054688\n",
      "learning rate A :  tf.Tensor(9.8063494e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1873 is 0.0960 sec\n",
      "train AE loss : 1.5010234117507935, train ANN loss : 1.999659538269043\n",
      "AE loss : 1.4502317905426025, ANN loss : 1.591323971748352, Total loss : 146.614501953125\n",
      "learning rate A :  tf.Tensor(9.8063494e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1874 is 0.0808 sec\n",
      "train AE loss : 1.5122054815292358, train ANN loss : 1.9739693403244019\n",
      "AE loss : 1.4408481121063232, ANN loss : 1.5901442766189575, Total loss : 145.67495727539062\n",
      "learning rate A :  tf.Tensor(9.8061435e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1875 is 0.0807 sec\n",
      "train AE loss : 1.5023183822631836, train ANN loss : 1.9702702760696411\n",
      "AE loss : 1.449022889137268, ANN loss : 1.5899304151535034, Total loss : 146.49220275878906\n",
      "learning rate A :  tf.Tensor(9.8061435e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1876 is 0.0795 sec\n",
      "train AE loss : 1.5109950304031372, train ANN loss : 1.9729154109954834\n",
      "AE loss : 1.4514294862747192, ANN loss : 1.589403510093689, Total loss : 146.7323455810547\n",
      "learning rate A :  tf.Tensor(9.8061435e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1877 is 0.0808 sec\n",
      "train AE loss : 1.5139063596725464, train ANN loss : 1.989166259765625\n",
      "AE loss : 1.4540295600891113, ANN loss : 1.5817314386367798, Total loss : 146.98468017578125\n",
      "learning rate A :  tf.Tensor(9.8061435e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1878 is 0.0820 sec\n",
      "train AE loss : 1.5168331861495972, train ANN loss : 1.9751471281051636\n",
      "AE loss : 1.460841178894043, ANN loss : 1.577929973602295, Total loss : 147.6620635986328\n",
      "learning rate A :  tf.Tensor(9.8061435e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1879 is 0.0806 sec\n",
      "train AE loss : 1.5241765975952148, train ANN loss : 1.9952023029327393\n",
      "AE loss : 1.4691557884216309, ANN loss : 1.5760986804962158, Total loss : 148.49168395996094\n",
      "learning rate A :  tf.Tensor(9.8061435e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1880 is 0.0802 sec\n",
      "train AE loss : 1.5330042839050293, train ANN loss : 1.9728648662567139\n",
      "AE loss : 1.4758472442626953, ANN loss : 1.5750186443328857, Total loss : 149.1597442626953\n",
      "learning rate A :  tf.Tensor(9.8061435e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1881 is 0.0936 sec\n",
      "train AE loss : 1.540110468864441, train ANN loss : 1.9802805185317993\n",
      "AE loss : 1.465224266052246, ANN loss : 1.5739778280258179, Total loss : 148.09640502929688\n",
      "learning rate A :  tf.Tensor(9.805937e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1882 is 0.0879 sec\n",
      "train AE loss : 1.5289798974990845, train ANN loss : 1.9992051124572754\n",
      "AE loss : 1.4719696044921875, ANN loss : 1.573044776916504, Total loss : 148.77000427246094\n",
      "learning rate A :  tf.Tensor(9.805937e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1883 is 0.0823 sec\n",
      "train AE loss : 1.5360217094421387, train ANN loss : 1.9771203994750977\n",
      "AE loss : 1.4613511562347412, ANN loss : 1.5720112323760986, Total loss : 147.70712280273438\n",
      "learning rate A :  tf.Tensor(9.80573e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1884 is 0.0775 sec\n",
      "train AE loss : 1.5248920917510986, train ANN loss : 1.964290738105774\n",
      "AE loss : 1.4511830806732178, ANN loss : 1.5710058212280273, Total loss : 146.68931579589844\n",
      "learning rate A :  tf.Tensor(9.8055236e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1885 is 0.0826 sec\n",
      "train AE loss : 1.514202356338501, train ANN loss : 1.9737894535064697\n",
      "AE loss : 1.4572627544403076, ANN loss : 1.5746581554412842, Total loss : 147.30091857910156\n",
      "learning rate A :  tf.Tensor(9.8055236e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1886 is 0.0848 sec\n",
      "train AE loss : 1.520559310913086, train ANN loss : 2.0013015270233154\n",
      "AE loss : 1.4470539093017578, ANN loss : 1.5736017227172852, Total loss : 146.27899169921875\n",
      "learning rate A :  tf.Tensor(9.805317e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1887 is 0.0805 sec\n",
      "train AE loss : 1.509809136390686, train ANN loss : 1.9833723306655884\n",
      "AE loss : 1.456709861755371, ANN loss : 1.5827000141143799, Total loss : 147.25369262695312\n",
      "learning rate A :  tf.Tensor(9.805317e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1888 is 0.0817 sec\n",
      "train AE loss : 1.51993989944458, train ANN loss : 1.974573016166687\n",
      "AE loss : 1.446313738822937, ANN loss : 1.581600546836853, Total loss : 146.2129669189453\n",
      "learning rate A :  tf.Tensor(9.80511e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1889 is 0.0790 sec\n",
      "train AE loss : 1.5090047121047974, train ANN loss : 1.9740151166915894\n",
      "AE loss : 1.4363625049591064, ANN loss : 1.5805280208587646, Total loss : 145.21678161621094\n",
      "learning rate A :  tf.Tensor(9.804904e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1890 is 0.0779 sec\n",
      "train AE loss : 1.4984952211380005, train ANN loss : 1.9796147346496582\n",
      "AE loss : 1.4489675760269165, ANN loss : 1.5821417570114136, Total loss : 146.47891235351562\n",
      "learning rate A :  tf.Tensor(9.804904e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1891 is 0.0824 sec\n",
      "train AE loss : 1.5121468305587769, train ANN loss : 1.999064326286316\n",
      "AE loss : 1.43887197971344, ANN loss : 1.58109450340271, Total loss : 145.46829223632812\n",
      "learning rate A :  tf.Tensor(9.804697e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1892 is 0.0782 sec\n",
      "train AE loss : 1.5014910697937012, train ANN loss : 1.9665557146072388\n",
      "AE loss : 1.452623963356018, ANN loss : 1.5842119455337524, Total loss : 146.8466033935547\n",
      "learning rate A :  tf.Tensor(9.804697e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1893 is 0.0795 sec\n",
      "train AE loss : 1.5162538290023804, train ANN loss : 1.9812889099121094\n",
      "AE loss : 1.4423794746398926, ANN loss : 1.58315110206604, Total loss : 145.82110595703125\n",
      "learning rate A :  tf.Tensor(9.8044904e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1894 is 0.0793 sec\n",
      "train AE loss : 1.5054455995559692, train ANN loss : 1.9826574325561523\n",
      "AE loss : 1.4574756622314453, ANN loss : 1.5834318399429321, Total loss : 147.33099365234375\n",
      "learning rate A :  tf.Tensor(9.8044904e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1895 is 0.0809 sec\n",
      "train AE loss : 1.521539568901062, train ANN loss : 1.9611231088638306\n",
      "AE loss : 1.4470235109329224, ANN loss : 1.5822923183441162, Total loss : 146.28463745117188\n",
      "learning rate A :  tf.Tensor(9.804284e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1896 is 0.0780 sec\n",
      "train AE loss : 1.5105254650115967, train ANN loss : 1.9764187335968018\n",
      "AE loss : 1.4585611820220947, ANN loss : 1.585142970085144, Total loss : 147.44126892089844\n",
      "learning rate A :  tf.Tensor(9.804284e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1897 is 0.0818 sec\n",
      "train AE loss : 1.5228856801986694, train ANN loss : 1.9756675958633423\n",
      "AE loss : 1.448034405708313, ANN loss : 1.5840076208114624, Total loss : 146.387451171875\n",
      "learning rate A :  tf.Tensor(9.804078e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1898 is 0.0781 sec\n",
      "train AE loss : 1.511802077293396, train ANN loss : 1.975212574005127\n",
      "AE loss : 1.4379514455795288, ANN loss : 1.5829036235809326, Total loss : 145.37803649902344\n",
      "learning rate A :  tf.Tensor(9.8038705e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1899 is 0.0780 sec\n",
      "train AE loss : 1.5011491775512695, train ANN loss : 1.984938621520996\n",
      "AE loss : 1.4282654523849487, ANN loss : 1.5818231105804443, Total loss : 144.40835571289062\n",
      "learning rate A :  tf.Tensor(9.8036646e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1900 is 0.0805 sec\n",
      "train AE loss : 1.490889072418213, train ANN loss : 1.9853579998016357\n",
      "AE loss : 1.4360077381134033, ANN loss : 1.5820149183273315, Total loss : 145.1827850341797\n",
      "learning rate A :  tf.Tensor(9.8036646e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1901 is 0.0791 sec\n",
      "train AE loss : 1.4992616176605225, train ANN loss : 1.9952956438064575\n",
      "AE loss : 1.4399741888046265, ANN loss : 1.5811189413070679, Total loss : 145.5785369873047\n",
      "learning rate A :  tf.Tensor(9.8036646e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1902 is 0.0813 sec\n",
      "train AE loss : 1.503367304801941, train ANN loss : 1.9805680513381958\n",
      "AE loss : 1.4300765991210938, ANN loss : 1.5801198482513428, Total loss : 144.58778381347656\n",
      "learning rate A :  tf.Tensor(9.803458e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1903 is 0.0796 sec\n",
      "train AE loss : 1.4928947687149048, train ANN loss : 1.9901955127716064\n",
      "AE loss : 1.4348191022872925, ANN loss : 1.5801641941070557, Total loss : 145.0620574951172\n",
      "learning rate A :  tf.Tensor(9.803458e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1904 is 0.0811 sec\n",
      "train AE loss : 1.4974088668823242, train ANN loss : 1.9697425365447998\n",
      "AE loss : 1.4394659996032715, ANN loss : 1.5729506015777588, Total loss : 145.51954650878906\n",
      "learning rate A :  tf.Tensor(9.803458e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1905 is 0.0807 sec\n",
      "train AE loss : 1.502010703086853, train ANN loss : 1.9737308025360107\n",
      "AE loss : 1.446519374847412, ANN loss : 1.5786306858062744, Total loss : 146.23057556152344\n",
      "learning rate A :  tf.Tensor(9.803458e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1906 is 0.0823 sec\n",
      "train AE loss : 1.5093507766723633, train ANN loss : 1.9742804765701294\n",
      "AE loss : 1.4360941648483276, ANN loss : 1.5775835514068604, Total loss : 145.18701171875\n",
      "learning rate A :  tf.Tensor(9.8032506e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1907 is 0.0787 sec\n",
      "train AE loss : 1.4983612298965454, train ANN loss : 1.9868046045303345\n",
      "AE loss : 1.426110029220581, ANN loss : 1.5765645503997803, Total loss : 144.1875762939453\n",
      "learning rate A :  tf.Tensor(9.803045e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1908 is 0.0789 sec\n",
      "train AE loss : 1.4878135919570923, train ANN loss : 1.9718400239944458\n",
      "AE loss : 1.416543960571289, ANN loss : 1.5755780935287476, Total loss : 143.22996520996094\n",
      "learning rate A :  tf.Tensor(9.802838e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1909 is 0.0815 sec\n",
      "train AE loss : 1.4776731729507446, train ANN loss : 1.983688473701477\n",
      "AE loss : 1.4264647960662842, ANN loss : 1.5789821147918701, Total loss : 144.22547912597656\n",
      "learning rate A :  tf.Tensor(9.802838e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1910 is 0.0810 sec\n",
      "train AE loss : 1.488186240196228, train ANN loss : 1.994012713432312\n",
      "AE loss : 1.4383209943771362, ANN loss : 1.5857927799224854, Total loss : 145.4178924560547\n",
      "learning rate A :  tf.Tensor(9.802838e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1911 is 0.0939 sec\n",
      "train AE loss : 1.5008341073989868, train ANN loss : 1.9760878086090088\n",
      "AE loss : 1.4489850997924805, ANN loss : 1.5829411745071411, Total loss : 146.48146057128906\n",
      "learning rate A :  tf.Tensor(9.802838e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1912 is 0.0814 sec\n",
      "train AE loss : 1.5123887062072754, train ANN loss : 1.9904406070709229\n",
      "AE loss : 1.4386630058288574, ANN loss : 1.5818634033203125, Total loss : 145.4481658935547\n",
      "learning rate A :  tf.Tensor(9.8026314e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1913 is 0.0801 sec\n",
      "train AE loss : 1.5015026330947876, train ANN loss : 1.9672660827636719\n",
      "AE loss : 1.4480730295181274, ANN loss : 1.5801235437393188, Total loss : 146.3874053955078\n",
      "learning rate A :  tf.Tensor(9.8026314e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1914 is 0.0847 sec\n",
      "train AE loss : 1.511590838432312, train ANN loss : 1.9656802415847778\n",
      "AE loss : 1.4549119472503662, ANN loss : 1.5765810012817383, Total loss : 147.06777954101562\n",
      "learning rate A :  tf.Tensor(9.8026314e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1915 is 0.0805 sec\n",
      "train AE loss : 1.5185346603393555, train ANN loss : 1.9792559146881104\n",
      "AE loss : 1.444416880607605, ANN loss : 1.5754667520523071, Total loss : 146.01715087890625\n",
      "learning rate A :  tf.Tensor(9.802425e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1916 is 0.0818 sec\n",
      "train AE loss : 1.507472038269043, train ANN loss : 1.9861921072006226\n",
      "AE loss : 1.4514316320419312, ANN loss : 1.5693317651748657, Total loss : 146.7124786376953\n",
      "learning rate A :  tf.Tensor(9.802425e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1917 is 0.0894 sec\n",
      "train AE loss : 1.5141658782958984, train ANN loss : 1.9824631214141846\n",
      "AE loss : 1.4409109354019165, ANN loss : 1.568139910697937, Total loss : 145.65924072265625\n",
      "learning rate A :  tf.Tensor(9.802218e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1918 is 0.0806 sec\n",
      "train AE loss : 1.5030901432037354, train ANN loss : 1.967482089996338\n",
      "AE loss : 1.4308385848999023, ANN loss : 1.5669864416122437, Total loss : 144.65084838867188\n",
      "learning rate A :  tf.Tensor(9.8020115e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1919 is 0.0824 sec\n",
      "train AE loss : 1.4924688339233398, train ANN loss : 1.973984718322754\n",
      "AE loss : 1.4383924007415771, ANN loss : 1.5674097537994385, Total loss : 145.40664672851562\n",
      "learning rate A :  tf.Tensor(9.8020115e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1920 is 0.0817 sec\n",
      "train AE loss : 1.499843955039978, train ANN loss : 1.9838078022003174\n",
      "AE loss : 1.4432495832443237, ANN loss : 1.573057770729065, Total loss : 145.89801025390625\n",
      "learning rate A :  tf.Tensor(9.8020115e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1921 is 0.0817 sec\n",
      "train AE loss : 1.5046567916870117, train ANN loss : 1.9656320810317993\n",
      "AE loss : 1.4463716745376587, ANN loss : 1.5723381042480469, Total loss : 146.20950317382812\n",
      "learning rate A :  tf.Tensor(9.8020115e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1922 is 0.0993 sec\n",
      "train AE loss : 1.507857084274292, train ANN loss : 1.9748636484146118\n",
      "AE loss : 1.4479249715805054, ANN loss : 1.5684865713119507, Total loss : 146.36097717285156\n",
      "learning rate A :  tf.Tensor(9.8020115e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1923 is 0.0798 sec\n",
      "train AE loss : 1.5096700191497803, train ANN loss : 1.9714748859405518\n",
      "AE loss : 1.437207579612732, ANN loss : 1.5673829317092896, Total loss : 145.2881317138672\n",
      "learning rate A :  tf.Tensor(9.8018056e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1924 is 0.0770 sec\n",
      "train AE loss : 1.498387336730957, train ANN loss : 1.9654237031936646\n",
      "AE loss : 1.4422425031661987, ANN loss : 1.5687448978424072, Total loss : 145.79298400878906\n",
      "learning rate A :  tf.Tensor(9.8018056e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1925 is 0.0771 sec\n",
      "train AE loss : 1.5039551258087158, train ANN loss : 1.9661977291107178\n",
      "AE loss : 1.4318424463272095, ANN loss : 1.5677251815795898, Total loss : 144.75198364257812\n",
      "learning rate A :  tf.Tensor(9.801598e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1926 is 0.0754 sec\n",
      "train AE loss : 1.4929959774017334, train ANN loss : 1.9789538383483887\n",
      "AE loss : 1.4452308416366577, ANN loss : 1.5735682249069214, Total loss : 146.09664916992188\n",
      "learning rate A :  tf.Tensor(9.801598e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1927 is 0.0783 sec\n",
      "train AE loss : 1.506907343864441, train ANN loss : 1.9859600067138672\n",
      "AE loss : 1.4606438875198364, ANN loss : 1.581072211265564, Total loss : 147.6454620361328\n",
      "learning rate A :  tf.Tensor(9.801598e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1928 is 0.0767 sec\n",
      "train AE loss : 1.5224095582962036, train ANN loss : 1.9577112197875977\n",
      "AE loss : 1.4719008207321167, ANN loss : 1.5872513055801392, Total loss : 148.77732849121094\n",
      "learning rate A :  tf.Tensor(9.801598e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1929 is 0.0780 sec\n",
      "train AE loss : 1.5336438417434692, train ANN loss : 1.9741075038909912\n",
      "AE loss : 1.4597554206848145, ANN loss : 1.58595871925354, Total loss : 147.56149291992188\n",
      "learning rate A :  tf.Tensor(9.801391e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1930 is 0.0760 sec\n",
      "train AE loss : 1.5209518671035767, train ANN loss : 1.96847665309906\n",
      "AE loss : 1.4481890201568604, ANN loss : 1.5847091674804688, Total loss : 146.4036102294922\n",
      "learning rate A :  tf.Tensor(9.801185e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1931 is 0.0760 sec\n",
      "train AE loss : 1.5088468790054321, train ANN loss : 1.973764419555664\n",
      "AE loss : 1.4371498823165894, ANN loss : 1.583497166633606, Total loss : 145.29847717285156\n",
      "learning rate A :  tf.Tensor(9.800978e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1932 is 0.0752 sec\n",
      "train AE loss : 1.4972598552703857, train ANN loss : 1.956648588180542\n",
      "AE loss : 1.4266072511672974, ANN loss : 1.5823217630386353, Total loss : 144.24302673339844\n",
      "learning rate A :  tf.Tensor(9.800772e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1933 is 0.0750 sec\n",
      "train AE loss : 1.4861624240875244, train ANN loss : 1.9739103317260742\n",
      "AE loss : 1.4300462007522583, ANN loss : 1.572596549987793, Total loss : 144.57720947265625\n",
      "learning rate A :  tf.Tensor(9.800772e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1934 is 0.0767 sec\n",
      "train AE loss : 1.4895801544189453, train ANN loss : 1.963889479637146\n",
      "AE loss : 1.4197319746017456, ANN loss : 1.5715265274047852, Total loss : 143.5447235107422\n",
      "learning rate A :  tf.Tensor(9.800566e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1935 is 0.0772 sec\n",
      "train AE loss : 1.478705883026123, train ANN loss : 1.9695559740066528\n",
      "AE loss : 1.4242632389068604, ANN loss : 1.5682227611541748, Total loss : 143.99453735351562\n",
      "learning rate A :  tf.Tensor(9.800566e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1936 is 0.0761 sec\n",
      "train AE loss : 1.4833076000213623, train ANN loss : 1.9603174924850464\n",
      "AE loss : 1.4306774139404297, ANN loss : 1.5694146156311035, Total loss : 144.6371612548828\n",
      "learning rate A :  tf.Tensor(9.800566e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1937 is 0.0750 sec\n",
      "train AE loss : 1.4899786710739136, train ANN loss : 1.9729105234146118\n",
      "AE loss : 1.4204332828521729, ANN loss : 1.5683372020721436, Total loss : 143.61167907714844\n",
      "learning rate A :  tf.Tensor(9.800359e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1938 is 0.0727 sec\n",
      "train AE loss : 1.4791721105575562, train ANN loss : 1.9677211046218872\n",
      "AE loss : 1.410632848739624, ANN loss : 1.5672887563705444, Total loss : 142.6305694580078\n",
      "learning rate A :  tf.Tensor(9.8001525e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1939 is 0.0746 sec\n",
      "train AE loss : 1.4688142538070679, train ANN loss : 1.9538583755493164\n",
      "AE loss : 1.4148006439208984, ANN loss : 1.5673164129257202, Total loss : 143.04739379882812\n",
      "learning rate A :  tf.Tensor(9.8001525e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1940 is 0.0759 sec\n",
      "train AE loss : 1.473364233970642, train ANN loss : 1.9761966466903687\n",
      "AE loss : 1.421740174293518, ANN loss : 1.5670405626296997, Total loss : 143.74105834960938\n",
      "learning rate A :  tf.Tensor(9.8001525e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1941 is 0.0788 sec\n",
      "train AE loss : 1.48094642162323, train ANN loss : 1.9847556352615356\n",
      "AE loss : 1.429610252380371, ANN loss : 1.5699820518493652, Total loss : 144.53102111816406\n",
      "learning rate A :  tf.Tensor(9.8001525e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1942 is 0.0794 sec\n",
      "train AE loss : 1.4892377853393555, train ANN loss : 1.968896508216858\n",
      "AE loss : 1.43984055519104, ANN loss : 1.5646380186080933, Total loss : 145.54869079589844\n",
      "learning rate A :  tf.Tensor(9.8001525e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1943 is 0.0762 sec\n",
      "train AE loss : 1.4997373819351196, train ANN loss : 1.964798927307129\n",
      "AE loss : 1.4508311748504639, ANN loss : 1.5660508871078491, Total loss : 146.649169921875\n",
      "learning rate A :  tf.Tensor(9.8001525e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1944 is 0.0770 sec\n",
      "train AE loss : 1.5110405683517456, train ANN loss : 1.9582146406173706\n",
      "AE loss : 1.4560061693191528, ANN loss : 1.5645524263381958, Total loss : 147.16517639160156\n",
      "learning rate A :  tf.Tensor(9.8001525e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1945 is 0.0764 sec\n",
      "train AE loss : 1.5165550708770752, train ANN loss : 1.9757477045059204\n",
      "AE loss : 1.459295392036438, ANN loss : 1.5683043003082275, Total loss : 147.4978485107422\n",
      "learning rate A :  tf.Tensor(9.8001525e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1946 is 0.0756 sec\n",
      "train AE loss : 1.5203160047531128, train ANN loss : 1.9775056838989258\n",
      "AE loss : 1.4479172229766846, ANN loss : 1.5672029256820679, Total loss : 146.35891723632812\n",
      "learning rate A :  tf.Tensor(9.799946e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1947 is 0.0835 sec\n",
      "train AE loss : 1.5083537101745605, train ANN loss : 1.972604513168335\n",
      "AE loss : 1.4370580911636353, ANN loss : 1.5661327838897705, Total loss : 145.27194213867188\n",
      "learning rate A :  tf.Tensor(9.799739e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1948 is 0.0780 sec\n",
      "train AE loss : 1.4969027042388916, train ANN loss : 1.9560933113098145\n",
      "AE loss : 1.4266743659973145, ANN loss : 1.565095067024231, Total loss : 144.23252868652344\n",
      "learning rate A :  tf.Tensor(9.7995326e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1949 is 0.0747 sec\n",
      "train AE loss : 1.4859424829483032, train ANN loss : 1.9616985321044922\n",
      "AE loss : 1.435056209564209, ANN loss : 1.5693979263305664, Total loss : 145.07501220703125\n",
      "learning rate A :  tf.Tensor(9.7995326e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1950 is 0.0757 sec\n",
      "train AE loss : 1.494887351989746, train ANN loss : 1.954649806022644\n",
      "AE loss : 1.424762487411499, ANN loss : 1.568356990814209, Total loss : 144.0446014404297\n",
      "learning rate A :  tf.Tensor(9.799327e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1951 is 0.0752 sec\n",
      "train AE loss : 1.4840153455734253, train ANN loss : 1.9686020612716675\n",
      "AE loss : 1.437643051147461, ANN loss : 1.5698256492614746, Total loss : 145.3341522216797\n",
      "learning rate A :  tf.Tensor(9.799327e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1952 is 0.0759 sec\n",
      "train AE loss : 1.4974114894866943, train ANN loss : 1.9500807523727417\n",
      "AE loss : 1.4510644674301147, ANN loss : 1.5765961408615112, Total loss : 146.68304443359375\n",
      "learning rate A :  tf.Tensor(9.799327e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1953 is 0.0765 sec\n",
      "train AE loss : 1.511461615562439, train ANN loss : 1.974814534187317\n",
      "AE loss : 1.4590810537338257, ANN loss : 1.5766620635986328, Total loss : 147.48477172851562\n",
      "learning rate A :  tf.Tensor(9.799327e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1954 is 0.0780 sec\n",
      "train AE loss : 1.5199627876281738, train ANN loss : 1.9550423622131348\n",
      "AE loss : 1.4607118368148804, ANN loss : 1.5758469104766846, Total loss : 147.6470184326172\n",
      "learning rate A :  tf.Tensor(9.799327e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1955 is 0.0767 sec\n",
      "train AE loss : 1.521891474723816, train ANN loss : 1.964773178100586\n",
      "AE loss : 1.4490505456924438, ANN loss : 1.5746554136276245, Total loss : 146.47972106933594\n",
      "learning rate A :  tf.Tensor(9.79912e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1956 is 0.0755 sec\n",
      "train AE loss : 1.509647011756897, train ANN loss : 1.976427674293518\n",
      "AE loss : 1.4379444122314453, ANN loss : 1.5734983682632446, Total loss : 145.36793518066406\n",
      "learning rate A :  tf.Tensor(9.7989134e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1957 is 0.0759 sec\n",
      "train AE loss : 1.4979573488235474, train ANN loss : 1.9761357307434082\n",
      "AE loss : 1.4273381233215332, ANN loss : 1.5723698139190674, Total loss : 144.30616760253906\n",
      "learning rate A :  tf.Tensor(9.7987075e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1958 is 0.0748 sec\n",
      "train AE loss : 1.4867687225341797, train ANN loss : 1.965483546257019\n",
      "AE loss : 1.4291781187057495, ANN loss : 1.5606451034545898, Total loss : 144.47845458984375\n",
      "learning rate A :  tf.Tensor(9.7987075e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1959 is 0.0770 sec\n",
      "train AE loss : 1.4889038801193237, train ANN loss : 1.9557641744613647\n",
      "AE loss : 1.4338557720184326, ANN loss : 1.5563796758651733, Total loss : 144.94195556640625\n",
      "learning rate A :  tf.Tensor(9.7987075e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1960 is 0.0769 sec\n",
      "train AE loss : 1.4939212799072266, train ANN loss : 1.9547024965286255\n",
      "AE loss : 1.4441415071487427, ANN loss : 1.5565712451934814, Total loss : 145.97073364257812\n",
      "learning rate A :  tf.Tensor(9.7987075e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1961 is 0.0764 sec\n",
      "train AE loss : 1.5046826601028442, train ANN loss : 1.9760080575942993\n",
      "AE loss : 1.455566644668579, ANN loss : 1.5640392303466797, Total loss : 147.1207275390625\n",
      "learning rate A :  tf.Tensor(9.7987075e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1962 is 0.0763 sec\n",
      "train AE loss : 1.5163720846176147, train ANN loss : 1.9678096771240234\n",
      "AE loss : 1.4660066366195679, ANN loss : 1.5700109004974365, Total loss : 148.170654296875\n",
      "learning rate A :  tf.Tensor(9.7987075e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1963 is 0.0773 sec\n",
      "train AE loss : 1.5272419452667236, train ANN loss : 1.9598345756530762\n",
      "AE loss : 1.4534330368041992, ANN loss : 1.568764567375183, Total loss : 146.91207885742188\n",
      "learning rate A :  tf.Tensor(9.7985e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1964 is 0.0750 sec\n",
      "train AE loss : 1.5140787363052368, train ANN loss : 1.9661263227462769\n",
      "AE loss : 1.4614026546478271, ANN loss : 1.5668233633041382, Total loss : 147.7070770263672\n",
      "learning rate A :  tf.Tensor(9.7985e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1965 is 0.0766 sec\n",
      "train AE loss : 1.5225995779037476, train ANN loss : 1.94294273853302\n",
      "AE loss : 1.4491350650787354, ANN loss : 1.5656346082687378, Total loss : 146.47914123535156\n",
      "learning rate A :  tf.Tensor(9.798294e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1966 is 0.0784 sec\n",
      "train AE loss : 1.5097323656082153, train ANN loss : 1.969728946685791\n",
      "AE loss : 1.4547371864318848, ANN loss : 1.565916895866394, Total loss : 147.03964233398438\n",
      "learning rate A :  tf.Tensor(9.798294e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1967 is 0.0797 sec\n",
      "train AE loss : 1.5158406496047974, train ANN loss : 1.9719537496566772\n",
      "AE loss : 1.4428654909133911, ANN loss : 1.564766526222229, Total loss : 145.85130310058594\n",
      "learning rate A :  tf.Tensor(9.7980876e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1968 is 0.0774 sec\n",
      "train AE loss : 1.5033597946166992, train ANN loss : 1.96646249294281\n",
      "AE loss : 1.4465293884277344, ANN loss : 1.5622789859771729, Total loss : 146.2152099609375\n",
      "learning rate A :  tf.Tensor(9.7980876e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1969 is 0.0782 sec\n",
      "train AE loss : 1.507327914237976, train ANN loss : 1.9654855728149414\n",
      "AE loss : 1.4351049661636353, ANN loss : 1.5611737966537476, Total loss : 145.07167053222656\n",
      "learning rate A :  tf.Tensor(9.797881e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1970 is 0.0761 sec\n",
      "train AE loss : 1.4952908754348755, train ANN loss : 1.979464054107666\n",
      "AE loss : 1.4427152872085571, ANN loss : 1.5704575777053833, Total loss : 145.84197998046875\n",
      "learning rate A :  tf.Tensor(9.797881e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1971 is 0.0788 sec\n",
      "train AE loss : 1.5030704736709595, train ANN loss : 1.9507136344909668\n",
      "AE loss : 1.450346827507019, ANN loss : 1.571018934249878, Total loss : 146.60569763183594\n",
      "learning rate A :  tf.Tensor(9.797881e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1972 is 0.0791 sec\n",
      "train AE loss : 1.5106899738311768, train ANN loss : 1.984466314315796\n",
      "AE loss : 1.4386471509933472, ANN loss : 1.5698062181472778, Total loss : 145.43450927734375\n",
      "learning rate A :  tf.Tensor(9.797675e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1973 is 0.0758 sec\n",
      "train AE loss : 1.4983915090560913, train ANN loss : 1.952445387840271\n",
      "AE loss : 1.4421851634979248, ANN loss : 1.5606333017349243, Total loss : 145.77915954589844\n",
      "learning rate A :  tf.Tensor(9.797675e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1974 is 0.0790 sec\n",
      "train AE loss : 1.5018876791000366, train ANN loss : 1.9485254287719727\n",
      "AE loss : 1.4308092594146729, ANN loss : 1.5594565868377686, Total loss : 144.640380859375\n",
      "learning rate A :  tf.Tensor(9.7974684e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1975 is 0.0771 sec\n",
      "train AE loss : 1.4899177551269531, train ANN loss : 1.960508108139038\n",
      "AE loss : 1.433412790298462, ANN loss : 1.5521968603134155, Total loss : 144.8934783935547\n",
      "learning rate A :  tf.Tensor(9.7974684e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1976 is 0.0784 sec\n",
      "train AE loss : 1.4925392866134644, train ANN loss : 1.9471955299377441\n",
      "AE loss : 1.4224268198013306, ANN loss : 1.5511025190353394, Total loss : 143.7937774658203\n",
      "learning rate A :  tf.Tensor(9.797262e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1977 is 0.0764 sec\n",
      "train AE loss : 1.4809560775756836, train ANN loss : 1.9586809873580933\n",
      "AE loss : 1.4300283193588257, ANN loss : 1.5542072057724, Total loss : 144.55703735351562\n",
      "learning rate A :  tf.Tensor(9.797262e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1978 is 0.0782 sec\n",
      "train AE loss : 1.4887070655822754, train ANN loss : 1.9545940160751343\n",
      "AE loss : 1.442026972770691, ANN loss : 1.563502311706543, Total loss : 145.76620483398438\n",
      "learning rate A :  tf.Tensor(9.797262e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1979 is 0.0781 sec\n",
      "train AE loss : 1.501054048538208, train ANN loss : 1.9461876153945923\n",
      "AE loss : 1.4306857585906982, ANN loss : 1.562221884727478, Total loss : 144.6307830810547\n",
      "learning rate A :  tf.Tensor(9.797056e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1980 is 0.0764 sec\n",
      "train AE loss : 1.4891259670257568, train ANN loss : 1.9526034593582153\n",
      "AE loss : 1.4390161037445068, ANN loss : 1.5612695217132568, Total loss : 145.462890625\n",
      "learning rate A :  tf.Tensor(9.797056e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1981 is 0.0785 sec\n",
      "train AE loss : 1.4980084896087646, train ANN loss : 1.9679418802261353\n",
      "AE loss : 1.4279927015304565, ANN loss : 1.5600649118423462, Total loss : 144.3593292236328\n",
      "learning rate A :  tf.Tensor(9.796849e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1982 is 0.0762 sec\n",
      "train AE loss : 1.4864039421081543, train ANN loss : 1.9594330787658691\n",
      "AE loss : 1.4175045490264893, ANN loss : 1.558896780014038, Total loss : 143.30935668945312\n",
      "learning rate A :  tf.Tensor(9.7966426e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1983 is 0.0764 sec\n",
      "train AE loss : 1.475343108177185, train ANN loss : 1.9568575620651245\n",
      "AE loss : 1.4075238704681396, ANN loss : 1.5577603578567505, Total loss : 142.31015014648438\n",
      "learning rate A :  tf.Tensor(9.796436e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1984 is 0.0763 sec\n",
      "train AE loss : 1.4647845029830933, train ANN loss : 1.9585720300674438\n",
      "AE loss : 1.4150617122650146, ANN loss : 1.564735770225525, Total loss : 143.07089233398438\n",
      "learning rate A :  tf.Tensor(9.796436e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1985 is 0.0781 sec\n",
      "train AE loss : 1.4729681015014648, train ANN loss : 1.9719024896621704\n",
      "AE loss : 1.4238463640213013, ANN loss : 1.5679240226745605, Total loss : 143.9525604248047\n",
      "learning rate A :  tf.Tensor(9.796436e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1986 is 0.0787 sec\n",
      "train AE loss : 1.4822112321853638, train ANN loss : 1.9518383741378784\n",
      "AE loss : 1.4290874004364014, ANN loss : 1.5647509098052979, Total loss : 144.47349548339844\n",
      "learning rate A :  tf.Tensor(9.796436e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1987 is 0.0788 sec\n",
      "train AE loss : 1.487708330154419, train ANN loss : 1.9574109315872192\n",
      "AE loss : 1.4320095777511597, ANN loss : 1.5616631507873535, Total loss : 144.7626190185547\n",
      "learning rate A :  tf.Tensor(9.796436e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1988 is 0.0781 sec\n",
      "train AE loss : 1.4909855127334595, train ANN loss : 1.9515472650527954\n",
      "AE loss : 1.421502947807312, ANN loss : 1.5605019330978394, Total loss : 143.71080017089844\n",
      "learning rate A :  tf.Tensor(9.79623e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1989 is 0.0753 sec\n",
      "train AE loss : 1.4798855781555176, train ANN loss : 1.9586797952651978\n",
      "AE loss : 1.427557110786438, ANN loss : 1.5565195083618164, Total loss : 144.31222534179688\n",
      "learning rate A :  tf.Tensor(9.79623e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1990 is 0.0786 sec\n",
      "train AE loss : 1.4866777658462524, train ANN loss : 1.9587284326553345\n",
      "AE loss : 1.417250394821167, ANN loss : 1.5554629564285278, Total loss : 143.28050231933594\n",
      "learning rate A :  tf.Tensor(9.7960234e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1991 is 0.0753 sec\n",
      "train AE loss : 1.4757709503173828, train ANN loss : 1.9490574598312378\n",
      "AE loss : 1.4275919198989868, ANN loss : 1.5554697513580322, Total loss : 144.3146514892578\n",
      "learning rate A :  tf.Tensor(9.7960234e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1992 is 0.0777 sec\n",
      "train AE loss : 1.4869376420974731, train ANN loss : 1.9492286443710327\n",
      "AE loss : 1.4172947406768799, ANN loss : 1.5544285774230957, Total loss : 143.28392028808594\n",
      "learning rate A :  tf.Tensor(9.795817e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1993 is 0.0770 sec\n",
      "train AE loss : 1.4760346412658691, train ANN loss : 1.959781289100647\n",
      "AE loss : 1.4074740409851074, ANN loss : 1.5534261465072632, Total loss : 142.30084228515625\n",
      "learning rate A :  tf.Tensor(9.795611e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1994 is 0.0761 sec\n",
      "train AE loss : 1.4656107425689697, train ANN loss : 1.9401626586914062\n",
      "AE loss : 1.4216594696044922, ANN loss : 1.561883568763733, Total loss : 143.7278289794922\n",
      "learning rate A :  tf.Tensor(9.795611e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1995 is 0.0777 sec\n",
      "train AE loss : 1.4803507328033447, train ANN loss : 1.9562417268753052\n",
      "AE loss : 1.411612629890442, ANN loss : 1.560767650604248, Total loss : 142.7220458984375\n",
      "learning rate A :  tf.Tensor(9.795404e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1996 is 0.0770 sec\n",
      "train AE loss : 1.4697132110595703, train ANN loss : 1.9332573413848877\n",
      "AE loss : 1.4020156860351562, ANN loss : 1.5596808195114136, Total loss : 141.76124572753906\n",
      "learning rate A :  tf.Tensor(9.7951975e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1997 is 0.0765 sec\n",
      "train AE loss : 1.4595346450805664, train ANN loss : 1.9591485261917114\n",
      "AE loss : 1.4161652326583862, ANN loss : 1.5677344799041748, Total loss : 143.1842498779297\n",
      "learning rate A :  tf.Tensor(9.7951975e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1998 is 0.0784 sec\n",
      "train AE loss : 1.4740500450134277, train ANN loss : 1.9550554752349854\n",
      "AE loss : 1.4063316583633423, ANN loss : 1.5665796995162964, Total loss : 142.19973754882812\n",
      "learning rate A :  tf.Tensor(9.794992e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 1999 is 0.0766 sec\n",
      "train AE loss : 1.4636590480804443, train ANN loss : 1.96311354637146\n",
      "AE loss : 1.4140536785125732, ANN loss : 1.5670419931411743, Total loss : 142.97239685058594\n",
      "learning rate A :  tf.Tensor(9.794992e-05, shape=(), dtype=float32)\n",
      "learning rate B :  <tf.Variable 'Adam/learning_rate:0' shape=() dtype=float32, numpy=0.001>\n",
      "Time for epoch 2000 is 0.0807 sec\n"
     ]
    }
   ],
   "source": [
    "train(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x1440 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_latent = model_down(val_x)\n",
    "from sklearn import manifold, datasets\n",
    "import matplotlib.pyplot as plt\n",
    "train_val_split = np.random.rand(len(val_latent)) < 0.4\n",
    "X_tsne = manifold.TSNE(n_components=2, init='pca', n_iter=5000, method='exact').fit_transform(val_latent[train_val_split])\n",
    "y = val_y[train_val_split].argmax(axis=1).reshape([-1,1])\n",
    "x_min, x_max = X_tsne.min(0), X_tsne.max(0)\n",
    "X_norm = (X_tsne - x_min) / (x_max - x_min)\n",
    "plt.figure(figsize=(20, 20))\n",
    "for i in range(X_norm.shape[0]):\n",
    "    plt.text(X_norm[i, 0], X_norm[i, 1], str(y[i,0]), color=plt.cm.Set1(y[i,0]), \n",
    "             fontdict={'weight': 'bold', 'size': 9})\n",
    "plt.xticks([])\n",
    "plt.yticks([])\n",
    "plt.savefig(\"result/mag_pca_latent16\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = val_y[train_val_split].argmax(axis=1).reshape([-1,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(143, 1)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1112230, shape=(8,), dtype=float32, numpy=\n",
       "array([ 0.06707124, -0.06958992, -0.08077073,  0.07173584, -0.00723271,\n",
       "       -0.05953319,  0.11224787,  0.03083349], dtype=float32)>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_encoder_decoder_ann.weights[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=1112235, shape=(8,), dtype=float32, numpy=\n",
       "array([ 0.06707124, -0.06958992, -0.08077073,  0.07173584, -0.00723271,\n",
       "       -0.05953319,  0.11224787,  0.03083349], dtype=float32)>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_down.weights[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gps_wifi",
   "language": "python",
   "name": "gps_wifi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
