{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "\n",
    "import os\n",
    "import tensorflow as tf   \n",
    "from sklearn.preprocessing import scale\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import layers, losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transpose for tied autoencoder\n",
    "class DenseTranspose(tf.keras.layers.Layer):\n",
    "    def __init__(self, dense, activation=None, **kwargs):\n",
    "        self.dense = dense\n",
    "        self.activation = tf.keras.activations.get(activation)\n",
    "        super().__init__(**kwargs)\n",
    "    def build(self, batch_input_shape):\n",
    "        self.biases = self.add_weight(name='bias',shape=[self.dense.input_shape[-1]],initializer=\"zeros\")\n",
    "        super().build(batch_input_shape)\n",
    "    def call(self, inputs):\n",
    "        z = tf.matmul(inputs, self.dense.weights[0], transpose_b = True)\n",
    "        return self.activation(z + self.biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gps model\n",
    "input_o = tf.keras.layers.Input(shape=(4), name='input_layer_gps')\n",
    "dense1 = layers.Dense(4, activation='relu')\n",
    "dense2 = layers.Dense(4, activation='relu')\n",
    "dense3 = layers.Dense(4, activation='relu')\n",
    "dense4 = layers.Dense(4, activation='relu')\n",
    "models = dense1(input_o )\n",
    "models = dense2(models)\n",
    "models = dense3(models)\n",
    "models = dense4(models)\n",
    "model = tf.keras.Model(inputs=input_o, outputs=models)\n",
    "\n",
    "input_oo = tf.keras.layers.Input(shape=(4), name='input_layer0_gps')\n",
    "models2 = DenseTranspose(dense4, activation = 'relu')(input_oo)\n",
    "models2 = DenseTranspose(dense3, activation = 'relu')(models2)\n",
    "models2 = DenseTranspose(dense2, activation = 'relu')(models2)\n",
    "models2 = DenseTranspose(dense1, activation = 'relu')(models2)\n",
    "model2 = tf.keras.Model(inputs=input_oo, outputs=models2)\n",
    "\n",
    "input = tf.keras.layers.Input(shape=(10,4), name='input_layer1_gps')\n",
    "input1 = layers.Lambda(lambda x: x[:,0,:], output_shape=(1))(input)\n",
    "input2 = layers.Lambda(lambda x: x[:,1,:], output_shape=(1))(input)\n",
    "input3 = layers.Lambda(lambda x: x[:,2,:], output_shape=(1))(input)\n",
    "input4 = layers.Lambda(lambda x: x[:,3,:], output_shape=(1))(input)\n",
    "input5 = layers.Lambda(lambda x: x[:,4,:], output_shape=(1))(input)\n",
    "input6 = layers.Lambda(lambda x: x[:,5,:], output_shape=(1))(input)\n",
    "input7 = layers.Lambda(lambda x: x[:,6,:], output_shape=(1))(input)\n",
    "input8 = layers.Lambda(lambda x: x[:,7,:], output_shape=(1))(input)\n",
    "input9 = layers.Lambda(lambda x: x[:,8,:], output_shape=(1))(input)\n",
    "input10= layers.Lambda(lambda x: x[:,9,:], output_shape=(1))(input)\n",
    "model_1 = model(input1)\n",
    "model_2 = model(input2)\n",
    "model_3 = model(input3)\n",
    "model_4 = model(input4)\n",
    "model_5 = model(input5)\n",
    "model_6 = model(input6)\n",
    "model_7 = model(input7)\n",
    "model_8 = model(input8)\n",
    "model_9 = model(input9)\n",
    "model_10= model(input10)\n",
    "merge_layer = tf.keras.layers.concatenate(inputs=[model_1, model_2,model_3,model_4,model_5,model_6,model_7,model_8,model_9,model_10])\n",
    "dense5 = layers.Dense(32, activation='relu')\n",
    "dense6 = layers.Dense(24, activation='relu')\n",
    "dense7 = layers.Dense(16, activation='relu')\n",
    "model_encoder = dense5(merge_layer)\n",
    "model_encoder = dense6(model_encoder)\n",
    "model_encoder = dense7(model_encoder)\n",
    "model_down_gps = tf.keras.Model(inputs=[input], outputs=model_encoder,name = \"encoder\")\n",
    "\n",
    "# wifi model\n",
    "input = tf.keras.layers.Input(shape=(15), name='input_layer1_wifi')\n",
    "dense1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "dense2 = tf.keras.layers.Dense(24, activation='relu')\n",
    "dense3 = tf.keras.layers.Dense(16, activation='relu')\n",
    "model_encoder = dense1(input)\n",
    "model_encoder = dense2(model_encoder)\n",
    "model_encoder = dense3(model_encoder)\n",
    "model_down_wifi = tf.keras.Model(inputs=[input], outputs=model_encoder,name = \"encoder\")\n",
    "\n",
    "# magnetic model\n",
    "input = tf.keras.layers.Input(shape=(3), name='input_layer1_mag')\n",
    "dense1 = tf.keras.layers.Dense(8, activation='relu')\n",
    "dense2 = tf.keras.layers.Dense(12, activation='relu')\n",
    "dense3 = tf.keras.layers.Dense(16, activation='relu')\n",
    "model_encoder = dense1(input)\n",
    "model_encoder = dense2(model_encoder)\n",
    "model_encoder = dense3(model_encoder)\n",
    "model_down_mag = tf.keras.Model(inputs=[input], outputs=model_encoder,name = \"encoder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f500016e7f0>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load gps trained model\n",
    "path = \"gps_checkpoints/checkpoints_1222/\"\n",
    "latest = tf.train.latest_checkpoint(path)\n",
    "latest\n",
    "checkpoint = tf.train.Checkpoint(model_down=model_down_gps)\n",
    "checkpoint.restore(latest).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4fbc4816d8>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load wifi trained model\n",
    "path = \"wifi_checkpoints/checkpoints_1222/\"\n",
    "latest = tf.train.latest_checkpoint(path)\n",
    "latest\n",
    "checkpoint = tf.train.Checkpoint(model_down=model_down_wifi)\n",
    "checkpoint.restore(latest).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7f4fbc41acc0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load magnetic trained model\n",
    "path = \"magnetic_checkpoints/checkpoints_1222/\"\n",
    "latest = tf.train.latest_checkpoint(path)\n",
    "latest\n",
    "checkpoint = tf.train.Checkpoint(model_down=model_down_mag)\n",
    "checkpoint.restore(latest).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_val_split = np.random.rand(len(train_data)) < 0.70\\ntrain_x = train_data[train_val_split]\\ntrain_y = train_label[train_val_split]\\nval_x = train_data[~train_val_split]\\nval_y = train_label[~train_val_split]'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gps data preprocess\n",
    "\n",
    "a = 6378137\n",
    "e = 8.1819190842622e-2\n",
    "asq = np.power(a,2)\n",
    "esq = np.power(e,2)\n",
    "def ecef2lla(ecef):\n",
    "    # change data from ecef coordiate to lla cordinate\n",
    "    x = ecef[0]\n",
    "    y = ecef[1]\n",
    "    z = ecef[2]\n",
    "    r = ecef[3]\n",
    "    b = np.sqrt( asq * (1-esq) )\n",
    "    bsq = np.power(b,2)\n",
    "    ep = np.sqrt( (asq - bsq)/bsq)\n",
    "    p = np.sqrt(np.power(x,2) + np.power(y,2) )\n",
    "    th = np.arctan2(a*z, b*p)\n",
    "    lon = np.arctan2(y,x)\n",
    "    lat = np.arctan2( (z + np.power(ep,2)*b*np.power(np.sin(th),3) ), (p - esq*a*np.power(np.cos(th),3)) )\n",
    "    N = a/( np.sqrt(1-esq*np.power(np.sin(lat),2)) )\n",
    "    alt = p / np.cos(lat) - N\n",
    "    lon = lon % (2*np.pi)\n",
    "    ret = [lat, lon, alt , r]\n",
    "    return ret\n",
    "\n",
    "datas = glob.glob('transfer/*/*/*.txt')\n",
    "train_data = []\n",
    "train_label = [] \n",
    "for data in datas:\n",
    "    if data.find('timestamp') == -1:\n",
    "        f = np.loadtxt(data,delimiter=\" \").copy()\n",
    "        if f.size == 4:\n",
    "            f = f.reshape((1,-1))\n",
    "        o = np.argsort(f,axis=(0))[:,3]\n",
    "        f = np.array([ecef2lla(d) for d in f])\n",
    "        f = f/np.array([(2*np.pi),(2*np.pi),1e+8,1e+14])\n",
    "        f = f[o]\n",
    "        f.resize((10,4))\n",
    "        train_data.append(f) #/100000000\n",
    "        if data.split('/')[1] == \"indoor\":\n",
    "            train_label.append(\"indoor\"+data.split('/')[-2])\n",
    "        else:\n",
    "            train_label.append(\"outdoor\"+data.split('/')[-2])\n",
    "        \n",
    "\n",
    "train_data_gps = np.array(train_data).astype('float32')\n",
    "train_label_gps = np.array(pd.get_dummies(train_label)).astype('float32')\n",
    "\n",
    "\"\"\"train_val_split = np.random.rand(len(train_data)) < 0.70\n",
    "train_x = train_data[train_val_split]\n",
    "train_y = train_label[train_val_split]\n",
    "val_x = train_data[~train_val_split]\n",
    "val_y = train_label[~train_val_split]\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_val_split = np.random.rand(len(train_data)) < 0.70\\ntrain_x = train_data[train_val_split]\\ntrain_o = origin_data[train_val_split]\\ntrain_y = train_label[train_val_split]\\nval_x = train_data[~train_val_split]\\nval_o = origin_data[~train_val_split]\\nval_y = train_label[~train_val_split]\\nBUFFER_SIZE = train_x.shape[0]\\nBATCH_SIZE = train_x.shape[0]\\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_x,train_o,train_y))\\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\\nvalid_dataset = tf.data.Dataset.from_tensor_slices((val_x,val_o)).batch(len(val_x))'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# wifi data preprocess\n",
    "\n",
    "datas = glob.glob('20201203/wifi/dataRssi_at_*.txt')\n",
    "train_data = []\n",
    "origin_data = []\n",
    "train_label = []\n",
    "for data in datas:\n",
    "    load_data = np.loadtxt(data)#f.read()\n",
    "    load_data = load_data[:200,:15].astype(int)\n",
    "    load_data[load_data==0] = -100\n",
    "    load_data = load_data/100 + 1\n",
    "    for i in range(len(load_data)):\n",
    "        origin_data.append(load_data[i])\n",
    "        mask = np.random.rand((15))\n",
    "        mask = (mask>0.1).astype(int)\n",
    "        noise = np.random.normal(scale = 0.05,size=(15))\n",
    "        load_data[i]*mask\n",
    "        load_data[i]+noise\n",
    "        train_data.append(load_data[i])\n",
    "        train_label.append(data.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0])\n",
    "\n",
    "origin_data_wifi = np.array(origin_data).astype('float32') \n",
    "train_data_wifi = np.array(train_data).astype('float32')\n",
    "train_label_wifi = np.array(pd.get_dummies(train_label)).astype('float32')\n",
    "\n",
    "\"\"\"train_val_split = np.random.rand(len(train_data)) < 0.70\n",
    "train_x = train_data[train_val_split]\n",
    "train_o = origin_data[train_val_split]\n",
    "train_y = train_label[train_val_split]\n",
    "val_x = train_data[~train_val_split]\n",
    "val_o = origin_data[~train_val_split]\n",
    "val_y = train_label[~train_val_split]\n",
    "BUFFER_SIZE = train_x.shape[0]\n",
    "BATCH_SIZE = train_x.shape[0]\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x,train_o,train_y))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_x,val_o)).batch(len(val_x))\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'train_val_split = np.random.rand(len(train_data)) < 0.70\\ntrain_x = train_data[train_val_split]\\ntrain_y = train_label[train_val_split]\\nval_x = train_data[~train_val_split]\\nval_y = train_label[~train_val_split]\\nBUFFER_SIZE = train_x.shape[0]\\nBATCH_SIZE = train_x.shape[0]\\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_x,train_y))\\ntrain_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\\nvalid_dataset = tf.data.Dataset.from_tensor_slices((val_x,val_x)).batch(len(val_x))'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# magnetic data preprocess\n",
    "\n",
    "datas = glob.glob('20201203/wifi/dataRssi_at_*.txt')\n",
    "\n",
    "def getRotationMatrix(gra,m):\n",
    "    Ax = gra[0]\n",
    "    Ay = gra[1]\n",
    "    Az = gra[2]\n",
    "    Ex = m[0]\n",
    "    Ey = m[1]\n",
    "    Ez = m[2]\n",
    "    Hx = Ey*Az - Ez*Ay\n",
    "    Hy = Ez*Ax - Ex*Az\n",
    "    Hz = Ex*Ay - Ey*Ax\n",
    "    normH = np.sqrt(Hx*Hx + Hy*Hy + Hz*Hz)\n",
    "    if normH < 0.1:\n",
    "        return False\n",
    "    invH = 1.0 / normH\n",
    "    Hx *= invH\n",
    "    Hy *= invH\n",
    "    Hz *= invH\n",
    "    invA = 1.0 / np.sqrt(Ax*Ax + Ay*Ay + Az*Az)\n",
    "    Ax *= invA\n",
    "    Ay *= invA\n",
    "    Az *= invA\n",
    "    Mx = Ay*Hz - Az*Hy\n",
    "    My = Az*Hx - Ax*Hz\n",
    "    Mz = Ax*Hy - Ay*Hx\n",
    "    R = np.array([Hx,Hy,Hz,Mx,My,Mz,Ax,Ay,Az])\n",
    "    return R\n",
    "\n",
    "train_data = []\n",
    "train_label = []\n",
    "for data in datas:\n",
    "    load_data = np.loadtxt(data)#f.read()\n",
    "    gras = load_data[:,-3:]/100\n",
    "    ms = load_data[:,-15:-12]/100\n",
    "    for gra,m in zip(gras,ms):\n",
    "        R = getRotationMatrix(gra,m)\n",
    "        gm = np.dot(R.reshape(3,3),m.reshape(3,1))\n",
    "        train_data.append(gm)\n",
    "        train_label.append(data.split(\"/\")[-1].split(\"_\")[-1].split(\".\")[0])\n",
    "\n",
    "\n",
    "train_data = np.array(train_data).astype('float32')\n",
    "train_data = train_data.reshape(-1,3)\n",
    "train_data_mag = (train_data - train_data.mean(axis=0)) / train_data.std(axis = 0)\n",
    "train_label_mag = np.array(pd.get_dummies(train_label)).astype('float32')\n",
    "\n",
    "\"\"\"train_val_split = np.random.rand(len(train_data)) < 0.70\n",
    "train_x = train_data[train_val_split]\n",
    "train_y = train_label[train_val_split]\n",
    "val_x = train_data[~train_val_split]\n",
    "val_y = train_label[~train_val_split]\n",
    "BUFFER_SIZE = train_x.shape[0]\n",
    "BATCH_SIZE = train_x.shape[0]\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_x,train_y))\n",
    "train_dataset = train_dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_x,val_x)).batch(len(val_x))\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gps_wifi",
   "language": "python",
   "name": "gps_wifi"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
